Using device: cuda
CL-Arguments: Namespace(augment=0, comment='q1a_early_stop', disp=False, dropout=None, e_stop=True, epoch=20, jitter=0.2, norm=False)
hidden sizes: [128, 512, 512, 512, 512, 512]

ConvNet(
  (conv_net): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU()
    (3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU()
    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): ReLU()
    (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): ReLU()
    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): ReLU()
    (15): Flatten(start_dim=1, end_dim=-1)
    (16): Linear(in_features=512, out_features=10, bias=True)
  )
)
conv_net.0.weight, torch.Size([128, 3, 3, 3]), # params: 3456, Parameter containing:
tensor([[[[-0.0591, -0.0327, -0.0104],
          [ 0.0132,  0.1667, -0.1166],
          [ 0.0013,  0.0805, -0.1280]],

         [[ 0.1902,  0.1828, -0.0547],
          [-0.0413,  0.0720,  0.0926],
          [ 0.1305, -0.0478,  0.1029]],

         [[ 0.0037,  0.1894,  0.1099],
          [-0.1007,  0.0651, -0.0860],
          [ 0.1690, -0.0019,  0.0648]]],


        [[[-0.1291,  0.0977,  0.0601],
          [-0.1698,  0.0099,  0.1137],
          [ 0.1716,  0.1090,  0.0165]],

         [[ 0.1197, -0.1082,  0.1754],
          [ 0.1810,  0.1528, -0.0566],
          [-0.0481, -0.0679, -0.1235]],

         [[-0.0445, -0.1503, -0.1637],
          [-0.0806,  0.1509, -0.1449],
          [ 0.1780, -0.1815,  0.1124]]],


        [[[-0.0882, -0.0969,  0.0913],
          [-0.1182, -0.1200,  0.0045],
          [-0.0928, -0.1272,  0.1514]],

         [[-0.1308, -0.1746, -0.0737],
          [ 0.1428,  0.1362, -0.1305],
          [-0.1019,  0.0635,  0.1911]],

         [[-0.1605, -0.1318, -0.1191],
          [ 0.1284,  0.1262, -0.0988],
          [-0.1614,  0.1912, -0.1389]]],


        ...,


        [[[ 0.0454, -0.1035,  0.0477],
          [-0.0798, -0.0853, -0.0203],
          [ 0.0590, -0.0357, -0.0683]],

         [[ 0.1257,  0.0253, -0.1465],
          [-0.0635,  0.0365,  0.0399],
          [-0.0785,  0.1195,  0.1308]],

         [[ 0.0248, -0.0327, -0.1464],
          [ 0.1696,  0.1558, -0.0810],
          [-0.1554,  0.0964, -0.1492]]],


        [[[ 0.0808, -0.0569,  0.0239],
          [ 0.0558,  0.1481,  0.0625],
          [-0.1291, -0.1093, -0.0102]],

         [[ 0.1069, -0.0173, -0.0531],
          [ 0.0849, -0.1062,  0.1498],
          [-0.0396,  0.0451,  0.1167]],

         [[ 0.0436, -0.0988,  0.0109],
          [-0.1324, -0.0117,  0.0588],
          [ 0.1062,  0.1251,  0.1122]]],


        [[[-0.1123, -0.1523,  0.0781],
          [-0.0226, -0.0539, -0.1202],
          [-0.1548, -0.0927, -0.0482]],

         [[-0.1049, -0.0350,  0.1489],
          [ 0.0433,  0.0218,  0.1424],
          [ 0.1633, -0.0729, -0.1425]],

         [[-0.0010, -0.0946, -0.1863],
          [ 0.0238, -0.0370, -0.1149],
          [ 0.0834,  0.1436,  0.0298]]]], device='cuda:0', requires_grad=True)

conv_net.0.bias, torch.Size([128]), # params: 128, Parameter containing:
tensor([-0.1502,  0.0763, -0.1894,  0.1127,  0.1218, -0.1715, -0.0858,  0.1392,
        -0.1915,  0.0903,  0.1098, -0.1858,  0.0400, -0.0188,  0.1225,  0.1484,
        -0.0390,  0.1800, -0.1433, -0.1000, -0.1208, -0.1407, -0.0440,  0.0335,
         0.1232, -0.0816,  0.1189,  0.0704,  0.1819, -0.0867, -0.0804, -0.1709,
         0.1164,  0.1228,  0.1486, -0.0719, -0.0194, -0.0884, -0.0380, -0.1558,
        -0.1867,  0.0766,  0.0390,  0.1708, -0.0437,  0.1787,  0.0026, -0.1671,
         0.1408,  0.0688,  0.0150,  0.1144, -0.0322, -0.1766,  0.1153, -0.0111,
         0.1040, -0.0783,  0.1747, -0.1439,  0.1326,  0.1039, -0.0705,  0.0786,
        -0.0334,  0.1300, -0.0074,  0.0202, -0.0350,  0.1676,  0.0398,  0.1623,
        -0.1506, -0.0617,  0.0715, -0.0338,  0.1372, -0.1728, -0.0585,  0.1658,
        -0.1147,  0.0919,  0.0118,  0.0415, -0.0830, -0.0214, -0.1034, -0.0926,
        -0.0150,  0.1129,  0.0870,  0.1270,  0.0052, -0.0566,  0.1898, -0.1326,
        -0.0353, -0.0560,  0.0171, -0.1658,  0.1719, -0.1283, -0.0500, -0.0939,
         0.0766,  0.0798,  0.1595, -0.0203,  0.0478,  0.0343, -0.0848, -0.1392,
        -0.0025, -0.0809,  0.1499,  0.0711, -0.1231,  0.0579,  0.0605, -0.1375,
         0.0852, -0.1243, -0.1140, -0.0585,  0.1591, -0.1469,  0.0406,  0.0679],
       device='cuda:0', requires_grad=True)

conv_net.3.weight, torch.Size([512, 128, 3, 3]), # params: 589824, Parameter containing:
tensor([[[[ 0.0244,  0.0251, -0.0031],
          [ 0.0211, -0.0124,  0.0060],
          [-0.0136,  0.0227, -0.0104]],

         [[ 0.0103, -0.0279, -0.0008],
          [-0.0248, -0.0243, -0.0083],
          [ 0.0032,  0.0170,  0.0160]],

         [[-0.0227,  0.0050, -0.0063],
          [-0.0091, -0.0211,  0.0186],
          [-0.0244,  0.0157, -0.0063]],

         ...,

         [[ 0.0245,  0.0176, -0.0034],
          [ 0.0001,  0.0227, -0.0209],
          [-0.0114,  0.0216,  0.0215]],

         [[-0.0126,  0.0251,  0.0247],
          [ 0.0029,  0.0202,  0.0289],
          [ 0.0235, -0.0044, -0.0263]],

         [[ 0.0285, -0.0111, -0.0213],
          [-0.0236,  0.0071, -0.0276],
          [-0.0266, -0.0263, -0.0083]]],


        [[[-0.0188, -0.0012, -0.0033],
          [-0.0175, -0.0036, -0.0222],
          [ 0.0106, -0.0034, -0.0166]],

         [[ 0.0038,  0.0067,  0.0262],
          [-0.0155,  0.0198,  0.0191],
          [ 0.0080,  0.0073,  0.0249]],

         [[ 0.0175,  0.0110, -0.0220],
          [-0.0077, -0.0157,  0.0226],
          [-0.0200,  0.0215,  0.0231]],

         ...,

         [[-0.0180,  0.0073, -0.0074],
          [-0.0160, -0.0012, -0.0102],
          [-0.0181, -0.0293,  0.0114]],

         [[ 0.0244, -0.0284,  0.0227],
          [ 0.0236, -0.0287, -0.0010],
          [-0.0211, -0.0012, -0.0036]],

         [[ 0.0285, -0.0118,  0.0218],
          [-0.0083,  0.0151, -0.0198],
          [-0.0050,  0.0222, -0.0277]]],


        [[[ 0.0151, -0.0215,  0.0123],
          [-0.0011, -0.0130, -0.0153],
          [ 0.0141, -0.0082, -0.0052]],

         [[ 0.0047,  0.0098,  0.0249],
          [-0.0072, -0.0042, -0.0206],
          [ 0.0273,  0.0172,  0.0104]],

         [[ 0.0138, -0.0028, -0.0014],
          [-0.0096, -0.0183,  0.0158],
          [ 0.0161,  0.0185,  0.0159]],

         ...,

         [[ 0.0029,  0.0005,  0.0007],
          [ 0.0151, -0.0118,  0.0256],
          [ 0.0260, -0.0004, -0.0150]],

         [[ 0.0272,  0.0126, -0.0037],
          [ 0.0020, -0.0113,  0.0112],
          [ 0.0096,  0.0100, -0.0057]],

         [[-0.0280,  0.0002, -0.0207],
          [-0.0292, -0.0281,  0.0022],
          [-0.0162,  0.0045, -0.0133]]],


        ...,


        [[[ 0.0291, -0.0152,  0.0114],
          [ 0.0142,  0.0171,  0.0019],
          [-0.0125, -0.0138, -0.0172]],

         [[ 0.0180,  0.0096, -0.0196],
          [-0.0224, -0.0250, -0.0067],
          [ 0.0283,  0.0190,  0.0198]],

         [[ 0.0114, -0.0176,  0.0260],
          [ 0.0155,  0.0233,  0.0168],
          [ 0.0273, -0.0262,  0.0068]],

         ...,

         [[ 0.0148, -0.0153, -0.0124],
          [-0.0155, -0.0005,  0.0111],
          [ 0.0250,  0.0274, -0.0274]],

         [[-0.0267,  0.0005,  0.0244],
          [-0.0276, -0.0194,  0.0051],
          [-0.0281, -0.0142,  0.0211]],

         [[-0.0262,  0.0068,  0.0212],
          [-0.0222,  0.0119,  0.0006],
          [ 0.0183, -0.0250,  0.0251]]],


        [[[-0.0032, -0.0185,  0.0141],
          [-0.0248,  0.0116,  0.0069],
          [-0.0195,  0.0002,  0.0056]],

         [[ 0.0172,  0.0010,  0.0289],
          [-0.0177, -0.0043, -0.0155],
          [-0.0151,  0.0270,  0.0079]],

         [[ 0.0151, -0.0060, -0.0070],
          [ 0.0182,  0.0171, -0.0246],
          [ 0.0004,  0.0172, -0.0119]],

         ...,

         [[ 0.0270, -0.0125,  0.0182],
          [-0.0125,  0.0194, -0.0176],
          [ 0.0210, -0.0247,  0.0007]],

         [[-0.0200,  0.0248, -0.0038],
          [ 0.0186,  0.0211,  0.0272],
          [ 0.0157, -0.0192,  0.0088]],

         [[-0.0134,  0.0156, -0.0090],
          [ 0.0210,  0.0045,  0.0245],
          [ 0.0015, -0.0045, -0.0279]]],


        [[[ 0.0134,  0.0134,  0.0224],
          [ 0.0043,  0.0011, -0.0227],
          [ 0.0048,  0.0018, -0.0242]],

         [[-0.0273, -0.0090,  0.0059],
          [ 0.0058,  0.0196, -0.0080],
          [-0.0048,  0.0176, -0.0003]],

         [[ 0.0269,  0.0285,  0.0228],
          [-0.0075,  0.0013,  0.0183],
          [ 0.0132,  0.0168, -0.0142]],

         ...,

         [[-0.0092, -0.0056, -0.0145],
          [ 0.0176, -0.0136,  0.0093],
          [-0.0293,  0.0049,  0.0012]],

         [[-0.0010,  0.0063,  0.0228],
          [-0.0008,  0.0095,  0.0293],
          [-0.0224,  0.0037,  0.0275]],

         [[-0.0095, -0.0084, -0.0279],
          [-0.0024, -0.0204,  0.0064],
          [ 0.0089,  0.0026, -0.0251]]]], device='cuda:0', requires_grad=True)

conv_net.3.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([-1.2004e-02,  2.1165e-03,  2.5218e-02,  1.1933e-02, -7.8507e-03,
         2.0193e-02,  2.8595e-02,  1.4242e-02, -3.0189e-03,  2.7256e-02,
        -1.7437e-02, -2.3072e-02,  4.1715e-03,  2.8267e-02,  4.4473e-03,
         1.9364e-02,  1.6716e-02,  3.2203e-03,  1.2653e-02, -2.7499e-02,
         1.7811e-02, -1.3442e-02, -2.6859e-02,  2.6712e-03,  1.1027e-02,
         1.1409e-02, -1.8051e-02,  6.5141e-03, -6.9170e-03, -1.4783e-02,
         1.9868e-03, -5.6721e-03, -9.6016e-03,  1.5883e-02, -2.0056e-02,
        -2.8020e-03,  1.6987e-02, -1.0507e-02, -2.7762e-02,  2.8414e-02,
         9.2399e-03, -1.9924e-02,  6.5145e-03,  9.5291e-03, -1.3781e-02,
        -1.8974e-02,  1.0545e-02, -2.9212e-02, -1.4547e-02, -2.8549e-02,
        -1.5935e-02,  2.4711e-02,  5.5028e-03, -1.7281e-02,  4.2732e-03,
         6.7439e-03,  1.6286e-02, -1.2870e-02, -1.3093e-02,  1.8332e-02,
        -2.4129e-02, -1.5992e-02, -1.7643e-02, -8.1770e-03, -9.0782e-03,
        -4.3930e-03, -1.1759e-03,  2.8032e-02,  2.9288e-02,  2.2850e-02,
         4.5072e-03, -7.1803e-03, -1.2857e-02,  4.7636e-04,  1.5132e-02,
         1.8941e-03,  6.1611e-03, -2.0014e-03,  1.4221e-02, -2.8555e-02,
         2.3716e-02,  2.7597e-02,  3.4436e-04, -2.3217e-02,  8.5780e-03,
        -1.6136e-03, -1.1908e-02,  7.0413e-03,  1.8067e-02, -1.3874e-02,
         6.5813e-03, -1.0606e-02,  9.7021e-03, -1.2373e-02, -5.1101e-03,
         5.4467e-03,  7.9371e-03, -5.0442e-03,  1.6311e-02, -9.1026e-03,
         2.6032e-02, -9.2345e-03, -1.6291e-02, -1.8736e-02,  1.7284e-04,
         2.1289e-02, -3.2439e-03, -1.9217e-02, -9.8069e-03,  9.1385e-03,
        -1.3422e-02, -3.6544e-03, -2.1720e-02,  1.6058e-02,  1.1656e-02,
         1.1638e-02,  2.5831e-02,  1.9643e-02, -1.8083e-02,  1.6326e-02,
         2.1245e-02, -8.0103e-03,  1.1024e-02, -1.4352e-02, -1.1827e-02,
         1.2179e-02,  2.5354e-02, -4.8772e-03, -2.1072e-02, -1.2463e-02,
         2.3289e-02,  2.1132e-02,  1.4040e-02,  2.7382e-03,  2.7167e-02,
         2.1695e-03,  2.7872e-02, -1.3849e-02, -9.5514e-03, -1.1083e-02,
         1.3930e-02, -9.3904e-03, -2.7682e-02, -6.3071e-03,  1.3977e-03,
        -1.0954e-02,  1.2754e-02, -2.2294e-02,  2.9249e-02,  1.2280e-02,
         2.1979e-03, -2.1292e-02, -1.7639e-02, -1.1891e-02,  2.3847e-02,
        -1.5077e-02,  2.3050e-02, -7.4582e-03,  2.5062e-02, -2.0780e-02,
        -2.8561e-02, -1.9617e-02,  6.4802e-03, -1.6680e-02, -2.4525e-02,
        -1.6259e-02, -1.9838e-02, -2.6560e-02,  1.5326e-02,  9.0225e-03,
        -1.3974e-02, -9.5336e-03, -2.3997e-02, -3.4932e-04, -2.9697e-03,
        -1.0180e-02,  1.0498e-03, -2.2237e-02,  8.8971e-03, -1.0141e-02,
        -1.1741e-02, -9.6975e-03,  1.3349e-04, -2.6020e-02,  2.1425e-02,
        -2.5211e-02, -3.5505e-03,  1.6228e-02,  1.0746e-02,  2.5157e-02,
         2.4732e-02, -9.0429e-03, -2.4879e-02,  1.6494e-02,  9.3680e-03,
         1.8819e-02,  9.6823e-03, -1.3585e-02, -8.9740e-03, -2.6409e-02,
         2.5566e-02,  1.1525e-02, -2.2372e-02, -2.7285e-02, -1.4012e-02,
         2.8882e-02, -2.5146e-03, -4.0271e-03,  1.7872e-02,  1.2269e-02,
        -1.6300e-02, -2.6328e-02,  1.6696e-02,  1.2260e-02,  1.1710e-02,
         2.0521e-02, -2.9320e-02, -1.9525e-04,  2.5698e-02, -1.2776e-03,
        -2.7327e-02,  3.6226e-03,  2.3809e-02, -1.1014e-02, -2.1273e-02,
         2.8378e-02,  4.9596e-03, -1.8606e-02, -2.5884e-03,  9.0753e-05,
         2.6685e-02,  2.4452e-02,  1.4715e-02, -2.1652e-02, -2.8621e-02,
         1.8824e-02,  2.2746e-03,  4.8780e-03, -2.7183e-02,  2.6631e-02,
         1.5291e-02,  1.3220e-02, -1.3766e-02,  1.1131e-02,  8.4122e-03,
        -6.2461e-03, -2.7846e-02, -2.5316e-02, -1.5249e-02,  1.7263e-02,
        -1.2939e-02, -4.9548e-03,  2.0163e-02,  8.4123e-04,  2.0261e-02,
        -1.3481e-02,  1.9654e-02,  2.4661e-02,  2.8687e-03, -8.7462e-04,
        -1.3271e-02, -2.8482e-02, -1.5305e-02,  1.1673e-02, -1.3906e-02,
         1.6882e-03,  8.6509e-04,  2.6084e-02, -2.1633e-02, -1.7941e-02,
         2.3572e-02, -1.0674e-02,  1.7385e-02, -8.0148e-04, -2.5648e-02,
         8.1861e-03, -1.5745e-02, -2.3788e-03, -2.8798e-02,  1.8280e-03,
         1.0667e-02, -1.6645e-02, -2.2253e-02,  1.7150e-02, -7.5574e-03,
         1.4794e-02, -9.0720e-03, -1.3645e-02,  1.0416e-03,  5.0382e-04,
        -3.5767e-03,  1.1406e-02,  2.9286e-02,  2.7875e-03, -2.2904e-02,
        -2.4769e-02,  7.6211e-03,  1.0577e-02,  1.9929e-02,  7.0520e-03,
        -2.9215e-02, -9.7840e-05,  1.2291e-02,  1.2349e-02,  1.2268e-02,
        -7.4490e-03,  2.7363e-02,  1.7569e-02,  1.1543e-02, -2.6889e-02,
        -7.6027e-03,  2.3473e-02, -1.0388e-02,  7.7378e-03,  1.1178e-03,
        -1.9384e-02,  2.1008e-02,  1.2374e-02,  1.2148e-02,  2.7817e-02,
        -5.0343e-03, -2.5951e-02, -2.1288e-02, -3.7666e-03, -2.4011e-02,
        -1.1794e-02, -1.3423e-02, -2.8997e-02,  2.5194e-02,  1.2084e-02,
        -8.9549e-03, -2.5584e-03, -1.3871e-02, -2.6258e-02,  3.8139e-03,
        -2.3462e-02, -1.1056e-02, -1.2481e-02,  2.5853e-02, -1.7984e-02,
        -2.3849e-02, -2.8416e-02,  8.7230e-03, -2.5176e-02, -1.8758e-02,
         1.7991e-02, -9.0077e-03,  1.0635e-02, -2.1212e-02,  1.7798e-02,
        -1.5659e-02, -2.1259e-03, -1.4620e-03,  1.7962e-02,  3.7793e-03,
        -8.3938e-03,  4.2187e-03, -1.6772e-04, -2.7426e-02, -9.9425e-03,
        -1.1526e-02, -1.7156e-02, -1.5558e-02,  1.2487e-02, -2.1020e-02,
         1.1565e-02,  1.0551e-02,  2.1705e-02, -2.0389e-02, -1.5795e-02,
         1.5010e-03, -2.7995e-03,  8.2249e-03, -9.4784e-03,  1.7727e-02,
        -4.6694e-03,  1.7329e-02,  2.1186e-02, -1.1006e-02,  2.2161e-02,
         8.7564e-03, -9.7530e-03, -1.3754e-02, -1.2493e-03, -1.9516e-02,
        -1.4544e-02, -7.1920e-03,  2.3175e-02,  4.4599e-03,  5.3595e-03,
        -1.8860e-02, -2.6866e-03, -2.3809e-02,  1.3020e-02,  6.5115e-03,
        -2.5670e-02,  9.0603e-03, -2.7465e-02,  2.5852e-02,  5.1205e-03,
        -2.3124e-02,  1.8089e-02,  2.2699e-02, -2.4685e-02,  9.5420e-03,
        -1.4773e-02,  1.4970e-02, -7.0354e-03, -2.5987e-03, -1.2265e-02,
        -2.1025e-02,  2.7246e-02,  1.6681e-02,  2.6745e-02,  1.8411e-03,
        -1.4466e-02,  2.8988e-02, -1.9921e-02,  1.8656e-02,  2.9274e-02,
         1.7249e-02,  2.1362e-02,  2.2357e-02, -2.7855e-02, -7.3565e-03,
         2.1643e-02, -2.8506e-02,  8.8105e-03,  2.7163e-02,  1.1607e-02,
         2.0297e-02, -4.3034e-03, -2.2240e-02,  2.4206e-02, -9.8720e-03,
        -1.9034e-02, -1.8075e-02,  7.6382e-03,  2.3711e-02, -9.8546e-03,
        -1.4146e-02,  2.8784e-02, -7.9420e-03, -1.2851e-02, -9.7613e-03,
         1.0610e-02, -1.1844e-02, -9.3824e-03, -1.6058e-02,  7.6011e-03,
         7.7493e-03,  1.4805e-02, -1.0408e-02, -1.3052e-02,  1.5943e-02,
        -2.6954e-02,  1.4539e-03, -1.6718e-02,  1.8828e-02,  9.6998e-03,
         9.6882e-03,  4.4436e-03,  1.2043e-02, -1.7877e-02,  4.2933e-03,
         5.7301e-03,  5.8411e-03, -1.7412e-02, -1.7542e-02, -7.1394e-03,
         2.1294e-03,  2.7778e-02,  1.7174e-02,  1.1618e-02, -2.4977e-02,
        -1.1451e-02, -2.9052e-02,  4.5853e-03,  1.5983e-02, -2.6415e-02,
        -2.5542e-02,  1.3755e-02,  1.5008e-02,  2.5663e-02, -1.7975e-02,
         1.6584e-02, -1.6527e-02,  1.9507e-03,  1.0203e-02, -1.0186e-02,
         1.3636e-02,  2.2870e-03, -7.1832e-03,  1.4635e-02, -2.7778e-02,
         9.9265e-03, -2.2326e-02, -2.0858e-02, -2.7878e-02, -6.6442e-03,
         7.1882e-03,  1.8926e-02,  3.2174e-03,  1.5505e-02, -2.7940e-02,
         2.1428e-02,  2.9044e-02,  5.8708e-03,  2.0899e-02, -5.4550e-03,
        -1.4784e-04, -5.4558e-03], device='cuda:0', requires_grad=True)

conv_net.6.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[-1.0982e-02, -1.1834e-02,  1.0804e-03],
          [ 1.0450e-02,  7.7264e-03,  1.4238e-02],
          [ 9.0039e-03,  1.9642e-03, -1.9115e-03]],

         [[-4.4159e-03, -1.1859e-03,  1.4679e-02],
          [ 7.5791e-03, -9.5190e-03,  6.8414e-03],
          [-5.0038e-03,  1.3817e-02,  6.0415e-03]],

         [[ 5.9103e-04,  1.0109e-02,  8.5587e-03],
          [ 6.9018e-03,  1.4442e-02,  8.9910e-03],
          [ 5.6319e-03,  9.8671e-04, -3.7351e-03]],

         ...,

         [[ 8.4906e-03, -3.0665e-03, -1.0637e-02],
          [ 7.5933e-03,  8.0917e-03, -1.3935e-02],
          [-1.0458e-02, -6.3934e-03,  4.1232e-03]],

         [[ 4.6049e-04, -7.2623e-03, -1.3793e-02],
          [ 1.1491e-02, -1.3635e-02,  1.0755e-02],
          [ 1.0464e-02, -3.5210e-05,  1.1312e-03]],

         [[ 1.1081e-02,  8.7397e-03,  1.2615e-02],
          [-2.3992e-03,  3.5027e-03,  4.0698e-03],
          [ 4.4715e-03,  8.9340e-03, -1.1988e-02]]],


        [[[ 3.2401e-03,  4.3524e-03,  1.6768e-03],
          [ 1.0606e-02, -1.2113e-02,  2.5258e-03],
          [-1.0168e-02, -3.5049e-03,  1.4523e-02]],

         [[ 3.3145e-03,  1.1874e-02,  7.8067e-03],
          [-1.7597e-03,  2.5165e-03,  3.5265e-04],
          [ 4.7681e-03,  1.2927e-02,  1.6644e-03]],

         [[ 1.5059e-03,  1.2332e-02, -1.2843e-02],
          [-8.1802e-03,  5.5403e-03, -1.3108e-02],
          [-1.4224e-02, -3.4113e-03, -1.4082e-02]],

         ...,

         [[-6.0003e-03, -4.9575e-03,  1.0285e-02],
          [-1.2186e-02,  1.4282e-02,  7.6549e-04],
          [-3.2703e-03, -7.3079e-03, -1.3910e-02]],

         [[-4.2813e-03,  1.0396e-02, -8.9114e-04],
          [-3.2217e-03, -1.3153e-02, -2.5242e-03],
          [ 5.6533e-03, -5.8033e-03, -1.1521e-02]],

         [[-1.2842e-03,  9.6577e-03, -3.2487e-03],
          [-1.3624e-02,  1.1858e-02,  1.7152e-03],
          [-3.3692e-03,  6.3230e-03, -1.2376e-02]]],


        [[[ 2.9943e-03, -5.1049e-03, -1.1349e-02],
          [ 1.0960e-02,  6.7139e-03,  1.0829e-02],
          [-1.3774e-02,  1.2758e-03,  9.5220e-03]],

         [[ 1.0716e-02, -1.0600e-02, -2.0875e-03],
          [ 9.2780e-03, -1.3760e-02,  1.0336e-02],
          [-7.7099e-03,  9.0423e-03, -4.9519e-03]],

         [[-3.3639e-03, -1.0308e-03, -9.2050e-03],
          [-1.3954e-02,  8.1619e-03, -1.1356e-02],
          [-1.1032e-02,  6.8734e-03, -1.1618e-02]],

         ...,

         [[-2.9662e-03,  5.6532e-03, -1.4263e-03],
          [-1.2914e-03,  4.0798e-03,  1.2219e-02],
          [ 1.0835e-02, -3.6322e-03, -1.9415e-03]],

         [[ 7.1912e-03, -1.0191e-02,  1.0124e-02],
          [-8.5924e-03,  4.1417e-03,  3.3191e-03],
          [ 1.2797e-02, -8.8013e-03,  5.1897e-04]],

         [[ 7.7267e-03, -1.3706e-02,  9.1624e-03],
          [-3.5107e-03,  2.4597e-03, -7.0827e-03],
          [ 5.9762e-03,  1.4038e-02,  3.9801e-03]]],


        ...,


        [[[-1.9791e-03,  8.6616e-03,  6.0612e-03],
          [ 5.6840e-03,  9.3564e-05,  7.6132e-03],
          [-1.1629e-02,  1.0837e-02,  9.4953e-03]],

         [[-6.3875e-03,  6.5252e-03, -1.2241e-03],
          [-1.2256e-02, -1.1185e-02,  7.0853e-04],
          [-2.8037e-03,  1.2475e-02, -1.9157e-03]],

         [[ 1.2342e-02,  5.3923e-03, -1.1236e-02],
          [ 1.4504e-02, -1.3735e-03, -1.2401e-02],
          [ 1.1411e-02, -1.1027e-02,  1.1526e-02]],

         ...,

         [[-1.2227e-02, -4.9409e-03,  1.4097e-03],
          [-8.5493e-03,  6.3903e-04,  1.3410e-02],
          [-2.2483e-03, -1.2664e-02,  4.0045e-03]],

         [[ 7.0931e-03, -3.7993e-03, -1.2200e-02],
          [ 5.3583e-03, -4.1858e-04, -7.1438e-03],
          [-3.7607e-03,  1.2096e-03, -8.8416e-03]],

         [[ 5.6804e-03,  3.1177e-03, -1.1845e-02],
          [ 8.8236e-03, -6.4728e-03, -1.3099e-02],
          [-2.8443e-03, -9.6137e-05, -1.6472e-03]]],


        [[[ 1.1207e-02,  1.0146e-02, -1.0137e-02],
          [-1.2296e-02,  1.0922e-02,  9.5866e-03],
          [-3.8881e-03, -1.0065e-02, -1.3922e-02]],

         [[-1.0444e-02,  5.9496e-03,  4.2542e-04],
          [-1.1910e-02,  3.9208e-03,  1.1642e-02],
          [ 1.0690e-02,  1.1547e-02,  1.3674e-03]],

         [[-8.7239e-03, -2.8940e-03, -1.0360e-03],
          [-3.5156e-03, -1.7058e-03,  4.3393e-03],
          [ 2.0437e-03,  5.1731e-03, -1.1338e-02]],

         ...,

         [[ 1.4151e-02, -1.2613e-02, -3.0467e-03],
          [-4.8819e-03,  9.5803e-03,  5.1501e-03],
          [-9.7590e-03, -6.0750e-04,  2.5197e-04]],

         [[ 8.5799e-03,  2.4822e-03,  1.4295e-02],
          [ 5.8329e-03, -3.3392e-03, -9.8128e-03],
          [ 5.6671e-03,  7.2020e-03,  1.2246e-03]],

         [[ 3.7724e-03,  1.1647e-02, -1.0043e-02],
          [-1.0172e-02,  3.1926e-03,  3.2910e-03],
          [ 4.4011e-03,  1.4701e-03, -7.9159e-03]]],


        [[[ 8.6500e-03, -2.3016e-03,  4.1584e-03],
          [ 6.5480e-03,  4.9754e-03, -1.1733e-02],
          [ 9.7086e-03,  1.1377e-02, -1.3462e-02]],

         [[ 5.1860e-04,  2.5930e-03, -8.1589e-03],
          [-7.9954e-03, -6.6781e-03, -7.2566e-03],
          [ 1.0792e-02, -9.4430e-04, -1.1151e-02]],

         [[-1.4077e-02,  9.6694e-03,  4.8387e-03],
          [ 1.0965e-02,  1.2777e-02, -1.2116e-02],
          [ 9.5088e-03,  5.8916e-03, -3.7327e-03]],

         ...,

         [[-2.2775e-03,  1.8720e-04,  1.4349e-02],
          [-1.4162e-02, -5.5975e-03,  4.1056e-03],
          [-1.0733e-03,  1.2160e-02, -1.3011e-02]],

         [[-1.1067e-02,  1.1622e-02,  2.7267e-03],
          [ 7.5457e-03, -1.0937e-02, -1.3278e-02],
          [-1.1653e-02, -2.0581e-03, -1.0377e-02]],

         [[ 4.0831e-03, -6.9240e-03,  5.9225e-03],
          [ 9.7983e-03,  7.7035e-03,  8.9504e-03],
          [ 1.2284e-02,  3.9791e-03, -5.2725e-03]]]], device='cuda:0',
       requires_grad=True)

conv_net.6.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([ 2.5814e-03,  3.0873e-03,  1.2225e-02,  8.8075e-03, -1.0397e-02,
         2.4851e-03, -5.0101e-03, -3.9201e-03,  2.2445e-03,  9.7098e-03,
        -5.3828e-03,  9.3108e-03, -4.8447e-03, -8.0344e-03, -1.4292e-02,
        -6.2307e-03,  8.1512e-03, -1.4463e-04, -7.9164e-03,  8.2945e-03,
         1.0359e-02, -1.7115e-03,  1.2071e-02, -2.2160e-03, -1.0215e-02,
         1.3640e-02, -8.3566e-03, -1.2965e-02,  8.7411e-03,  1.0582e-02,
         1.1715e-02,  1.1446e-02, -1.0430e-02,  1.2974e-03, -8.8064e-03,
         9.4474e-03, -1.4484e-02, -1.0461e-02,  2.3259e-03,  1.0697e-03,
        -7.2814e-03,  1.2206e-02,  5.1129e-04,  2.1311e-03,  7.5777e-03,
         1.3162e-02, -3.7394e-04, -5.1589e-04,  2.7797e-03, -4.3200e-03,
        -8.1018e-03, -7.9685e-03, -6.1928e-03, -1.3333e-02, -2.4549e-03,
         6.0111e-03, -1.3508e-02, -3.1386e-03, -9.0990e-04, -1.0164e-02,
        -4.0068e-03, -7.3970e-03, -1.0316e-02,  1.2012e-02,  5.5050e-03,
         9.4780e-03, -4.3060e-05, -1.8176e-03, -6.0805e-03,  4.9845e-03,
         7.1018e-03,  2.8311e-03,  2.6547e-03, -1.2816e-03, -1.4512e-02,
        -5.1158e-03, -2.3991e-03, -1.0739e-02,  6.9163e-03,  1.1563e-02,
         1.3652e-02,  2.0578e-03,  2.3311e-03,  1.0431e-03,  1.2296e-02,
        -1.0162e-02,  6.1311e-03,  1.6555e-03,  1.0374e-02,  1.3036e-02,
         1.6539e-03,  9.3397e-03,  1.4333e-02, -1.2737e-02,  9.3963e-03,
        -1.4517e-02,  3.1177e-03, -4.2961e-04, -1.3618e-02, -1.1850e-02,
         1.3841e-02,  1.0361e-02, -8.2869e-03,  8.1752e-03,  6.2993e-03,
         6.3582e-03, -4.9089e-03, -1.3658e-02, -8.6111e-03, -1.0615e-02,
        -1.2033e-02,  2.5943e-03,  9.7835e-03,  4.4055e-03, -1.1928e-02,
        -6.8696e-03, -1.1894e-02, -3.4992e-03, -2.0915e-03, -1.0786e-02,
        -6.1458e-03,  3.4072e-03, -8.5193e-03,  1.2054e-02, -5.6566e-04,
         7.3184e-03, -2.2212e-03,  1.9565e-04,  9.0118e-03,  7.6273e-04,
        -1.0571e-02,  5.1349e-03,  1.4729e-02,  7.8633e-03, -3.3212e-03,
         7.7624e-04,  3.2537e-03,  8.6825e-03,  1.3865e-02,  5.8412e-03,
         1.0685e-02, -4.9080e-03,  7.5399e-03,  1.0077e-02, -2.1800e-03,
        -1.7857e-03, -2.6929e-03,  5.7220e-03,  1.0116e-02, -8.3854e-03,
         3.4208e-03,  1.2361e-02,  7.4014e-03,  3.5962e-03,  1.4559e-02,
         8.5584e-04, -1.0529e-02, -1.1304e-02, -4.6155e-03,  3.1199e-03,
         2.4673e-03,  8.5709e-04, -3.7732e-03,  1.9906e-03, -7.8816e-04,
        -9.0198e-03, -8.9672e-03,  2.7538e-03, -6.5881e-03, -1.3746e-02,
         6.6325e-03,  1.2229e-02,  4.6981e-03, -7.3248e-04, -3.4358e-03,
        -1.2120e-02, -3.4222e-03, -3.1701e-03,  1.4072e-02, -7.8325e-03,
         1.2975e-02,  4.9160e-03, -1.0006e-02, -9.4314e-03,  8.7338e-03,
         3.9781e-03,  4.8587e-03,  6.7831e-03, -9.5517e-03, -9.2017e-03,
        -1.7034e-03,  7.1028e-03,  1.2170e-02,  3.5974e-03,  7.6587e-03,
        -6.5998e-03,  1.3378e-02,  2.5775e-03,  1.1895e-03,  1.4184e-02,
         1.0085e-02, -2.1236e-03, -1.0372e-02,  4.1368e-03,  1.6818e-03,
         3.3990e-03, -8.4247e-03,  1.3683e-02,  7.1854e-03,  9.8542e-03,
         7.2426e-03,  3.8314e-03,  1.4221e-02,  1.1165e-02,  1.2856e-02,
        -1.0674e-02, -8.7500e-03, -1.0560e-02,  3.9587e-03, -9.1101e-04,
        -3.0258e-03,  2.3619e-03,  1.1715e-02,  3.4598e-03, -7.0809e-03,
        -5.4341e-03,  6.8761e-03,  1.3531e-02,  1.3113e-03,  7.0645e-03,
        -1.0541e-02, -1.0501e-02,  1.3937e-02,  3.9312e-03, -1.2623e-02,
        -7.2150e-03, -2.1622e-03, -8.4808e-03,  8.7012e-03,  6.6139e-03,
         2.0164e-03, -6.9743e-03,  1.1652e-03, -6.4233e-03, -1.0036e-02,
         2.6624e-03,  1.1185e-02, -1.4017e-02,  5.6040e-03, -3.5659e-03,
         6.8037e-05,  1.4307e-02, -1.0622e-02,  7.6148e-03, -1.4485e-02,
         8.4064e-03,  7.4291e-03,  2.7892e-03,  9.3011e-03, -1.4692e-02,
         1.3840e-02,  7.4146e-03, -8.3523e-03,  1.2465e-02,  2.5261e-03,
         8.9880e-03,  3.0049e-03, -1.1334e-02, -1.1896e-04,  1.4496e-02,
        -1.3823e-02,  1.4129e-02, -2.3765e-03, -1.2218e-02, -1.0470e-02,
        -8.1351e-04, -5.9802e-04, -1.0836e-02, -8.1750e-03, -6.6043e-03,
         1.2210e-02,  7.0937e-03,  7.1958e-03, -1.3723e-02, -6.3452e-03,
         5.5724e-04,  1.1566e-02,  6.6610e-06,  1.0884e-02,  3.6637e-04,
        -1.0525e-02,  1.8112e-03, -1.1862e-02,  4.2657e-03, -2.1045e-03,
        -2.6255e-03, -1.8016e-03,  1.1449e-02, -1.2597e-03,  1.0001e-02,
         1.0840e-02,  1.0518e-02,  5.7567e-03,  9.5915e-03,  3.5507e-03,
        -3.5990e-03,  3.8062e-03,  1.3664e-02, -4.5433e-03,  1.3132e-02,
         1.0272e-02, -3.9286e-04, -9.1953e-03, -1.3200e-02,  1.1987e-02,
         7.1521e-03, -1.0913e-02, -2.0232e-04, -1.2417e-02, -8.7393e-04,
         1.4606e-02,  2.4465e-03, -1.4302e-02,  4.7216e-03, -1.2243e-02,
         1.4284e-04,  8.0007e-03, -1.2006e-02,  1.1035e-02,  1.1525e-02,
        -9.5058e-03, -5.2334e-03, -1.0612e-02, -6.5808e-03, -1.3811e-02,
        -1.4482e-02,  9.3124e-04, -8.0447e-03,  3.8964e-03, -8.7695e-03,
         4.1327e-03,  1.2129e-02,  1.2600e-02, -7.2126e-03, -1.1765e-02,
         6.0243e-03,  9.1632e-03, -1.4189e-02,  1.0613e-02,  3.3068e-03,
         1.4436e-02,  1.3756e-02, -7.0357e-03, -1.2769e-02, -1.1481e-02,
        -7.4456e-04, -7.1079e-03,  1.0115e-02,  1.1067e-02, -1.8922e-03,
         4.5790e-03,  1.0858e-02, -1.2564e-02, -8.6278e-03,  9.1511e-03,
         3.1450e-03, -5.4936e-03, -7.4592e-03, -8.5916e-03,  1.0887e-02,
        -2.3791e-03, -4.9216e-03, -1.1803e-02,  1.9456e-03,  5.6690e-03,
        -4.2183e-03, -6.8672e-03,  1.1088e-02, -8.9417e-04,  1.0552e-02,
         9.5904e-03,  2.6228e-03,  5.1689e-03,  2.6225e-03,  5.9762e-03,
        -3.3825e-03, -1.4406e-03, -7.1429e-04, -2.1661e-03, -3.0864e-03,
        -8.3340e-03,  1.3868e-02, -1.3250e-02, -9.5446e-03,  8.6211e-03,
        -1.0327e-02, -1.0755e-02, -1.7147e-03,  1.2109e-02, -5.5725e-03,
        -1.5689e-03,  4.0464e-03,  1.2448e-02, -3.2333e-03,  8.4848e-03,
        -6.1111e-03, -1.3211e-02,  8.7045e-03, -2.9194e-03, -7.2202e-03,
        -1.8216e-05,  9.1478e-03,  9.2574e-03,  1.1044e-02, -1.7435e-03,
        -7.4207e-03, -1.5328e-03,  9.9255e-04,  6.4462e-03, -3.9413e-03,
         1.2921e-02, -1.2045e-02,  1.3191e-03,  1.1054e-02,  1.9953e-03,
         4.4203e-03,  1.1161e-02, -3.7114e-03,  9.4313e-03,  6.0096e-03,
        -4.7130e-03,  9.5570e-03,  2.1422e-04, -1.1776e-02, -1.4215e-02,
        -3.5591e-03,  7.0798e-03, -8.3804e-03, -5.6350e-03, -8.3653e-03,
        -8.8921e-03,  3.4693e-03, -7.1598e-03, -1.0736e-03,  1.3031e-02,
        -2.8534e-03, -2.5295e-05,  1.1966e-02,  1.4409e-02,  1.1035e-02,
         1.3240e-02, -1.4152e-02, -1.3978e-02, -1.1122e-02,  2.7016e-03,
         4.0260e-03, -1.0838e-02, -7.2401e-03,  6.9735e-03,  6.6041e-03,
        -8.8602e-03, -1.1009e-02,  1.8362e-03,  9.8953e-03,  1.4448e-02,
        -1.8065e-03,  3.0818e-03,  5.0893e-03,  9.7008e-03, -1.2038e-03,
         4.3759e-03,  6.4370e-03,  1.0381e-02,  5.2989e-03,  2.8699e-03,
        -1.1132e-02,  4.8055e-03,  4.9762e-03, -1.4620e-02,  9.9586e-03,
        -6.3044e-04, -7.8294e-03, -2.1475e-03,  5.0062e-03, -6.4232e-05,
        -1.3705e-02, -8.7139e-03, -1.0923e-02,  2.5588e-03,  4.2452e-03,
        -1.0629e-02, -5.9099e-04,  2.6385e-03,  4.8395e-03,  7.4478e-04,
        -1.4359e-02,  2.3394e-03,  1.2643e-02, -4.2680e-03, -8.8749e-04,
        -1.1603e-02, -7.1266e-03,  5.6062e-03, -5.4592e-03, -8.3183e-03,
         9.8782e-03,  7.0320e-03,  1.2558e-02, -1.0245e-02, -4.7664e-03,
         1.1507e-02,  4.0114e-03], device='cuda:0', requires_grad=True)

conv_net.9.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[-0.0108, -0.0104,  0.0056],
          [-0.0049, -0.0037,  0.0092],
          [ 0.0122,  0.0141,  0.0060]],

         [[-0.0013,  0.0036, -0.0046],
          [-0.0066, -0.0138,  0.0062],
          [ 0.0030,  0.0086, -0.0043]],

         [[-0.0051,  0.0013,  0.0101],
          [-0.0126,  0.0018, -0.0122],
          [-0.0104,  0.0023, -0.0053]],

         ...,

         [[ 0.0078,  0.0121,  0.0103],
          [-0.0061,  0.0037, -0.0056],
          [-0.0124,  0.0140,  0.0091]],

         [[-0.0067, -0.0045,  0.0078],
          [ 0.0068,  0.0100,  0.0140],
          [ 0.0142, -0.0003, -0.0138]],

         [[ 0.0060,  0.0108,  0.0066],
          [ 0.0062, -0.0104, -0.0026],
          [-0.0128, -0.0052,  0.0031]]],


        [[[-0.0010, -0.0144,  0.0026],
          [ 0.0020,  0.0117, -0.0029],
          [-0.0083,  0.0010, -0.0018]],

         [[ 0.0135, -0.0110, -0.0111],
          [-0.0146, -0.0018,  0.0068],
          [-0.0048,  0.0019, -0.0019]],

         [[-0.0029,  0.0051, -0.0126],
          [-0.0004, -0.0028,  0.0062],
          [-0.0099, -0.0132, -0.0073]],

         ...,

         [[ 0.0113,  0.0070, -0.0136],
          [ 0.0032,  0.0089, -0.0044],
          [-0.0043,  0.0093,  0.0024]],

         [[-0.0109,  0.0142,  0.0052],
          [-0.0084, -0.0062,  0.0032],
          [-0.0090, -0.0076,  0.0070]],

         [[-0.0015, -0.0110,  0.0013],
          [-0.0109,  0.0077,  0.0017],
          [-0.0029,  0.0033, -0.0036]]],


        [[[-0.0145,  0.0035,  0.0060],
          [ 0.0057,  0.0067, -0.0126],
          [ 0.0059, -0.0087,  0.0073]],

         [[-0.0137, -0.0135, -0.0023],
          [ 0.0034,  0.0100,  0.0055],
          [-0.0039,  0.0045,  0.0046]],

         [[ 0.0024,  0.0068,  0.0106],
          [ 0.0118,  0.0074,  0.0039],
          [ 0.0074,  0.0055, -0.0008]],

         ...,

         [[-0.0103,  0.0083,  0.0142],
          [-0.0101, -0.0029,  0.0085],
          [ 0.0020,  0.0076, -0.0066]],

         [[-0.0028, -0.0007,  0.0136],
          [-0.0071, -0.0141,  0.0047],
          [ 0.0114,  0.0071,  0.0028]],

         [[ 0.0120,  0.0036,  0.0037],
          [-0.0091, -0.0048,  0.0137],
          [ 0.0071, -0.0096, -0.0138]]],


        ...,


        [[[ 0.0121,  0.0057, -0.0083],
          [ 0.0024,  0.0142, -0.0090],
          [ 0.0019, -0.0049, -0.0099]],

         [[ 0.0087, -0.0012,  0.0053],
          [-0.0121, -0.0104,  0.0041],
          [-0.0087, -0.0102, -0.0014]],

         [[ 0.0065, -0.0015, -0.0057],
          [-0.0113,  0.0084, -0.0015],
          [-0.0003, -0.0027, -0.0042]],

         ...,

         [[ 0.0143, -0.0083,  0.0078],
          [-0.0037,  0.0016,  0.0002],
          [ 0.0011, -0.0037,  0.0001]],

         [[-0.0133,  0.0039, -0.0054],
          [ 0.0079, -0.0101,  0.0084],
          [ 0.0064, -0.0072,  0.0078]],

         [[ 0.0084, -0.0127, -0.0129],
          [ 0.0024,  0.0138,  0.0007],
          [ 0.0146, -0.0120, -0.0025]]],


        [[[-0.0101, -0.0104, -0.0077],
          [ 0.0078, -0.0052, -0.0041],
          [ 0.0087,  0.0135,  0.0062]],

         [[-0.0118,  0.0116,  0.0017],
          [-0.0007,  0.0086, -0.0090],
          [ 0.0113,  0.0014, -0.0115]],

         [[ 0.0053, -0.0061, -0.0118],
          [ 0.0070, -0.0144,  0.0007],
          [ 0.0095, -0.0091, -0.0022]],

         ...,

         [[ 0.0016, -0.0105, -0.0022],
          [ 0.0097, -0.0037, -0.0139],
          [ 0.0087, -0.0059, -0.0138]],

         [[ 0.0132, -0.0006,  0.0068],
          [ 0.0140,  0.0030, -0.0114],
          [ 0.0078,  0.0065,  0.0054]],

         [[-0.0018,  0.0111, -0.0118],
          [ 0.0045,  0.0129,  0.0055],
          [-0.0112,  0.0011,  0.0143]]],


        [[[-0.0030, -0.0060, -0.0084],
          [-0.0066,  0.0076,  0.0120],
          [ 0.0109, -0.0143,  0.0037]],

         [[ 0.0096,  0.0047,  0.0111],
          [-0.0060,  0.0080,  0.0069],
          [-0.0108,  0.0103,  0.0060]],

         [[ 0.0089, -0.0058,  0.0027],
          [ 0.0030, -0.0106,  0.0139],
          [-0.0003, -0.0017,  0.0144]],

         ...,

         [[-0.0111,  0.0095,  0.0108],
          [-0.0011, -0.0031, -0.0010],
          [-0.0092,  0.0001, -0.0087]],

         [[-0.0067,  0.0090, -0.0090],
          [-0.0116,  0.0043, -0.0132],
          [ 0.0092, -0.0079, -0.0147]],

         [[-0.0133, -0.0041, -0.0017],
          [-0.0080, -0.0084, -0.0120],
          [ 0.0002, -0.0092,  0.0065]]]], device='cuda:0', requires_grad=True)

conv_net.9.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([ 1.0766e-02,  8.9644e-03, -8.8631e-04, -1.0460e-04, -1.4485e-02,
        -9.2508e-03,  7.1782e-03,  1.1916e-02, -5.5566e-03,  1.1403e-02,
        -1.1247e-03,  1.0301e-02, -8.4840e-03, -1.2036e-02, -1.4254e-02,
        -1.5380e-03,  9.0077e-03, -7.2274e-03,  7.2532e-03, -3.6991e-03,
        -1.2806e-02, -4.1456e-03,  6.4659e-03,  6.7871e-03, -4.8746e-03,
         3.1018e-03, -8.0236e-03, -2.9771e-03, -8.0466e-03,  1.4627e-02,
        -6.9461e-03,  3.5478e-03, -1.3272e-04, -1.6744e-03,  1.3863e-02,
         4.0659e-03, -7.2027e-03,  2.8098e-03, -1.4433e-02, -1.4525e-02,
         7.4640e-04,  7.7890e-03, -1.1739e-02,  8.7490e-03, -8.6022e-03,
         1.1326e-02, -1.1484e-02,  8.3509e-04,  1.0832e-02, -6.3111e-04,
        -2.1304e-03,  1.0298e-02, -5.7439e-03,  2.4329e-03,  1.4590e-02,
        -3.8336e-03,  1.1812e-03, -1.0950e-02, -1.2337e-02,  1.4543e-02,
        -1.1666e-02,  1.0513e-02,  1.3608e-03,  1.2139e-02,  6.6271e-03,
        -6.9398e-03, -2.6276e-03,  8.7385e-04,  7.3111e-03, -9.1688e-03,
        -1.2213e-02,  1.4461e-02, -9.0282e-03,  9.4180e-03,  9.7315e-03,
         7.6163e-03, -8.6822e-03,  7.5509e-03,  1.0950e-02,  6.2268e-03,
        -3.2440e-03,  2.9795e-04,  9.8977e-03, -9.8677e-03, -9.9209e-04,
        -7.6497e-03,  3.1086e-03,  7.2430e-03,  1.3605e-02, -1.4138e-02,
         8.2045e-03,  9.7723e-03,  1.4414e-02, -6.1150e-03,  1.3260e-03,
         1.4039e-02,  5.6839e-03,  2.1152e-03, -3.0225e-03,  4.1982e-03,
        -1.8470e-03,  1.0244e-02, -6.0026e-03, -1.2793e-02,  1.3831e-02,
         1.3365e-02,  1.2407e-04,  1.4475e-02, -2.3053e-03,  1.0891e-02,
        -9.9957e-03,  1.1202e-02, -1.0597e-03, -7.0912e-03, -9.5264e-03,
        -7.2495e-03,  3.6922e-03,  1.0511e-02, -1.4230e-02, -3.6401e-03,
        -2.0647e-03, -4.0009e-03,  1.3177e-02,  9.1595e-03, -1.1954e-03,
         1.3863e-02, -5.6922e-03,  4.1828e-03,  1.2319e-02, -1.0720e-02,
         3.7857e-03, -3.6892e-03,  1.4679e-02, -3.9438e-03,  8.3894e-03,
         1.4539e-02,  1.1397e-02, -4.2776e-03, -8.3092e-03,  1.8672e-03,
         6.2843e-03,  7.3752e-03,  2.3151e-04, -1.2353e-02,  6.5402e-03,
         5.8811e-03,  7.9397e-03,  2.8453e-03, -1.1498e-02,  1.2470e-03,
         9.4299e-03, -4.4155e-04, -5.0971e-03, -1.3376e-02,  3.7851e-03,
         9.2384e-04, -7.9632e-03,  8.2323e-03,  8.9544e-03, -3.7431e-03,
         3.2902e-03,  8.4836e-04, -3.1676e-03,  1.2071e-02, -1.9310e-03,
        -9.2804e-03,  7.0898e-03, -1.4076e-03,  1.1760e-03, -1.4307e-02,
        -3.4782e-03,  2.1091e-03,  1.3391e-02, -1.7199e-03,  1.6796e-03,
        -4.1841e-04,  6.4698e-03, -1.2519e-02, -2.8093e-03,  9.1754e-03,
        -1.4642e-02,  1.2173e-02,  1.3008e-02,  7.2786e-04,  8.7496e-03,
         1.4130e-02,  2.1881e-03,  3.0049e-03, -5.2116e-03, -9.9224e-03,
         2.5299e-03, -9.7832e-03, -1.3040e-02, -7.5658e-03, -4.5014e-03,
        -5.9834e-04, -4.4664e-03,  2.0559e-03,  3.6004e-03, -5.8202e-03,
         2.6191e-03,  4.2632e-03, -1.2611e-02,  6.2108e-03, -1.0492e-02,
         5.5000e-03, -2.5428e-03,  7.9103e-03, -1.1426e-02, -3.6569e-03,
         5.0756e-03, -7.0369e-03, -1.0078e-02, -1.3196e-02, -1.0895e-02,
         6.1951e-04,  1.2419e-02,  4.4796e-03, -1.0117e-02, -2.5060e-03,
        -9.2876e-03,  1.0685e-02, -1.6561e-03,  1.1041e-03,  1.4706e-02,
         9.1025e-03,  1.0676e-02, -2.5340e-03,  1.4715e-03, -1.4019e-03,
         8.4260e-03, -1.8051e-03,  5.2743e-03,  2.7729e-03, -6.2957e-03,
        -1.2357e-03,  1.2216e-02,  1.4630e-02,  5.5222e-03,  1.0124e-03,
        -1.5446e-03,  1.2103e-02, -6.4724e-03,  6.6778e-03,  1.2682e-02,
        -6.9471e-03,  1.3360e-02, -4.3258e-03,  7.8245e-03,  1.0966e-03,
        -9.5062e-04, -1.1640e-02,  9.0748e-03, -1.8693e-03,  6.7485e-03,
        -1.1841e-02,  1.2469e-02,  9.5624e-03, -6.7401e-03, -7.0216e-03,
        -6.7259e-03,  3.6973e-03, -6.1001e-03, -6.2768e-03,  7.6601e-03,
        -6.5562e-03,  1.1382e-02,  9.5746e-03, -1.0599e-02, -1.0952e-02,
        -8.1266e-04, -5.7983e-03,  9.5834e-03,  3.6928e-04, -9.6012e-04,
        -3.3468e-03,  1.4227e-02, -1.2871e-02,  1.0720e-02, -9.5997e-03,
         1.3893e-02,  3.5280e-03,  7.5652e-03,  2.6235e-03, -3.2448e-03,
         1.3966e-02, -6.2471e-03, -1.2659e-02, -6.6544e-03,  1.1857e-02,
         3.6027e-03,  1.7244e-03, -1.3443e-02,  8.7295e-03, -1.3303e-02,
         1.3096e-02,  1.1976e-02, -8.3025e-03,  9.9395e-04,  1.4301e-02,
         6.2495e-03, -1.0807e-02, -9.1991e-03, -1.8952e-03,  1.0544e-02,
         1.3850e-02,  1.3527e-02, -1.2225e-02, -3.3167e-04,  1.0579e-02,
         9.6593e-03,  1.0942e-02, -8.0910e-03,  9.7077e-03, -1.3366e-02,
        -4.9491e-03, -1.1865e-02, -9.8537e-03, -1.1637e-02, -9.3133e-03,
         8.9666e-03,  3.4593e-03, -3.7931e-03,  1.4981e-03, -9.1736e-03,
        -4.0162e-03,  7.4693e-03,  4.7230e-03, -2.8296e-03,  1.2818e-03,
        -6.0145e-03, -1.4160e-02, -3.7852e-03,  1.0876e-02, -8.1528e-03,
         4.6501e-03, -8.2296e-03,  3.4334e-04,  6.9678e-03,  1.4049e-02,
        -1.0781e-03,  1.1778e-04, -2.0705e-03,  1.2336e-03, -1.2860e-02,
        -1.2678e-02, -7.0371e-03,  1.0851e-02,  1.1009e-02,  1.6954e-03,
         9.7327e-03,  1.3567e-02,  6.6039e-03,  7.0001e-03,  1.0852e-02,
        -2.7769e-03,  1.2790e-02,  8.7393e-04,  1.3195e-02, -1.0217e-02,
        -3.3288e-03, -1.3448e-02, -5.0590e-03, -1.4221e-02,  5.2672e-03,
        -1.3897e-02, -1.1427e-02,  4.7053e-03, -3.8762e-03,  8.1776e-04,
         1.3028e-02, -2.6224e-03,  7.8242e-03,  1.1396e-02,  1.2474e-02,
        -6.4570e-03,  1.0297e-02, -5.8836e-03, -9.0503e-03, -4.2897e-03,
        -2.3741e-03, -9.0966e-03,  1.3021e-02,  1.4010e-02, -2.6920e-05,
        -4.5145e-03, -7.7854e-03, -1.4200e-02,  1.4427e-02, -5.8635e-03,
        -4.9412e-05, -5.9846e-03,  1.6404e-03, -8.6780e-04, -8.1947e-04,
         6.4941e-03, -9.3636e-03, -4.6746e-03,  1.2005e-02,  1.0276e-02,
         7.7962e-03, -1.0188e-02, -5.2698e-03, -1.4374e-02, -7.9778e-03,
        -1.0867e-02,  1.4296e-02, -1.2147e-02, -3.2305e-03, -1.2944e-02,
         6.1524e-04,  7.7060e-03,  7.7611e-03,  1.4248e-02, -2.7150e-03,
        -2.1878e-03, -1.3244e-02,  1.1620e-02,  7.1757e-03,  5.6281e-03,
         6.3361e-03, -5.5229e-03,  9.8313e-03,  2.8543e-03,  1.2662e-02,
        -6.8486e-03,  7.8680e-04, -6.3044e-03, -9.5533e-03,  1.3167e-02,
        -1.2971e-02, -1.0366e-02, -1.0307e-02,  6.2202e-03, -9.1638e-03,
        -2.7883e-04, -9.5817e-03, -9.4646e-03,  1.0709e-02, -5.8020e-03,
         6.0499e-04, -9.7378e-03, -1.0646e-02,  1.3458e-03,  6.3376e-03,
         1.9526e-03,  7.1795e-05,  1.4025e-02, -1.4042e-02, -4.3795e-03,
        -2.3316e-03,  7.7665e-03,  8.5436e-03, -1.1091e-02,  2.7914e-04,
        -7.0549e-03,  5.5681e-03, -9.6540e-04,  3.3036e-03, -3.8023e-03,
         7.7844e-03, -1.1948e-02, -1.0843e-02,  5.6907e-03, -7.5148e-03,
        -1.0853e-02, -6.7217e-03, -3.1525e-03, -6.8711e-03,  6.1553e-03,
         6.0835e-03, -1.0575e-02, -3.3254e-03,  1.3075e-02, -1.3905e-02,
         1.2138e-02, -5.3107e-03, -1.4512e-02, -4.9741e-03,  6.5508e-03,
         1.0619e-02,  7.6286e-03, -3.0213e-03, -1.3642e-02, -6.8713e-03,
        -5.2241e-03, -9.4428e-03,  5.5549e-03, -6.4302e-03, -1.5002e-03,
         7.4132e-03,  2.0389e-03,  3.0854e-03, -1.2115e-02,  9.2131e-03,
         4.7526e-03,  7.1968e-03,  7.1270e-03,  5.7264e-03,  8.0095e-03,
        -1.2596e-02, -2.8086e-03, -6.3022e-03, -6.2002e-03, -3.3056e-03,
         4.7192e-04, -1.1501e-02,  1.6069e-03,  8.4517e-04,  1.0324e-02,
         3.9278e-03, -6.4218e-04], device='cuda:0', requires_grad=True)

conv_net.12.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[ 1.3787e-02,  6.5100e-03,  8.0390e-03],
          [-1.4476e-02, -2.5136e-03,  6.9569e-04],
          [ 9.3818e-04,  5.4718e-03, -4.0922e-03]],

         [[-1.0977e-02, -1.2421e-02,  8.6218e-03],
          [ 5.0761e-03, -3.9178e-03,  6.3810e-03],
          [-1.2283e-02, -7.1274e-03, -1.4586e-02]],

         [[ 1.3827e-02, -1.6019e-03,  1.0872e-02],
          [-1.9994e-03, -1.3595e-02, -3.5508e-03],
          [ 5.8261e-03,  5.2196e-04,  6.8042e-03]],

         ...,

         [[ 1.0556e-02, -7.7385e-03,  3.7972e-03],
          [-8.7786e-03,  5.0196e-03, -6.8060e-03],
          [-1.2480e-02,  7.7741e-03, -1.0539e-02]],

         [[ 3.4640e-04, -8.1134e-03,  5.5310e-03],
          [-8.4084e-03, -1.4859e-03, -1.2315e-03],
          [ 1.2802e-02,  1.9998e-03,  8.3298e-03]],

         [[ 1.2590e-03, -1.3285e-02, -2.6984e-03],
          [-1.6028e-03, -6.6802e-03, -1.0889e-02],
          [-6.1515e-03,  5.2038e-03, -7.9814e-04]]],


        [[[-5.5910e-03,  9.4144e-04,  5.2212e-03],
          [-1.0415e-04,  9.7352e-03, -8.4110e-03],
          [ 6.9645e-03, -1.3343e-02, -8.2118e-04]],

         [[ 8.3736e-03,  1.1288e-02,  1.6288e-03],
          [-1.2405e-02, -4.4087e-03,  8.4003e-03],
          [-1.2243e-02,  7.5795e-04,  1.1069e-03]],

         [[ 1.0577e-02,  5.4451e-03, -5.2555e-03],
          [-8.4474e-04,  3.6357e-03,  1.4478e-02],
          [-2.6146e-04, -3.3431e-03, -1.2018e-03]],

         ...,

         [[-6.4798e-03,  1.9802e-04, -7.9164e-05],
          [ 9.4417e-03,  1.1536e-02,  1.1631e-02],
          [-8.6863e-03, -9.3402e-03,  5.1199e-04]],

         [[ 1.1964e-02,  2.1130e-03, -1.1473e-02],
          [-8.2652e-04, -1.0860e-02, -2.6634e-03],
          [-1.3375e-02,  1.0684e-02,  3.1280e-03]],

         [[ 5.8232e-03,  5.5041e-03, -7.5329e-04],
          [ 5.7659e-03,  8.4864e-04, -4.4715e-04],
          [ 5.2635e-03,  4.4511e-03, -9.6520e-03]]],


        [[[ 8.7339e-03, -1.0835e-02, -5.8032e-03],
          [ 1.0512e-02, -5.6369e-03, -4.8392e-05],
          [-1.4213e-02,  1.7722e-03, -8.7990e-03]],

         [[-1.4646e-02, -4.9227e-03,  1.0370e-02],
          [-7.2364e-03, -1.3519e-03,  8.5530e-03],
          [-3.7991e-03,  1.1338e-02, -4.4615e-03]],

         [[ 1.0807e-02, -4.0830e-03, -7.0440e-03],
          [-1.2146e-02,  1.3289e-02,  4.4072e-03],
          [ 1.1128e-02,  8.5253e-03,  4.1277e-04]],

         ...,

         [[ 5.2698e-03, -6.9365e-03, -2.3730e-03],
          [-4.8040e-04,  1.1224e-02,  1.0592e-03],
          [ 1.3961e-02, -9.0351e-03, -8.8647e-03]],

         [[-1.0045e-02, -6.5502e-03,  7.5493e-03],
          [-1.3754e-02, -3.5177e-03,  8.3216e-03],
          [-1.1084e-02, -1.2532e-02, -7.4400e-03]],

         [[-1.1183e-02,  7.8092e-03, -2.0836e-04],
          [ 6.3001e-03, -4.2850e-03, -3.5888e-04],
          [-4.7749e-03,  4.3742e-03, -3.0955e-03]]],


        ...,


        [[[-1.1200e-02, -7.0939e-04, -1.3018e-02],
          [-1.1046e-02,  1.1103e-02, -1.4385e-02],
          [-5.9527e-03, -3.0538e-03, -2.8918e-03]],

         [[-2.3877e-03, -3.3316e-03,  6.2888e-03],
          [-1.3953e-02,  2.0458e-03, -2.3586e-03],
          [ 1.3645e-02, -3.5453e-03,  1.4380e-02]],

         [[-1.4526e-02, -1.2848e-02, -4.5127e-03],
          [-1.3546e-02, -4.6888e-03,  9.2261e-03],
          [-5.2061e-04,  4.4406e-03,  5.4221e-03]],

         ...,

         [[-1.3180e-03, -4.1168e-03,  6.9148e-03],
          [-1.2503e-02,  2.1990e-03, -7.5142e-03],
          [-1.0686e-02,  8.5482e-03, -2.5028e-03]],

         [[-1.3929e-02,  5.9959e-03,  8.0486e-03],
          [ 1.3863e-02,  2.6138e-03, -1.2670e-02],
          [-5.0986e-03,  1.5286e-03, -7.8632e-03]],

         [[-7.7436e-03, -1.0380e-02, -1.1028e-02],
          [ 6.3415e-04, -8.1602e-03,  6.7237e-03],
          [-1.6635e-03,  5.5449e-03, -2.4813e-04]]],


        [[[ 1.4495e-02,  1.1812e-02, -1.2992e-02],
          [-9.4969e-03, -1.4379e-02,  1.0822e-02],
          [-2.6160e-03, -1.1830e-03,  7.0147e-04]],

         [[-1.3576e-02, -1.3207e-02, -1.1774e-02],
          [-6.5198e-03,  2.7258e-03,  5.0678e-03],
          [ 3.0073e-03,  3.6255e-03, -5.7630e-03]],

         [[ 1.0228e-02,  7.1310e-03, -9.3827e-03],
          [ 9.4634e-03,  1.2349e-02,  1.6186e-03],
          [-1.2930e-02, -7.6580e-03,  1.2972e-02]],

         ...,

         [[ 1.1521e-02, -1.2154e-02,  1.0905e-02],
          [ 1.1579e-02,  8.7283e-03, -9.9134e-03],
          [-1.1776e-02, -1.1345e-02,  1.4041e-02]],

         [[ 4.9603e-03, -4.5513e-03, -1.6749e-03],
          [-3.9386e-03, -1.3055e-02, -1.3412e-02],
          [-9.0276e-03,  1.3124e-02, -1.0029e-02]],

         [[-1.3715e-02,  1.4137e-02,  2.3474e-03],
          [ 1.1943e-02, -6.7474e-04,  6.7189e-03],
          [ 4.6486e-03, -5.8180e-03,  1.3540e-02]]],


        [[[-4.2485e-03, -1.9378e-03,  1.8056e-03],
          [-2.9572e-03, -1.1372e-02, -1.3763e-02],
          [-8.6370e-03,  1.4259e-02, -4.5131e-03]],

         [[ 4.4157e-03,  7.1535e-03,  6.4608e-04],
          [ 5.5947e-03, -7.2457e-03,  9.3423e-03],
          [-1.2732e-02,  4.3470e-03,  1.0367e-02]],

         [[-2.2557e-03,  2.3276e-03, -5.3881e-03],
          [-4.9265e-03,  6.6717e-04, -7.2338e-03],
          [ 9.2875e-03,  1.3766e-02, -7.6929e-03]],

         ...,

         [[-1.2748e-02,  3.8143e-03,  3.7870e-03],
          [ 7.9183e-03, -1.9496e-03, -4.8572e-03],
          [-1.4343e-02,  1.8837e-03, -7.6571e-03]],

         [[ 8.8518e-03,  3.3538e-03,  1.5961e-03],
          [-3.5292e-03, -1.0366e-02,  8.1738e-03],
          [-1.4170e-02, -9.7549e-04, -9.5676e-03]],

         [[ 2.2557e-03,  7.3798e-03,  5.8760e-04],
          [ 4.8215e-03,  1.3390e-02,  1.2014e-02],
          [ 4.5965e-04, -8.6045e-03, -7.9347e-03]]]], device='cuda:0',
       requires_grad=True)

conv_net.12.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([-5.7307e-03, -3.2551e-03,  3.3407e-03,  1.1690e-02,  1.0105e-02,
        -8.9203e-03,  1.2819e-02,  1.3100e-02,  5.3362e-03, -5.6882e-03,
         8.1624e-03, -1.4444e-02, -1.4215e-02,  7.4960e-04, -1.2825e-02,
         5.2857e-03, -4.8812e-03, -2.1224e-03, -8.2251e-03,  7.7292e-03,
         5.3451e-03, -1.0641e-02, -1.9962e-03, -7.5662e-03,  2.8177e-03,
         1.2167e-02,  1.1840e-02, -1.0808e-02,  7.3170e-03, -5.8046e-04,
         1.2240e-02, -1.0293e-02, -9.6208e-03,  1.0457e-02, -1.4724e-02,
        -1.4475e-02, -6.0077e-03,  7.4794e-03,  2.7860e-03, -1.6042e-03,
         3.9763e-04, -6.8443e-03,  1.4684e-02, -9.8392e-03, -1.2470e-03,
        -3.8861e-03, -1.0226e-02,  3.3006e-03, -1.0628e-02,  1.3523e-02,
        -1.1423e-02,  1.1631e-02,  2.5006e-03, -3.2681e-03,  1.3456e-02,
         1.1154e-02, -1.0448e-02,  3.0612e-03, -9.5059e-03, -1.0337e-02,
         1.3734e-02,  2.9667e-03, -1.3354e-03,  1.9235e-03,  2.0686e-03,
         5.5368e-04, -1.1044e-02, -3.5536e-03, -4.9250e-03, -1.3242e-02,
        -5.7192e-03, -7.2078e-03,  3.3263e-03,  8.9491e-03,  3.1121e-03,
        -4.9844e-03, -8.5532e-03, -7.8180e-03, -2.5851e-03,  7.8628e-03,
         1.9573e-03,  1.2649e-02,  1.1257e-02,  2.1521e-03,  6.0684e-03,
        -8.3225e-03, -8.4340e-04,  1.3149e-03,  1.3170e-02, -2.5083e-04,
         5.1600e-03, -1.4701e-02, -5.0680e-03, -4.1071e-03, -1.3177e-02,
         4.4585e-03,  1.3266e-02,  8.7085e-04,  9.5575e-03, -8.9219e-03,
        -3.5837e-05, -9.4128e-06, -8.0470e-03,  3.8981e-03, -5.6065e-03,
        -6.6498e-03, -4.1963e-03, -1.0294e-02,  3.9764e-03,  8.3265e-03,
         6.9427e-03, -1.3450e-02,  3.3235e-03, -6.8538e-04,  2.8491e-04,
         2.5169e-03, -6.9878e-03,  1.0003e-02, -8.7679e-04, -7.0689e-03,
         1.1567e-02, -1.3786e-02, -9.6477e-03,  4.7144e-03,  9.0115e-04,
         1.1160e-02, -5.2327e-03,  2.7331e-03,  1.2157e-02,  2.2047e-03,
         1.5214e-03,  5.4084e-03, -4.1881e-03, -1.0421e-02,  9.5517e-03,
         9.1304e-03, -1.4203e-02,  1.4000e-03, -3.0988e-03, -1.0477e-02,
        -1.7854e-03, -5.5400e-03,  1.3673e-02,  4.8159e-03,  9.4245e-03,
        -5.3624e-03, -5.9338e-03, -3.5881e-03,  1.1619e-02, -8.0043e-03,
         3.9698e-03, -3.0381e-04, -1.4637e-02, -1.1133e-02, -1.1885e-02,
         1.3868e-02,  5.4558e-03,  9.3385e-04, -7.9727e-04,  3.2709e-03,
         1.4356e-03, -1.3856e-02, -1.1479e-02, -7.6154e-03, -1.1944e-02,
         1.1427e-02, -4.3135e-03,  1.2825e-02, -5.2818e-03,  9.3181e-03,
        -1.3635e-02,  9.8584e-03, -7.5432e-04,  8.8013e-03,  1.1478e-02,
        -5.4789e-03, -7.4495e-03,  4.0280e-04, -1.3765e-03,  6.3624e-03,
         1.1287e-03, -1.0630e-02, -6.9141e-03,  1.4686e-02,  5.4101e-03,
         3.7336e-03, -1.3303e-02, -2.1373e-03, -8.3244e-03,  1.9266e-03,
         5.4791e-03,  1.2453e-02, -1.2442e-02, -1.4662e-03,  1.3761e-02,
        -1.0219e-03, -1.0764e-03,  2.7107e-03,  3.9678e-04,  4.5581e-03,
         3.6871e-03,  8.0951e-03, -8.3755e-03, -8.2724e-03,  1.1262e-02,
         1.1213e-02,  1.1989e-02, -4.8735e-03, -6.7046e-03, -3.5199e-03,
        -8.5222e-04,  5.6924e-03,  1.2939e-02,  4.1946e-03,  1.0942e-04,
         4.5385e-03, -1.4625e-02,  1.2527e-02,  4.2212e-04,  1.1842e-02,
         1.3189e-02,  1.3684e-02,  1.8246e-03, -5.5273e-03, -1.0553e-02,
         6.1986e-03,  4.5238e-04,  1.2929e-02,  1.0806e-03,  4.3510e-03,
         1.4393e-02,  5.7397e-03,  5.0362e-03, -1.4055e-02,  1.0141e-02,
         1.0377e-02, -5.5686e-04, -9.5682e-03, -4.9828e-03,  4.7795e-03,
         8.8254e-03,  1.3324e-03,  4.1270e-03, -4.5178e-03, -1.6798e-03,
        -3.8525e-03, -7.4024e-03, -1.4664e-02,  8.9252e-03, -3.0615e-03,
         1.4291e-02,  3.2478e-03, -1.2646e-03, -1.4650e-02,  7.2922e-03,
        -1.0602e-02,  1.1709e-02,  1.2214e-02,  7.4804e-03, -3.5544e-03,
        -1.0891e-03,  2.3869e-03, -3.8552e-03, -1.1368e-02, -7.2002e-03,
         1.1333e-03, -5.7851e-03, -1.1443e-02,  9.2342e-04,  1.0900e-02,
         9.5502e-03,  1.0284e-02, -1.3186e-02, -1.8594e-03, -3.4906e-03,
        -1.1079e-02,  8.2621e-03, -1.4217e-02, -1.0290e-02,  1.2164e-02,
        -4.7935e-04,  4.5920e-04,  3.3343e-03, -1.4076e-02,  4.6116e-03,
         5.5882e-03, -5.3802e-03, -2.5020e-03,  4.3927e-03, -9.6612e-03,
        -1.3787e-02,  9.7346e-03, -1.2674e-02, -1.1923e-02, -1.3579e-03,
         1.1350e-03,  8.6673e-03, -3.4024e-03,  8.0154e-03,  4.2177e-03,
         2.9906e-04,  5.4229e-03, -1.0031e-02,  1.1391e-02,  6.8182e-04,
         5.4115e-04, -2.3713e-03,  1.1639e-02,  1.0813e-03,  5.7073e-03,
         1.4505e-02, -1.3102e-02,  9.0262e-04,  1.2535e-02,  3.2727e-03,
        -5.4145e-03, -1.8985e-03,  1.2644e-02,  1.3708e-02, -2.4895e-03,
        -7.1614e-03, -9.3255e-03, -1.3177e-02, -6.3051e-03, -4.3552e-03,
         1.3616e-02,  1.0301e-02,  1.1284e-02, -4.3194e-03,  1.0736e-02,
        -1.0636e-02, -9.0509e-03, -1.2072e-02,  5.0485e-03,  1.1725e-03,
        -1.7381e-03, -1.1966e-02, -1.2501e-02, -5.7654e-04, -4.4826e-03,
         1.8325e-03,  1.0553e-02,  1.3644e-02, -5.1731e-04, -1.1700e-02,
         1.0559e-02, -3.6183e-03, -1.6991e-03, -3.6291e-03,  7.6387e-03,
        -1.9147e-03, -5.0084e-03,  5.0941e-03,  7.0886e-03,  6.0738e-03,
         6.1597e-03,  4.0974e-03, -1.0343e-03, -3.8355e-03, -5.0920e-03,
         2.3769e-03, -3.4053e-03,  8.6432e-03,  9.4705e-03,  2.5843e-03,
        -9.5850e-03, -1.4138e-02,  1.4598e-02,  1.4672e-02,  1.4476e-02,
         1.1176e-02,  1.4697e-03, -1.0317e-02, -8.1659e-03, -5.1157e-03,
         9.7447e-03,  3.7329e-03, -7.1360e-03,  1.0547e-02, -3.2188e-03,
        -2.9411e-03, -1.2497e-02, -1.8598e-03, -1.3462e-02,  9.4239e-03,
         1.2314e-02, -1.7446e-03, -1.4435e-02,  1.3822e-02, -1.3698e-02,
        -2.4248e-03,  2.7189e-03,  4.2299e-03, -7.6274e-03, -6.6141e-04,
        -8.0165e-03, -8.6672e-03, -7.2755e-03, -5.2281e-03,  4.2436e-03,
        -1.0370e-02,  8.5201e-03,  2.7425e-03,  7.2424e-03, -5.8013e-03,
         8.8488e-03, -3.2563e-03,  5.5497e-03,  1.3046e-02,  1.3793e-02,
         1.2147e-02,  2.2023e-03,  7.0600e-03,  1.3657e-02, -8.1810e-03,
         1.2355e-02, -4.9878e-03, -2.0133e-03,  1.9809e-03, -1.4125e-02,
        -2.8819e-03, -6.4245e-03,  5.4602e-03,  5.5964e-03,  1.3397e-02,
        -7.3480e-03, -1.4618e-02,  9.0115e-03, -1.7144e-04, -1.3837e-02,
         9.2962e-03, -2.2576e-03,  6.6940e-03, -7.3685e-03,  7.8714e-03,
        -1.3559e-03,  1.4436e-02, -1.2364e-02, -1.0546e-02,  3.4903e-03,
        -2.6007e-03, -1.3910e-02,  9.0458e-03, -5.0465e-03, -1.2542e-02,
        -1.3933e-02, -4.5429e-04, -1.3781e-02,  1.3284e-02, -1.0835e-02,
         5.4305e-03,  1.3357e-02, -1.1070e-02,  1.0381e-03, -8.4411e-03,
        -9.0373e-03, -4.2746e-03,  3.1035e-03, -6.2732e-03,  1.7790e-03,
        -1.4680e-02,  2.1766e-04, -1.0960e-02, -2.3907e-03, -3.6862e-03,
         2.3531e-03,  3.9795e-03,  6.2849e-03,  1.2063e-02, -1.7516e-03,
         3.9347e-03, -3.3755e-03,  6.7610e-03, -1.3251e-02, -1.3211e-02,
        -5.2558e-04, -4.8276e-03, -4.3062e-03,  5.2519e-03,  1.2641e-02,
         1.3715e-02,  1.0209e-02,  7.0269e-03,  4.7518e-04,  1.3221e-02,
        -1.0663e-02, -1.0602e-02,  9.9142e-03, -1.1643e-03, -1.2598e-02,
        -1.0656e-02, -1.0962e-02,  9.9645e-03,  1.0922e-02, -6.9131e-05,
         7.8085e-03,  9.1398e-03,  1.6761e-03,  2.2172e-03,  1.4641e-02,
        -1.1219e-02, -5.5365e-05, -7.2454e-03, -1.4709e-02, -1.2613e-02,
        -5.8159e-03, -9.5384e-03, -1.1035e-02, -2.7306e-03,  1.1217e-02,
         9.5307e-04,  1.2435e-02], device='cuda:0', requires_grad=True)

conv_net.16.weight, torch.Size([10, 512]), # params: 5120, Parameter containing:
tensor([[-1.9011e-03,  2.9611e-04, -7.1228e-04,  ...,  4.9003e-04,
         -2.1233e-04,  1.5194e-04],
        [-6.4800e-05, -1.6811e-03, -3.0059e-04,  ..., -1.1015e-03,
         -2.0044e-03,  1.1473e-03],
        [-1.3482e-03,  6.2091e-04, -1.0429e-04,  ...,  1.1547e-04,
         -1.6392e-03, -4.9613e-04],
        ...,
        [-9.4939e-04, -9.8320e-04,  1.2410e-03,  ...,  1.2158e-03,
         -6.2541e-04, -1.1114e-03],
        [ 8.9012e-04, -5.5196e-05, -2.8833e-04,  ..., -1.7057e-03,
         -8.8453e-04,  5.3763e-04],
        [-1.4874e-03,  2.1964e-04, -9.8865e-04,  ..., -2.1733e-03,
          1.3135e-03, -1.7905e-03]], device='cuda:0', requires_grad=True)

conv_net.16.bias, torch.Size([10]), # params: 10, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       requires_grad=True)

Total # params: 7678474

conv_net[0].weight shape: torch.Size([128, 3, 3, 3])
Epoch [1/20], Step [100/245], Loss: 1.8965
Epoch [1/20], Step [200/245], Loss: 1.4923
Validataion accuracy is: 48.6 %
Saving model with best validation accuracy so-far...

Epoch [2/20], Step [100/245], Loss: 1.3145
Epoch [2/20], Step [200/245], Loss: 1.0823
Validataion accuracy is: 60.2 %
Saving model with best validation accuracy so-far...

Epoch [3/20], Step [100/245], Loss: 1.0580
Epoch [3/20], Step [200/245], Loss: 0.9128
Validataion accuracy is: 65.2 %
Saving model with best validation accuracy so-far...

Epoch [4/20], Step [100/245], Loss: 0.7976
Epoch [4/20], Step [200/245], Loss: 0.8049
Validataion accuracy is: 71.9 %
Saving model with best validation accuracy so-far...

Epoch [5/20], Step [100/245], Loss: 0.8397
Epoch [5/20], Step [200/245], Loss: 0.5256
Validataion accuracy is: 73.8 %
Saving model with best validation accuracy so-far...

Epoch [6/20], Step [100/245], Loss: 0.4898
Epoch [6/20], Step [200/245], Loss: 0.6815
Validataion accuracy is: 75.6 %
Saving model with best validation accuracy so-far...

Epoch [7/20], Step [100/245], Loss: 0.6121
Epoch [7/20], Step [200/245], Loss: 0.5990
Validataion accuracy is: 77.6 %
Saving model with best validation accuracy so-far...

Epoch [8/20], Step [100/245], Loss: 0.5514
Epoch [8/20], Step [200/245], Loss: 0.5085
Validataion accuracy is: 76.4 %
Epoch [9/20], Step [100/245], Loss: 0.4875
Epoch [9/20], Step [200/245], Loss: 0.4221
Validataion accuracy is: 78.0 %
Saving model with best validation accuracy so-far...

Epoch [10/20], Step [100/245], Loss: 0.4244
Epoch [10/20], Step [200/245], Loss: 0.4023
Validataion accuracy is: 76.7 %
Epoch [11/20], Step [100/245], Loss: 0.4212
Epoch [11/20], Step [200/245], Loss: 0.4206
Validataion accuracy is: 79.6 %
Saving model with best validation accuracy so-far...

Epoch [12/20], Step [100/245], Loss: 0.4495
Epoch [12/20], Step [200/245], Loss: 0.4602
Validataion accuracy is: 78.4 %
Epoch [13/20], Step [100/245], Loss: 0.3486
Epoch [13/20], Step [200/245], Loss: 0.3579
Validataion accuracy is: 80.0 %
Saving model with best validation accuracy so-far...

Epoch [14/20], Step [100/245], Loss: 0.3494
Epoch [14/20], Step [200/245], Loss: 0.2473
Validataion accuracy is: 79.5 %
Epoch [15/20], Step [100/245], Loss: 0.3613
Epoch [15/20], Step [200/245], Loss: 0.3262
Validataion accuracy is: 79.2 %
Epoch [16/20], Step [100/245], Loss: 0.2485
Epoch [16/20], Step [200/245], Loss: 0.3129
Validataion accuracy is: 79.8 %
Epoch [17/20], Step [100/245], Loss: 0.2049
Epoch [17/20], Step [200/245], Loss: 0.2834
Validataion accuracy is: 78.3 %
Epoch [18/20], Step [100/245], Loss: 0.2346
Epoch [18/20], Step [200/245], Loss: 0.2223
Validataion accuracy is: 78.6 %
Epoch [19/20], Step [100/245], Loss: 0.1362
Epoch [19/20], Step [200/245], Loss: 0.1899
Validataion accuracy is: 79.3 %
Epoch [20/20], Step [100/245], Loss: 0.1820
Epoch [20/20], Step [200/245], Loss: 0.1814
Validataion accuracy is: 79.4 %
Best Validataion accuracy is: 80.0
Accuracy of the network on the 1000 test images: 78.2 %
conv_net[0].weight shape: torch.Size([128, 3, 3, 3])

