Using device: cuda
CL-Arguments: Namespace(augment=0, comment='q2a_baseline', disp=False, dropout=None, e_stop=False, epoch=20, jitter=0.2, norm=True)
hidden sizes: [128, 512, 512, 512, 512, 512]

ConvNet(
  (conv_net): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): ReLU()
    (4): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (7): ReLU()
    (8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): ReLU()
    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (15): ReLU()
    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (19): ReLU()
    (20): Flatten(start_dim=1, end_dim=-1)
    (21): Linear(in_features=512, out_features=10, bias=True)
  )
)
conv_net.0.weight, torch.Size([128, 3, 3, 3]), # params: 3456, Parameter containing:
tensor([[[[ 0.0472, -0.1181, -0.0198],
          [ 0.1195, -0.0812, -0.0482],
          [ 0.1277, -0.1742,  0.1670]],

         [[ 0.0341,  0.1348, -0.0962],
          [-0.0454, -0.1143, -0.1224],
          [ 0.1102, -0.0751, -0.1866]],

         [[-0.0179,  0.1685,  0.1396],
          [-0.0953,  0.1491,  0.0494],
          [ 0.0066,  0.1668,  0.1361]]],


        [[[ 0.1654,  0.1535,  0.1098],
          [ 0.0128, -0.1475,  0.0850],
          [-0.1605,  0.1624,  0.1814]],

         [[-0.0610,  0.1344, -0.1549],
          [ 0.1033, -0.1226,  0.1747],
          [-0.0666,  0.0514, -0.1280]],

         [[ 0.0721, -0.1653,  0.0960],
          [-0.1203,  0.0514,  0.0619],
          [ 0.0222,  0.0391,  0.1307]]],


        [[[-0.1290,  0.1583, -0.1768],
          [ 0.0767, -0.1156, -0.0212],
          [ 0.1405,  0.1106,  0.1156]],

         [[-0.1393, -0.1708,  0.0952],
          [ 0.0403,  0.1845,  0.0543],
          [-0.1853,  0.1903,  0.0922]],

         [[-0.0357, -0.0994, -0.0626],
          [ 0.0192,  0.1410,  0.1098],
          [ 0.1517, -0.0864,  0.0943]]],


        ...,


        [[[-0.1741,  0.1755,  0.0803],
          [ 0.0780,  0.1294, -0.1399],
          [-0.0751, -0.0635,  0.0073]],

         [[ 0.0292,  0.0629, -0.0334],
          [ 0.1247, -0.1763, -0.1216],
          [ 0.0414,  0.1471,  0.0856]],

         [[-0.0227, -0.1447, -0.0104],
          [ 0.0383, -0.0772, -0.1401],
          [ 0.1529,  0.1844, -0.0881]]],


        [[[ 0.0365,  0.0045,  0.0996],
          [ 0.0516,  0.0636, -0.0325],
          [ 0.0102, -0.1404, -0.0583]],

         [[ 0.0250, -0.0166,  0.1875],
          [ 0.1193,  0.1643,  0.1700],
          [ 0.0471, -0.0431,  0.0825]],

         [[-0.0586,  0.1265,  0.1277],
          [ 0.1906,  0.1053,  0.0385],
          [ 0.1048,  0.1367, -0.1467]]],


        [[[ 0.0961,  0.0336,  0.0339],
          [ 0.1137,  0.0768, -0.1070],
          [ 0.1480,  0.1445, -0.1509]],

         [[-0.0603, -0.0960,  0.1905],
          [ 0.1815,  0.1232, -0.1672],
          [-0.1042,  0.1625, -0.1002]],

         [[ 0.1768, -0.1880, -0.1202],
          [ 0.0859,  0.0872,  0.1923],
          [ 0.1668,  0.0562,  0.1641]]]], device='cuda:0', requires_grad=True)

conv_net.0.bias, torch.Size([128]), # params: 128, Parameter containing:
tensor([-1.2459e-01,  1.0525e-01, -9.7181e-02, -8.6122e-02,  1.0329e-01,
        -1.3118e-01,  8.8568e-02, -5.9849e-02,  1.5917e-01, -1.9884e-02,
         5.8538e-02, -1.3948e-01,  1.1937e-01, -6.4467e-02, -1.7663e-01,
        -7.3614e-02,  1.3938e-01, -1.5271e-01, -1.3555e-01,  1.6093e-01,
        -1.1752e-01, -2.0455e-02,  1.7734e-01,  2.7358e-02, -3.0296e-02,
         2.4181e-02,  8.7059e-02,  1.1963e-01,  5.9976e-02,  1.9013e-01,
        -4.7210e-02, -2.5536e-02, -1.2785e-01,  1.0121e-01,  1.1431e-02,
         1.0794e-01,  1.6620e-01, -1.4684e-01, -5.0074e-02, -1.6796e-01,
        -5.0211e-02,  6.6380e-03, -1.5779e-01, -1.2163e-01,  5.7073e-02,
         1.1544e-01,  1.4792e-02,  8.7981e-02,  1.2562e-01,  1.5494e-01,
         1.9180e-01, -1.4022e-01, -8.9738e-02,  1.2330e-02, -1.5983e-01,
        -1.1492e-01, -1.7059e-02,  1.2900e-03, -5.4098e-02,  3.0079e-02,
        -4.8455e-02, -1.6618e-01, -2.0745e-02,  2.6939e-02,  1.9188e-02,
         1.8957e-02, -1.0694e-01,  8.5114e-02,  1.1139e-02, -2.2116e-02,
        -1.2473e-01,  1.1104e-01,  7.3835e-02, -1.5182e-01,  6.7324e-02,
         7.9956e-02, -5.1579e-02,  5.1608e-02,  1.8277e-01, -1.3742e-01,
         1.5515e-02, -9.3036e-02,  4.4768e-02,  6.3937e-02,  1.2200e-01,
        -1.0934e-01, -3.5491e-05, -1.8444e-01, -1.2789e-01,  8.3228e-02,
         8.7821e-02,  1.7631e-01, -4.8731e-03, -1.4594e-01, -3.5157e-02,
         4.0214e-02,  1.0361e-01, -1.4770e-02,  1.2529e-01,  4.2725e-02,
         8.7537e-03, -1.6815e-01,  1.4282e-01,  7.1845e-02,  1.5847e-01,
        -6.6333e-02,  7.9676e-03,  1.3532e-02, -1.3162e-01,  1.2743e-01,
        -4.7123e-03, -4.9132e-02, -8.9259e-02,  1.3323e-01, -1.9262e-02,
         3.3768e-02, -1.8375e-01, -1.2921e-01, -1.3255e-01,  9.4381e-02,
         1.8669e-01, -1.3931e-01, -6.7666e-03, -7.4540e-02, -7.1556e-02,
        -1.8588e-01, -4.5498e-04, -1.1314e-01], device='cuda:0',
       requires_grad=True)

conv_net.1.weight, torch.Size([128]), # params: 128, Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1.], device='cuda:0', requires_grad=True)

conv_net.1.bias, torch.Size([128]), # params: 128, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

conv_net.4.weight, torch.Size([512, 128, 3, 3]), # params: 589824, Parameter containing:
tensor([[[[ 2.1322e-02,  6.2853e-03,  1.0410e-02],
          [ 1.0223e-02,  1.6415e-02, -2.3862e-02],
          [ 2.3699e-03,  1.2889e-02, -2.0203e-02]],

         [[-6.2330e-03, -3.9692e-03, -1.0154e-02],
          [ 9.6260e-04,  6.3977e-03,  5.9441e-03],
          [ 9.2839e-03,  1.7535e-02, -1.2457e-02]],

         [[-7.3603e-03,  2.6040e-02, -1.3666e-02],
          [-1.2184e-02, -8.6470e-03,  1.4049e-03],
          [ 9.7066e-04,  6.5904e-03, -1.0098e-03]],

         ...,

         [[-1.7588e-02,  5.8311e-03, -2.1359e-02],
          [-9.5473e-03,  6.6142e-03,  1.1828e-02],
          [ 7.8007e-03, -1.9586e-02, -2.5192e-02]],

         [[ 1.4370e-02,  1.1725e-02,  7.1158e-03],
          [-1.5791e-02, -3.2122e-03, -2.0028e-02],
          [ 2.0603e-02,  1.8208e-02, -6.9645e-03]],

         [[ 1.4956e-02,  1.2634e-02, -1.1769e-02],
          [-2.4621e-04, -3.3133e-03,  6.4384e-03],
          [ 1.2946e-03, -1.0902e-02, -1.2591e-02]]],


        [[[ 2.1229e-02,  2.0321e-02, -2.5430e-02],
          [ 9.9240e-03,  4.4470e-03, -3.7956e-03],
          [ 1.8111e-02,  5.0292e-03, -3.4142e-04]],

         [[ 9.2086e-03, -2.7040e-02,  1.7853e-02],
          [ 1.8839e-02,  2.4180e-02,  1.5277e-03],
          [-2.1311e-02, -1.1146e-02, -2.0319e-02]],

         [[-9.5918e-03,  1.8450e-02, -2.8512e-02],
          [ 2.9353e-02,  8.5111e-03,  1.1597e-02],
          [-2.7256e-02, -1.8090e-02, -1.5470e-02]],

         ...,

         [[ 2.7052e-02,  6.8025e-03, -4.5540e-04],
          [-1.4890e-02,  1.1253e-02, -4.3171e-03],
          [-1.8200e-02,  1.0092e-02, -9.9617e-03]],

         [[ 2.6639e-02,  6.3942e-03, -1.2517e-02],
          [-2.2569e-02,  6.9047e-03,  4.0324e-03],
          [ 1.5528e-02,  1.0629e-02,  1.4008e-02]],

         [[-2.8196e-02,  2.7711e-02, -1.4760e-02],
          [ 4.0350e-03,  1.0711e-02,  2.3038e-02],
          [ 6.0084e-03,  2.5338e-02, -1.2301e-02]]],


        [[[-1.2862e-02,  2.8259e-02, -2.7614e-02],
          [ 2.1985e-02, -1.0031e-02,  1.0636e-02],
          [ 7.8698e-03, -6.9098e-03, -1.4496e-02]],

         [[ 1.8654e-02, -2.4040e-02,  3.5483e-03],
          [ 8.5045e-03,  1.5806e-02, -2.4881e-02],
          [ 1.9008e-02,  1.1907e-02, -1.8723e-02]],

         [[-2.4972e-02, -1.4740e-02, -1.0765e-02],
          [ 2.1147e-02,  1.4141e-02,  1.1844e-02],
          [-6.0157e-03, -1.8327e-02,  2.2748e-03]],

         ...,

         [[-2.4766e-02,  2.1452e-02, -1.6887e-02],
          [-2.2808e-02, -2.5102e-03, -2.1409e-03],
          [-1.1717e-02,  2.8289e-02, -2.8156e-02]],

         [[ 2.8666e-04,  3.2583e-03, -2.7217e-02],
          [-4.2178e-04,  1.4916e-02,  2.8765e-02],
          [-4.0482e-03,  2.7003e-02, -1.1440e-02]],

         [[ 1.1368e-02,  2.3899e-02, -2.4869e-02],
          [ 2.7117e-02, -7.4520e-03, -1.3074e-02],
          [ 2.0153e-02, -1.4221e-02, -2.7051e-02]]],


        ...,


        [[[ 2.2034e-02,  2.2551e-03, -1.3403e-02],
          [ 1.3447e-02, -2.9872e-04, -2.3921e-02],
          [-1.3281e-02,  5.6222e-04, -3.8406e-03]],

         [[ 6.6070e-03,  2.2730e-02, -1.4818e-02],
          [-2.6683e-02, -1.4494e-02, -9.7095e-03],
          [-2.6244e-03,  1.3557e-02,  5.9272e-03]],

         [[-6.7779e-03,  1.6904e-02, -1.0688e-02],
          [-1.5295e-02,  2.3692e-03,  9.2894e-03],
          [-7.7002e-03,  2.0511e-02, -2.0658e-02]],

         ...,

         [[ 3.5605e-03, -2.0723e-02, -2.8918e-02],
          [-1.3509e-03,  6.6045e-03,  1.5555e-02],
          [ 2.7257e-02,  2.8132e-02, -1.0975e-02]],

         [[ 9.2595e-03, -1.8183e-02,  6.5233e-03],
          [-1.6332e-02, -1.4647e-02, -1.7779e-02],
          [ 2.0671e-02, -5.6187e-04, -2.3792e-02]],

         [[-1.7117e-02,  9.1208e-03,  2.2300e-02],
          [-2.6252e-02, -1.4007e-05,  2.7999e-02],
          [ 2.2076e-02,  2.2193e-02, -2.7841e-02]]],


        [[[-1.3788e-02, -1.5320e-02, -1.5223e-02],
          [-2.1807e-02,  7.4020e-03,  2.7238e-02],
          [-1.3270e-03, -1.3972e-02,  2.0484e-02]],

         [[-2.1313e-02, -2.1350e-02,  1.5782e-02],
          [-1.9634e-02,  2.2706e-02, -1.5166e-02],
          [-1.7236e-02, -1.3479e-02,  2.6064e-03]],

         [[-1.5203e-02,  2.7036e-02,  2.6994e-03],
          [-1.9532e-02,  3.0333e-03, -2.3233e-02],
          [ 1.0503e-02, -1.8923e-03,  2.3770e-02]],

         ...,

         [[-2.1354e-02, -1.4798e-02, -2.2999e-02],
          [ 2.3968e-02, -1.2254e-03, -2.4542e-02],
          [-2.0005e-02,  3.8959e-03, -1.0017e-02]],

         [[-9.5452e-03,  9.2531e-03, -2.4434e-02],
          [ 2.5802e-02, -4.0242e-03, -1.4642e-03],
          [-4.7992e-03, -1.8579e-02, -6.0313e-03]],

         [[-6.0688e-03,  2.0114e-02,  5.9885e-03],
          [ 2.9037e-03,  1.1151e-02, -2.1919e-02],
          [ 9.5124e-03, -1.2098e-02,  2.8887e-02]]],


        [[[-6.6532e-03,  2.8333e-02,  4.6089e-03],
          [ 1.8235e-02, -5.4970e-03,  8.3923e-03],
          [ 7.7449e-03,  1.1050e-02, -5.2554e-04]],

         [[ 1.0063e-02,  1.5373e-02, -8.4340e-03],
          [-2.5474e-02,  1.9738e-03, -1.7493e-02],
          [-5.4457e-03,  1.9729e-02,  2.2097e-02]],

         [[-8.0902e-03, -2.4000e-02, -2.7596e-03],
          [ 2.5189e-02, -2.8577e-04, -2.3326e-02],
          [-2.1651e-02,  7.0011e-03, -1.0907e-02]],

         ...,

         [[ 3.2287e-03, -4.4170e-03,  1.9584e-03],
          [-2.4149e-03,  2.2900e-02,  1.5887e-02],
          [-2.0849e-02, -8.5682e-03, -1.7432e-02]],

         [[ 2.0816e-02, -2.0102e-02,  1.8350e-02],
          [-2.5146e-02,  2.3897e-02, -6.1700e-03],
          [-2.0559e-02,  1.5391e-02,  2.3360e-02]],

         [[-1.6369e-02, -1.8234e-02,  2.2163e-02],
          [ 1.6575e-02,  1.4132e-02,  2.1925e-02],
          [ 3.2873e-03,  5.0962e-03, -1.1345e-02]]]], device='cuda:0',
       requires_grad=True)

conv_net.4.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([-2.4509e-02,  1.9064e-02,  2.1368e-02,  5.4996e-03,  1.4871e-02,
         2.3662e-02, -2.8382e-02,  6.7008e-03, -2.2409e-02,  2.7256e-02,
         2.7822e-02,  4.8700e-03,  2.3464e-02,  2.1205e-03,  9.6922e-03,
         2.2459e-02, -2.7475e-03, -2.2647e-02, -2.7809e-02,  2.5843e-02,
        -1.1346e-02,  5.4881e-03,  2.6266e-02,  1.2036e-04, -5.6864e-03,
        -2.4858e-02,  6.9173e-03,  2.6053e-02, -5.7893e-03, -2.1690e-02,
        -1.2392e-02, -2.2727e-02,  2.0837e-02, -3.6305e-03, -1.9292e-02,
         1.8522e-03, -4.6515e-03,  9.4603e-03, -1.0609e-02,  4.2820e-03,
        -1.6007e-02, -2.8192e-02, -1.2835e-02, -2.1908e-02, -8.0697e-03,
         3.8021e-03,  4.2546e-03, -2.4183e-02,  2.0862e-02, -1.1638e-02,
         1.0624e-02, -2.8687e-02,  1.2268e-02, -2.2087e-02,  1.5478e-02,
        -2.7669e-03, -2.4568e-02, -3.6881e-03,  9.4338e-04, -4.3049e-03,
        -6.0459e-03,  2.3757e-02, -2.2527e-02,  2.4524e-02,  7.7122e-04,
        -2.1711e-02,  2.5347e-02,  2.6702e-02,  2.8775e-02,  1.5636e-02,
         2.4513e-02,  2.5305e-02,  1.3169e-02,  1.1019e-02,  3.3392e-03,
         1.6168e-02,  2.5321e-02,  9.9634e-03,  3.6146e-03,  2.3538e-03,
         2.0651e-02,  2.3356e-04, -1.5861e-02,  8.9855e-03,  1.5910e-02,
        -2.9310e-02, -2.1206e-02,  9.9787e-03, -6.4823e-03, -1.0543e-02,
        -1.8202e-02,  1.7142e-02, -1.8372e-02,  3.0528e-05, -2.0319e-02,
         1.9019e-02,  2.6285e-02,  1.3159e-02, -9.0069e-03,  1.6714e-02,
        -2.3377e-02,  2.1573e-02, -6.1633e-03,  2.8617e-02,  1.7742e-02,
         1.0863e-02,  4.3852e-03, -2.2814e-02,  1.6409e-02, -2.6737e-02,
        -2.8498e-02, -2.2342e-02, -2.2096e-02,  2.8619e-02, -3.3150e-03,
         2.4680e-02, -2.6627e-03, -7.9420e-03,  3.6502e-03,  9.4449e-03,
        -2.8754e-02,  1.4293e-02,  1.4214e-03, -2.8947e-02,  3.2591e-03,
        -2.7750e-02,  2.0448e-03,  1.2829e-02,  1.9246e-02,  7.7435e-03,
         1.4921e-02,  1.2729e-02, -4.8738e-03, -1.3843e-02, -1.0589e-02,
        -2.6302e-02, -1.9583e-02,  7.2782e-03,  2.1144e-02, -2.4064e-02,
        -2.5947e-02, -2.1014e-02,  1.5197e-02,  2.9938e-03,  2.2257e-02,
         1.3872e-02, -1.4986e-02, -2.1312e-02,  2.9228e-02,  2.4649e-02,
         6.4895e-03,  1.1486e-02, -2.7786e-02, -1.8247e-02, -2.3326e-02,
        -7.3036e-03, -1.7433e-02, -9.0590e-03,  1.3561e-02,  2.3283e-02,
         8.0232e-04,  7.5345e-03, -1.3141e-02, -2.3622e-02, -1.1797e-02,
        -1.3318e-02, -2.1694e-02,  1.9641e-02,  7.1787e-03, -1.7663e-02,
         1.6416e-02,  2.7720e-02, -1.0799e-02,  2.5061e-02,  1.4773e-02,
        -3.4618e-03,  2.0030e-02,  1.1206e-02,  2.4530e-02, -6.4562e-04,
        -7.3393e-03,  2.6622e-02,  1.9862e-02, -1.7338e-02, -1.8534e-03,
         2.9812e-03, -1.2208e-02, -1.4038e-02,  9.6623e-03,  2.0424e-02,
         2.5902e-02, -1.6648e-02, -2.6128e-02, -2.0385e-02, -2.8259e-02,
         2.8508e-02,  2.2707e-02,  2.1569e-02, -1.2376e-02, -2.5635e-02,
        -2.8128e-02,  2.8587e-02,  1.7608e-02,  6.1432e-03, -1.3436e-02,
        -9.8150e-03,  2.2447e-02,  1.4140e-02,  2.8734e-02,  2.6625e-02,
        -1.9016e-02, -2.7677e-02,  3.3410e-03, -1.6467e-02,  2.1584e-02,
         2.7657e-02, -1.2209e-02,  9.7688e-03, -9.0660e-03,  3.8858e-03,
        -1.0472e-02, -2.7632e-02, -2.2516e-02, -2.0911e-02,  1.6355e-02,
         1.3895e-02, -1.5575e-02,  5.3449e-03, -2.3034e-03, -6.1584e-04,
         2.2494e-02,  1.7112e-03,  1.4502e-02, -2.2688e-02,  4.7311e-03,
        -2.5851e-02, -2.3936e-02,  1.4054e-02, -1.2530e-02, -2.7366e-03,
         4.5063e-03,  1.2983e-02, -1.6604e-03,  2.0383e-04,  1.9730e-02,
         2.5051e-02,  1.4080e-02, -2.3257e-02,  5.9353e-03,  2.7038e-02,
         2.4481e-02,  1.3219e-02, -2.2944e-02, -1.6416e-02,  1.8681e-02,
        -1.9122e-02,  4.0349e-03,  3.5170e-03, -1.7543e-02, -4.6379e-03,
         2.6903e-02, -2.4260e-02,  7.9741e-03, -2.5704e-02, -1.1490e-02,
         1.6209e-02, -8.3496e-03, -1.5676e-02, -1.1570e-02,  7.7639e-03,
         4.1095e-04,  6.6095e-03, -1.6924e-02, -3.3373e-03, -2.4573e-02,
         2.1506e-02, -2.4557e-02,  1.7418e-02, -2.8462e-02,  2.2971e-02,
        -1.6384e-02,  1.0319e-02, -6.7263e-03, -2.4440e-02,  1.1777e-02,
        -1.0331e-03, -2.1453e-02,  2.0515e-02,  9.4114e-03,  1.5046e-03,
        -1.2735e-02, -7.2310e-03,  2.8964e-02,  9.6839e-03, -5.5957e-04,
        -2.9274e-02,  2.3725e-03,  1.9049e-02,  2.1245e-03,  8.4752e-03,
         1.1992e-02, -1.9914e-02,  2.9211e-02, -2.2163e-02, -1.2871e-02,
         2.5118e-02,  1.8062e-02, -2.9421e-02,  2.2010e-02, -2.8510e-02,
         8.3505e-03, -9.5571e-03,  1.8802e-02,  2.5684e-02,  1.2829e-02,
        -1.9590e-02, -2.6533e-03, -1.2714e-02, -1.2484e-02, -1.2753e-02,
         1.8548e-02,  1.5313e-02,  7.3067e-03,  1.7426e-02, -2.9016e-02,
        -2.1769e-02,  3.1658e-03,  3.3676e-03, -6.3441e-03,  1.4281e-02,
        -2.2487e-02, -1.0868e-02, -2.3132e-02,  3.9289e-03,  5.6703e-03,
         1.9110e-02,  2.4686e-02, -8.2980e-04,  2.2514e-02, -1.8104e-02,
         1.4088e-02,  2.7916e-02, -1.6974e-02,  2.4806e-02,  2.6466e-02,
        -2.6289e-02, -2.3878e-03,  9.4191e-03, -1.1736e-02, -8.0690e-03,
        -7.8909e-03,  7.3796e-05, -1.0439e-02,  1.3504e-02, -1.3489e-02,
        -3.8538e-03,  1.6894e-02, -1.2776e-02,  9.3906e-03,  1.3488e-02,
        -1.4455e-02,  1.9640e-02, -2.7466e-02,  1.6354e-02, -1.5163e-02,
        -2.9269e-02, -1.4366e-02, -8.7343e-03,  7.7496e-03,  1.0556e-02,
        -1.9755e-02, -2.5111e-02, -2.1212e-02,  6.9826e-03, -2.0689e-02,
        -1.2221e-02,  5.3752e-03,  2.6405e-04, -1.4390e-02, -2.1025e-02,
        -2.3278e-02, -1.4876e-02,  2.8124e-02,  8.9748e-05, -6.1001e-03,
        -3.8407e-03,  2.0430e-02, -2.3445e-02,  2.2405e-02,  6.8711e-03,
        -4.1187e-03, -1.2200e-02,  5.7202e-03, -2.6010e-02,  2.2884e-02,
        -2.1925e-02,  7.7030e-03,  1.1847e-02,  1.4723e-03, -2.7165e-02,
        -1.5485e-02,  2.3300e-02, -4.5582e-03, -1.8986e-02,  6.5189e-03,
         1.8125e-02, -2.8621e-02,  1.8104e-02, -2.3533e-02, -1.5745e-02,
        -2.3148e-02,  2.1611e-02, -2.0271e-02,  2.8627e-02,  2.1084e-03,
        -5.6724e-03, -1.6366e-04, -1.8709e-02,  2.5700e-02, -8.1601e-03,
        -1.4376e-03,  1.4253e-02, -5.0062e-03,  8.9863e-03, -2.7978e-02,
         2.0094e-02,  4.7222e-03, -1.0590e-02,  3.8516e-03, -2.4928e-02,
        -2.0375e-02, -1.2749e-03,  1.7989e-02,  3.3822e-03,  1.9469e-02,
         1.4270e-02,  6.8575e-04, -1.4394e-02,  1.4144e-02, -6.0583e-03,
         9.6452e-03,  8.9919e-03, -2.1439e-02,  2.0865e-02, -3.4688e-03,
        -8.0589e-03, -2.3847e-02, -2.2266e-03,  1.2615e-03, -2.6886e-02,
         1.9174e-02, -2.1557e-02,  2.8996e-02, -9.6569e-05,  1.0390e-02,
         1.7777e-02,  7.9638e-03, -6.4691e-03,  1.1127e-03, -9.5151e-03,
         1.9854e-02, -1.2216e-02,  1.9916e-02,  7.3602e-03, -2.7636e-03,
         9.5237e-03,  2.0885e-02,  5.1689e-03,  1.3773e-02,  2.5992e-02,
        -2.7161e-02,  2.1462e-02, -3.0358e-03,  1.7490e-02,  8.6339e-03,
        -9.6578e-03,  1.7304e-02, -5.6804e-03,  1.8402e-02, -3.0862e-03,
         1.1739e-02,  6.5652e-03, -4.7723e-04,  1.6263e-02,  1.4018e-04,
         6.2255e-03,  1.0687e-02,  1.9461e-03,  1.3092e-02, -7.2629e-03,
        -2.6399e-02, -1.6351e-03, -1.6172e-02,  2.1564e-02, -1.6741e-02,
         1.5142e-02, -4.9262e-03, -1.1995e-02, -1.5926e-02,  6.3862e-03,
         1.9188e-02, -2.7917e-02,  2.6228e-02, -8.1396e-03, -1.0542e-02,
        -2.5150e-02,  2.0043e-02,  1.8684e-02,  1.5936e-02, -2.0270e-02,
         2.6017e-02,  7.5477e-03], device='cuda:0', requires_grad=True)

conv_net.5.weight, torch.Size([512]), # params: 512, Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)

conv_net.5.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

conv_net.8.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[ 1.2306e-02,  3.9379e-03, -3.8485e-04],
          [-1.2212e-02, -7.4385e-03, -1.1941e-02],
          [ 4.8233e-04, -7.1122e-03, -8.0328e-03]],

         [[-1.3998e-02,  6.4452e-03,  8.3650e-03],
          [-1.3116e-02, -4.2575e-03,  2.8754e-04],
          [-7.8932e-03,  3.4066e-03,  6.4799e-03]],

         [[-6.4789e-04, -8.7615e-03,  6.3473e-03],
          [-1.2369e-02, -8.6812e-03, -1.3457e-02],
          [ 2.8125e-03,  6.8369e-03, -3.8590e-03]],

         ...,

         [[ 8.9614e-03,  1.0356e-02, -1.6450e-03],
          [-3.9932e-03,  1.1661e-03,  3.1385e-03],
          [ 4.3210e-03, -1.4064e-02, -8.1944e-03]],

         [[-1.1993e-02,  1.0107e-03,  3.7218e-03],
          [ 4.0738e-03,  1.2245e-02, -1.0352e-03],
          [-3.9993e-03, -6.7879e-03,  3.2658e-03]],

         [[ 1.0727e-02, -1.0731e-02, -1.1135e-02],
          [ 4.5242e-03,  1.2277e-02,  1.3304e-03],
          [ 1.0274e-02,  4.8696e-04,  5.3579e-03]]],


        [[[ 1.4625e-02,  1.5177e-03, -9.9730e-03],
          [ 7.0428e-03, -1.5667e-03, -8.8748e-03],
          [ 4.3945e-03, -4.8329e-03, -4.3786e-03]],

         [[ 1.3141e-02,  7.2877e-03,  6.0652e-03],
          [-1.2268e-02,  1.2077e-02, -1.2287e-02],
          [-6.0570e-03,  1.1583e-02, -1.1750e-02]],

         [[-2.0600e-03, -1.4589e-02,  5.3595e-03],
          [ 4.8359e-03,  9.5625e-03, -3.9176e-03],
          [-5.7180e-03,  5.6232e-03, -4.2356e-03]],

         ...,

         [[-1.2013e-02, -6.7509e-03,  4.7558e-03],
          [ 1.1209e-02, -9.3078e-03, -1.3636e-02],
          [ 1.5837e-03, -1.1493e-04,  1.3036e-02]],

         [[ 7.2644e-03,  9.2247e-03, -7.6348e-03],
          [ 9.3025e-04, -8.6259e-03,  3.1158e-03],
          [-6.6151e-03, -5.5450e-03, -1.7432e-03]],

         [[ 1.3186e-02,  9.0939e-04, -1.3357e-02],
          [ 8.0446e-03, -9.3427e-03,  1.1664e-02],
          [-1.4357e-02, -1.5413e-03,  1.0014e-02]]],


        [[[-1.4801e-03,  9.7382e-03, -4.7051e-03],
          [-1.2362e-02, -4.2324e-03,  2.5336e-03],
          [ 5.6604e-03, -8.3849e-03,  1.4046e-02]],

         [[-1.3957e-02,  6.8396e-03, -9.5211e-03],
          [ 1.8350e-03, -1.4684e-02, -1.2724e-02],
          [ 3.3878e-03,  2.5803e-03, -9.6140e-04]],

         [[ 1.4409e-02,  7.4384e-03,  1.2493e-03],
          [-6.6785e-03,  3.0106e-03,  7.6441e-04],
          [-5.2251e-03,  1.0353e-03, -3.4912e-03]],

         ...,

         [[-1.3019e-03,  6.8549e-03,  6.0420e-03],
          [ 9.0252e-03, -7.0697e-03, -1.4376e-02],
          [-5.1631e-03,  3.9493e-03,  6.6465e-03]],

         [[-4.1244e-03,  1.1939e-02, -3.3007e-04],
          [ 1.1683e-02,  8.8660e-03,  4.6796e-03],
          [ 1.3661e-02,  4.3077e-03, -4.2266e-03]],

         [[-5.4778e-03, -1.5153e-03, -1.2490e-02],
          [-4.5215e-03, -5.3292e-03, -9.1510e-03],
          [-6.7275e-03,  4.7849e-03,  1.4383e-02]]],


        ...,


        [[[ 9.1372e-04, -9.9567e-03,  1.3529e-02],
          [-8.6913e-03,  6.3272e-03, -4.4249e-03],
          [-1.3126e-02, -1.0673e-03,  1.1710e-02]],

         [[ 2.1896e-03, -1.2457e-03, -6.1227e-03],
          [-1.2837e-02, -8.6882e-03,  5.9260e-03],
          [ 3.5415e-03,  3.1322e-03,  2.2262e-03]],

         [[ 5.0139e-03, -1.2010e-02,  9.9442e-03],
          [-1.4348e-02, -6.2651e-03, -6.3126e-03],
          [-1.2353e-05,  1.9555e-03, -3.0837e-03]],

         ...,

         [[ 1.3516e-02,  7.8607e-03, -4.3822e-04],
          [ 1.2812e-02,  1.0812e-04,  7.7940e-03],
          [ 6.7483e-03, -1.1971e-02,  6.5904e-03]],

         [[-4.9915e-03, -1.1156e-02,  5.5838e-03],
          [ 5.9876e-04, -3.3278e-04, -6.7314e-04],
          [ 4.2246e-03,  8.1752e-03, -6.6490e-03]],

         [[ 1.2373e-02,  8.1706e-03, -1.1500e-02],
          [-1.3170e-02,  2.8407e-03, -3.5490e-03],
          [ 8.1149e-03, -1.1106e-02, -2.1712e-03]]],


        [[[-1.4277e-02, -1.1437e-02, -5.7400e-03],
          [ 7.0097e-03, -1.2443e-03, -7.5780e-03],
          [-9.7749e-03,  4.8215e-03,  7.5100e-04]],

         [[ 8.6130e-03,  4.9535e-03, -4.6802e-03],
          [ 6.9984e-03, -3.6324e-03,  7.0184e-04],
          [-2.6752e-03,  6.2330e-03,  1.0825e-02]],

         [[ 4.1829e-03, -1.1557e-02, -7.8339e-03],
          [ 4.7029e-03, -7.4984e-03,  1.1213e-02],
          [ 4.7807e-03, -6.0406e-03,  1.2593e-02]],

         ...,

         [[ 1.3015e-02, -1.1866e-02, -4.1831e-03],
          [-4.3015e-03,  3.5074e-03,  4.1089e-03],
          [-4.4841e-03,  7.0289e-03,  9.0098e-04]],

         [[ 1.4070e-02,  9.1793e-03, -1.1845e-02],
          [-1.7388e-03, -8.3923e-03,  6.8010e-04],
          [-1.1040e-02,  1.1373e-03, -9.5781e-03]],

         [[-1.1588e-02, -1.1354e-02, -1.2847e-02],
          [ 2.3487e-03, -1.4183e-02,  1.1069e-02],
          [ 1.2581e-02, -1.3825e-03, -1.1581e-02]]],


        [[[ 4.3693e-03,  9.4374e-04, -9.3203e-03],
          [ 4.2327e-03,  5.0432e-03,  1.4973e-03],
          [-1.2748e-02, -1.4316e-02, -5.9446e-03]],

         [[-8.3043e-03,  7.0168e-03, -1.3062e-02],
          [ 9.7647e-03,  4.7014e-03,  7.9348e-03],
          [ 3.8987e-03, -1.3286e-02, -5.4047e-03]],

         [[ 1.2977e-02, -7.7623e-04, -8.0145e-03],
          [-7.5312e-03,  6.2019e-03,  4.7931e-03],
          [ 1.2088e-02, -2.5613e-03,  5.2034e-03]],

         ...,

         [[ 1.4650e-02, -6.4106e-03, -1.4702e-02],
          [ 6.6559e-03, -1.1829e-02,  1.2310e-02],
          [ 1.3758e-02, -4.9252e-03, -1.3366e-02]],

         [[ 9.8336e-03,  1.1826e-02, -1.3752e-02],
          [-9.1761e-03, -1.4191e-02,  6.3393e-03],
          [-8.8994e-03,  2.5907e-03,  1.3778e-02]],

         [[ 7.1219e-03, -1.1046e-02, -1.2034e-02],
          [ 4.0653e-03,  3.2667e-03, -4.3761e-03],
          [-4.6989e-03, -1.2374e-03,  9.7568e-03]]]], device='cuda:0',
       requires_grad=True)

conv_net.8.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([ 4.1662e-03,  6.3523e-03,  1.1184e-03, -1.3189e-02, -2.1558e-03,
        -4.8798e-03, -3.5641e-03, -3.7561e-03, -1.1132e-02, -5.8928e-03,
        -6.9604e-03, -1.7519e-03, -1.1175e-02, -7.2454e-04, -1.4705e-02,
         1.4553e-04,  1.4364e-02,  7.5060e-03, -8.8425e-03, -1.0322e-02,
         2.0595e-03,  4.9655e-03, -5.5472e-03,  3.1380e-03,  1.3686e-02,
        -5.4703e-06,  9.8076e-03,  5.1276e-03, -5.1637e-04, -8.0947e-03,
        -9.5998e-03,  8.2533e-03, -6.5840e-03, -7.9561e-03,  1.3308e-02,
        -8.9445e-03, -1.2362e-02, -1.1845e-02, -8.1650e-03, -5.7999e-03,
         7.4679e-03, -1.1094e-02, -2.0803e-03, -4.6367e-03, -1.2783e-02,
        -8.1303e-03, -2.8116e-03, -7.4737e-03, -4.0707e-03,  5.8936e-03,
         2.0907e-03,  1.3746e-02, -1.2333e-02, -1.4712e-02,  4.2067e-03,
        -8.5377e-03,  5.9617e-03, -1.3300e-02, -1.0576e-02,  1.5683e-04,
         3.5141e-03,  5.8879e-03,  9.2442e-03,  1.3561e-02,  9.5375e-03,
         1.2088e-02, -1.2829e-02, -3.4681e-03,  7.2466e-03, -1.3824e-02,
        -1.1901e-03, -9.3439e-03,  5.5412e-03, -1.2352e-02, -1.0213e-02,
         4.0983e-03, -3.5995e-03,  6.0317e-03,  4.2824e-03,  1.3078e-02,
        -1.3197e-02, -1.0529e-02, -2.4324e-04, -1.5604e-03, -6.1747e-03,
        -1.2680e-02, -3.9060e-03,  1.0191e-02, -3.3913e-03,  3.1647e-03,
        -7.7486e-03,  7.2535e-04,  3.7459e-03, -1.1372e-02,  2.2170e-03,
        -1.1213e-03, -4.8710e-03,  3.9899e-03, -6.3123e-03, -5.1180e-04,
         2.9572e-03, -1.1471e-02,  9.4524e-03, -1.4137e-02, -1.1435e-02,
         1.5901e-03, -4.5239e-03,  9.1286e-04, -8.0458e-03, -5.6555e-03,
        -9.1055e-03,  2.8186e-03, -1.0803e-02,  5.4218e-03, -9.7522e-03,
         5.8445e-04,  3.9073e-04,  1.4055e-02,  5.1592e-03,  7.5763e-03,
         3.7954e-03, -3.1244e-03,  4.3546e-03, -8.2834e-03,  9.3842e-03,
        -4.7630e-04, -1.1946e-02, -5.9198e-03, -6.9282e-03,  1.2766e-02,
        -4.4228e-03, -7.6126e-04, -6.5024e-03, -6.5354e-03,  1.1164e-02,
         6.9063e-03, -1.3213e-02, -8.8504e-03, -5.6999e-03,  1.3408e-02,
        -8.8434e-03, -8.5799e-03,  4.5672e-03, -1.3999e-03,  1.2095e-02,
         7.6241e-03,  1.0721e-02,  1.1734e-02,  4.2605e-03, -5.1768e-03,
        -2.2975e-03, -1.1174e-02,  1.2052e-02,  6.3784e-03, -6.7784e-04,
         6.4876e-03,  7.4506e-03, -1.1773e-02,  6.2867e-03,  1.6834e-03,
        -9.9765e-03, -1.3339e-02,  7.8259e-03,  1.0075e-02,  1.3742e-02,
        -1.1682e-02, -5.3355e-03, -1.5667e-03,  2.1109e-04,  7.4318e-03,
         1.1895e-03,  8.5797e-03,  7.9857e-03,  7.1563e-03, -7.0328e-03,
         1.2023e-02, -1.3288e-02, -6.7537e-03,  7.8840e-03,  1.4555e-02,
         2.6990e-04,  1.3667e-02, -7.9924e-03, -1.6118e-03,  6.1888e-03,
        -4.4156e-03, -1.0234e-02, -1.3633e-02, -9.5114e-03, -4.1089e-03,
        -9.7812e-03, -5.0097e-03, -6.7286e-04,  1.6148e-04, -6.4202e-03,
         1.0321e-02, -1.2676e-03, -6.8110e-03,  1.3990e-02,  3.2543e-05,
        -5.8124e-03,  3.5287e-03, -7.3523e-03, -8.1686e-03,  8.9661e-03,
        -9.7555e-03,  2.2321e-03,  1.3723e-02, -1.0997e-02,  6.2258e-03,
        -3.5312e-03,  6.7247e-04,  3.6873e-03, -5.9257e-03, -1.6396e-03,
         7.8012e-03,  1.0589e-02, -1.3178e-02,  1.0332e-02,  8.9926e-03,
         2.5791e-03, -1.4019e-02,  4.2728e-03,  1.3018e-02,  1.4635e-02,
        -1.3559e-02, -2.0439e-04,  1.0854e-02,  9.7223e-03, -8.8606e-03,
        -1.1813e-02,  4.8227e-03, -7.0162e-04, -5.3187e-03, -1.3234e-02,
        -9.8234e-03, -7.2005e-03, -1.1773e-02, -1.1988e-02,  1.2321e-02,
         9.7457e-03, -4.0590e-03,  1.0324e-02,  8.8231e-04, -8.2091e-03,
         5.8175e-03,  1.1603e-02,  1.1829e-02, -7.9721e-03, -2.2739e-03,
        -1.0302e-02, -8.7131e-03,  5.7523e-03, -4.7666e-03,  1.0283e-02,
        -1.1514e-02, -3.8072e-03,  6.5626e-03, -1.3756e-02, -1.3794e-02,
         1.2597e-02, -7.3276e-03,  7.6271e-03, -1.8154e-03, -1.5765e-03,
         4.3117e-04,  1.4561e-02,  6.0836e-03, -7.8795e-03, -7.6652e-03,
         1.6951e-03,  1.1705e-03,  1.1265e-02,  1.3845e-03, -3.2944e-03,
         4.2486e-03,  7.6575e-03,  1.2864e-02,  1.1981e-02, -6.8791e-03,
        -1.2384e-02, -2.0854e-03, -2.7333e-03, -5.2175e-03,  1.3666e-02,
        -9.7297e-03,  2.8902e-03, -1.3126e-02,  1.1970e-02, -3.7520e-03,
        -1.2223e-02, -1.9474e-04, -3.9732e-03,  7.0654e-03, -1.2098e-02,
         9.1887e-03, -4.5245e-03, -1.1494e-02,  7.9259e-03,  5.0182e-03,
        -1.2634e-02,  3.8962e-03,  4.3738e-03, -1.1260e-02,  6.5562e-03,
        -1.1074e-02,  7.8494e-04, -1.3996e-02,  2.4552e-03, -7.9102e-03,
         9.7491e-03, -1.0829e-02, -1.1988e-02,  9.1349e-03, -1.3538e-02,
        -9.9368e-03,  4.5261e-03, -8.4181e-03, -1.4886e-03,  1.4301e-02,
        -1.4274e-02,  1.8665e-03,  1.2936e-02,  1.3647e-02,  6.9424e-03,
         1.1978e-02, -1.6993e-03, -5.9803e-03,  1.0721e-02,  4.2855e-03,
         7.1395e-03,  2.2053e-03, -9.1928e-03, -9.4666e-03, -7.7631e-04,
        -1.5570e-03, -1.0407e-02, -9.8274e-03,  8.5593e-03, -1.0227e-02,
         1.2161e-02, -1.4346e-02,  4.7074e-03, -1.1347e-02,  1.1512e-02,
        -9.2159e-03, -1.2567e-02, -6.3259e-03,  1.2930e-02, -5.0487e-03,
         1.1943e-02,  4.5800e-03, -1.4480e-03,  4.0283e-04,  4.1651e-04,
        -5.1889e-03,  1.3619e-02,  6.2734e-03,  3.2744e-03, -1.4307e-02,
        -4.1131e-04, -2.8871e-03,  2.4081e-03, -1.2661e-02,  6.3850e-03,
        -1.0124e-02,  1.0572e-02, -4.9057e-03,  1.1172e-02,  2.7189e-03,
         9.4462e-03,  1.1649e-02,  2.8580e-03, -1.4209e-02, -3.2434e-03,
        -1.0729e-02, -1.2935e-02,  1.0536e-04, -1.9725e-03,  4.0513e-03,
         1.3002e-02,  1.2246e-02,  4.6518e-03, -3.8696e-03,  8.5001e-04,
         3.6707e-03, -1.3491e-02,  3.3848e-03,  7.2274e-03, -1.1866e-02,
        -1.1775e-02,  1.0480e-03, -8.5521e-03, -8.5123e-03, -2.7719e-03,
        -6.4105e-04,  3.7768e-03, -2.2443e-03, -4.2929e-03,  1.1709e-02,
        -5.1675e-03, -1.0586e-02,  1.4496e-04, -4.0765e-03,  4.3975e-03,
         1.2809e-02, -1.0645e-02,  1.3474e-03, -6.7627e-03,  6.3343e-03,
        -8.3424e-03, -6.2222e-03, -5.2897e-03, -8.4532e-03, -9.4779e-03,
         1.0993e-02, -1.1883e-02, -3.5674e-03, -1.2897e-02, -6.5394e-03,
         1.2996e-02, -1.2649e-02,  1.3582e-03, -1.3202e-02, -1.3026e-02,
         1.4621e-03,  1.3071e-02, -1.4581e-02,  4.5949e-03, -9.1497e-03,
         2.7625e-03,  8.6427e-03,  1.0631e-02,  8.6647e-03, -1.0058e-02,
        -9.0099e-03,  5.2582e-03, -9.0726e-03, -4.8825e-03, -1.6934e-04,
         7.9478e-03,  4.3623e-03, -8.1872e-03,  1.2834e-02, -9.6698e-03,
        -3.8108e-03, -1.1541e-02, -1.1330e-02,  7.7499e-03, -1.0036e-02,
         7.4017e-03,  1.1214e-02,  3.2033e-03, -4.6407e-03, -8.9597e-03,
        -1.0605e-02, -6.3113e-03,  8.2890e-03, -7.8269e-03, -1.3213e-02,
        -1.1103e-02, -1.0708e-02,  1.2657e-02,  1.0966e-02,  5.3606e-03,
         9.8148e-03, -1.3176e-02, -4.8188e-03,  5.1194e-03, -2.3375e-03,
         6.3189e-03,  1.0619e-02,  1.0052e-02, -1.2444e-02, -1.1201e-02,
        -9.7198e-03,  4.7660e-03,  4.5622e-03, -1.0812e-02, -5.6102e-03,
         1.0588e-02,  1.1312e-02, -1.0058e-02,  1.3832e-03, -1.2005e-02,
        -9.8584e-03, -9.1667e-03,  9.6476e-03, -4.1141e-03, -3.8310e-03,
         3.3365e-04, -2.5937e-03, -1.1983e-02,  6.2191e-03, -2.0136e-03,
        -1.3201e-02,  9.5892e-03,  3.0774e-03,  1.4713e-02, -7.4009e-03,
         9.9014e-03,  9.3077e-04, -1.1615e-02,  5.0323e-04,  1.3558e-02,
        -1.5208e-03, -1.8055e-04, -8.9442e-03,  7.6406e-04, -3.3713e-03,
        -1.6105e-03, -6.6460e-03], device='cuda:0', requires_grad=True)

conv_net.9.weight, torch.Size([512]), # params: 512, Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)

conv_net.9.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

conv_net.12.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[-2.9607e-03,  1.2978e-04,  9.7479e-03],
          [-1.3442e-02, -1.2166e-02, -1.4303e-02],
          [ 5.8271e-03,  4.3195e-03,  8.2986e-03]],

         [[ 1.1304e-02, -3.3829e-03, -7.1769e-03],
          [ 1.3874e-02, -5.5534e-03, -4.1947e-04],
          [ 4.4599e-03, -9.3794e-05,  1.1729e-02]],

         [[ 8.3096e-03, -2.4058e-03,  1.0979e-03],
          [ 3.1802e-03,  3.2823e-03,  2.4759e-04],
          [-3.2532e-03, -1.3380e-02,  1.2234e-02]],

         ...,

         [[-3.5106e-04,  1.1749e-02,  7.6775e-03],
          [-1.2156e-02,  1.2003e-02,  1.4078e-02],
          [-2.1967e-03, -6.7341e-03,  1.1008e-02]],

         [[-7.1416e-03, -1.4471e-02, -7.0825e-03],
          [ 1.3294e-02, -3.1675e-05, -1.0614e-02],
          [ 1.3820e-02, -8.4428e-03, -7.4192e-04]],

         [[-1.0490e-02, -1.3119e-03,  2.6297e-03],
          [ 1.1184e-02, -8.2168e-03,  7.2162e-03],
          [-9.9018e-03,  1.0684e-03,  9.7043e-03]]],


        [[[ 4.1586e-03,  7.7861e-03, -3.6516e-03],
          [ 6.1173e-03,  1.0480e-02, -4.6005e-03],
          [ 1.3499e-02,  6.8194e-03,  2.4487e-04]],

         [[-1.8866e-03, -7.0539e-03, -1.1825e-03],
          [-7.7097e-03,  4.5343e-03,  2.1702e-03],
          [-3.9198e-03, -1.3723e-02, -1.0486e-03]],

         [[-5.0396e-03,  1.0650e-02, -1.0958e-02],
          [-1.1513e-02,  8.4806e-03,  4.0671e-03],
          [ 1.2970e-02, -8.2972e-03, -1.1773e-02]],

         ...,

         [[-1.3753e-02,  7.3320e-03, -1.2469e-02],
          [ 6.0744e-03, -8.9451e-04, -1.3282e-02],
          [-4.6126e-03, -9.9159e-03, -1.2678e-03]],

         [[ 8.1447e-03, -1.1546e-02, -5.1389e-03],
          [ 8.3187e-03, -8.6800e-03,  8.4870e-03],
          [-1.2514e-02,  1.2404e-04,  8.0356e-03]],

         [[-1.0492e-04, -5.4343e-04,  8.3576e-03],
          [ 1.1220e-02, -1.2344e-02, -2.8224e-03],
          [-8.6939e-04,  5.5457e-03, -8.8822e-03]]],


        [[[ 1.0467e-02,  4.7463e-03, -8.0059e-03],
          [-5.9529e-03,  7.3778e-03,  1.3769e-02],
          [-3.5280e-03, -3.4507e-03, -9.7226e-03]],

         [[ 1.2219e-02, -3.9110e-03, -6.3199e-03],
          [ 2.1963e-03,  4.9590e-03, -1.2528e-02],
          [-5.0413e-04,  8.9161e-03,  5.6875e-03]],

         [[-5.7082e-03,  1.3729e-02,  1.1889e-02],
          [-1.0740e-02, -4.1756e-03,  1.0600e-02],
          [ 8.5297e-03,  6.4856e-03, -9.7172e-03]],

         ...,

         [[ 1.0543e-02,  5.8702e-03,  6.4540e-03],
          [-6.2490e-03, -9.6186e-03, -7.2452e-03],
          [ 5.0391e-03, -5.0367e-03, -3.6065e-03]],

         [[-1.0259e-02,  1.3922e-02,  6.4913e-04],
          [ 9.7174e-03, -9.1848e-03, -1.5521e-03],
          [ 8.8138e-03, -1.1107e-02, -8.7960e-03]],

         [[-8.8157e-03,  4.8216e-03,  2.8233e-03],
          [ 1.0217e-02, -1.3078e-02,  9.8177e-04],
          [ 6.7959e-03,  1.3094e-02,  7.4402e-03]]],


        ...,


        [[[ 5.2797e-04, -1.4395e-02, -1.2642e-02],
          [ 8.2747e-04, -7.6087e-03,  9.5990e-03],
          [ 9.9106e-03,  1.9702e-03,  7.7183e-04]],

         [[ 1.3791e-02, -1.2991e-02, -3.4487e-03],
          [-1.3164e-02, -8.6099e-03, -1.3780e-02],
          [ 4.4653e-03, -5.6235e-03, -7.8824e-04]],

         [[-8.5220e-03,  7.8085e-03,  2.5937e-03],
          [-1.8806e-03, -1.0126e-02,  9.9042e-03],
          [-4.0212e-03, -1.1253e-02,  1.2481e-02]],

         ...,

         [[-7.8262e-04, -1.0847e-02, -9.4025e-03],
          [ 2.2243e-03,  1.4559e-02,  8.5448e-03],
          [-1.0436e-02, -3.6168e-03, -4.7927e-03]],

         [[ 6.4134e-03,  4.0211e-03, -5.5889e-04],
          [ 6.6777e-03,  7.1793e-03, -7.6327e-03],
          [ 2.0876e-03,  9.3229e-03, -3.9328e-03]],

         [[-9.5891e-03,  8.8395e-03,  1.3317e-03],
          [-5.5050e-03, -1.0764e-02,  1.0516e-02],
          [-2.9955e-03,  8.8963e-03, -2.6554e-03]]],


        [[[ 4.2638e-03,  1.1649e-02, -5.4232e-03],
          [-8.4260e-03, -5.1113e-03, -1.6349e-03],
          [-8.0281e-03, -1.5564e-03, -9.4454e-04]],

         [[ 4.3603e-03, -1.4132e-02, -7.1470e-03],
          [ 1.0971e-02, -6.8436e-03, -9.9794e-03],
          [-1.2697e-02,  2.8258e-03,  2.1367e-03]],

         [[-2.8064e-03, -1.1866e-02,  2.1223e-03],
          [-9.8442e-03,  1.0223e-02,  1.1435e-02],
          [ 7.2765e-03,  3.3439e-03, -8.7514e-03]],

         ...,

         [[-5.0951e-03,  1.2185e-02, -1.4190e-04],
          [-5.0139e-03, -5.3700e-04, -9.0207e-03],
          [ 7.4118e-04, -3.9406e-03, -1.0724e-02]],

         [[-2.6773e-04,  1.3764e-02, -1.1879e-02],
          [-1.1969e-02,  9.0024e-03, -1.3927e-02],
          [-5.0861e-03, -9.1057e-03, -2.7806e-03]],

         [[ 1.6551e-03,  7.1238e-04,  7.6235e-03],
          [-7.9268e-03, -1.0839e-02,  4.4926e-03],
          [ 1.0946e-02,  1.0767e-02,  7.9955e-03]]],


        [[[ 9.2744e-03, -6.2586e-03, -1.9060e-03],
          [-6.8243e-03,  3.5073e-03, -1.4022e-02],
          [ 2.7902e-03, -9.2853e-03, -8.8199e-03]],

         [[-2.8587e-03, -1.4120e-02,  2.9326e-03],
          [ 9.6956e-03, -3.3400e-03,  1.0693e-02],
          [-1.4492e-02, -1.3325e-02, -2.5793e-03]],

         [[-1.4119e-02,  1.2021e-02,  1.2197e-02],
          [-1.3491e-03, -5.9807e-03, -8.8198e-03],
          [ 8.1129e-03, -1.6889e-03, -1.4225e-02]],

         ...,

         [[-7.1745e-03, -2.0114e-03, -6.5550e-03],
          [-1.1940e-02,  6.1579e-03, -8.4257e-03],
          [-1.1577e-02, -7.8137e-03, -1.2091e-02]],

         [[-1.8300e-03,  4.1612e-03, -1.3762e-02],
          [ 1.0639e-02,  5.5308e-03,  2.6999e-03],
          [ 1.5777e-03, -7.6378e-03,  2.9491e-03]],

         [[-5.1359e-03, -1.1086e-02, -5.8049e-03],
          [ 1.0230e-02,  5.5117e-03,  1.1578e-02],
          [-9.3995e-03, -9.6743e-04,  1.2158e-02]]]], device='cuda:0',
       requires_grad=True)

conv_net.12.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([-6.1576e-03,  7.1785e-03,  1.1494e-02,  1.3108e-02,  9.4278e-04,
        -8.7899e-03, -1.1296e-02,  1.3995e-02,  8.6944e-03, -4.9891e-03,
         1.4499e-02, -5.0573e-03,  2.6693e-03,  7.2373e-03,  8.8321e-03,
         1.1698e-02, -2.2932e-03,  5.6286e-03,  9.6085e-03, -1.3121e-02,
         1.2045e-02,  1.2361e-02, -2.7689e-03,  2.9904e-03,  3.9930e-03,
         6.2182e-03,  1.2999e-02,  6.5351e-03,  2.6495e-04, -1.4612e-02,
        -7.9686e-03, -5.7418e-03, -3.7736e-03, -7.7902e-03, -9.5631e-03,
        -1.0517e-02,  1.8631e-03, -3.4110e-03, -3.3387e-04, -7.8392e-03,
        -5.4918e-03, -6.3404e-03, -1.1949e-02,  7.5964e-03, -7.6735e-03,
         1.1315e-02, -4.0369e-03, -7.3598e-03, -8.5972e-03,  1.0713e-02,
        -8.6159e-03,  1.1746e-02, -1.0590e-02, -1.4284e-03, -1.4461e-02,
         1.1843e-02,  1.0732e-02,  3.5718e-03,  6.4805e-03, -8.1720e-03,
         4.9781e-03, -3.2522e-03, -5.6721e-03, -8.0880e-03,  4.6952e-03,
         2.6887e-03, -3.0859e-03,  8.6784e-03, -1.3326e-02, -6.4095e-03,
         1.4657e-02, -1.1298e-02, -7.8084e-03, -4.0063e-03, -9.2522e-03,
         1.3564e-02, -2.8696e-03,  2.5601e-03,  9.8001e-03, -2.1932e-03,
        -3.5332e-03,  8.0748e-03,  7.9916e-03,  1.4960e-03, -3.9474e-03,
        -7.9717e-03, -1.3800e-02, -2.1936e-03,  4.1342e-03, -1.5363e-03,
        -5.1277e-03,  5.0132e-03, -1.1200e-02, -1.2568e-02,  1.4061e-02,
        -1.3743e-02, -1.1837e-02, -9.7236e-03, -3.5120e-03, -2.2341e-03,
         7.9239e-03, -1.5160e-03, -1.0387e-02, -2.8153e-03, -4.9539e-03,
        -1.0540e-02, -8.1230e-03,  6.9311e-03, -1.4336e-02,  1.0613e-02,
        -6.2988e-03,  9.1434e-04, -1.1044e-02,  1.0716e-03, -9.1779e-03,
        -8.4697e-03,  2.1846e-03, -1.4056e-02,  3.0974e-04,  1.1081e-02,
         1.9707e-03,  1.1863e-02,  8.0273e-03, -3.3268e-04,  4.5888e-03,
         2.2931e-03, -1.4712e-02, -5.6367e-03, -4.8064e-03,  8.5848e-03,
        -8.6801e-03, -9.6289e-04, -1.0934e-02, -7.1208e-03,  6.2024e-03,
         7.1501e-03,  5.8403e-03, -9.4039e-03,  5.3123e-03, -8.7131e-03,
         8.6696e-03, -1.0608e-02,  1.4598e-02, -4.7796e-03, -1.1116e-02,
        -1.9665e-03, -3.7359e-03, -6.6113e-03,  1.0776e-02, -3.7362e-03,
        -2.0559e-03,  1.1122e-03, -2.6874e-03, -9.1434e-04, -1.1343e-02,
         7.1941e-03,  9.2556e-03, -1.4540e-02, -4.9476e-03,  1.2089e-02,
         5.4630e-03, -3.3512e-04,  1.2873e-02, -1.2420e-02,  7.8035e-03,
        -9.1788e-03,  1.4803e-03, -1.0477e-02, -5.9277e-03,  7.6322e-03,
        -1.2749e-02, -1.5641e-03, -3.8875e-03,  2.3246e-03, -1.4058e-02,
         4.1373e-03,  3.4214e-03, -1.0065e-02, -1.1049e-02,  6.4708e-03,
         1.2389e-02,  7.4435e-03, -1.1584e-02,  1.2869e-02,  7.0902e-03,
        -3.1084e-03, -6.9575e-03,  1.0174e-02, -4.5724e-03, -1.1737e-02,
        -1.6963e-03,  1.1044e-02, -7.1913e-04,  4.1534e-03,  1.1925e-02,
        -6.3514e-03, -7.6626e-03, -9.8244e-03, -8.0137e-03, -1.1240e-03,
         1.1615e-02, -5.4495e-03,  1.0011e-02, -7.0236e-03, -4.6785e-03,
        -6.0362e-03, -1.2354e-02, -4.5201e-03, -3.2076e-03,  1.2716e-03,
         9.8323e-03,  8.7322e-03,  8.9714e-03,  6.2175e-03, -5.7993e-03,
         5.2941e-03, -7.4759e-04,  7.9596e-03, -1.4659e-02, -9.4527e-03,
         1.1108e-02, -4.0054e-03, -1.0802e-02,  1.3200e-02,  6.2247e-03,
        -4.5282e-03, -1.2286e-02,  5.7501e-03, -5.3222e-03, -5.1602e-04,
        -1.4089e-03,  1.1252e-03,  5.9577e-03,  1.8478e-03, -6.7381e-04,
         1.4470e-02, -9.4037e-03, -7.2800e-03,  1.4443e-02, -1.4538e-02,
        -5.1362e-04,  4.8154e-03,  8.5615e-03,  1.2279e-02, -1.0305e-02,
         8.3020e-03, -7.7258e-03, -1.1504e-02, -1.0699e-02, -1.4689e-02,
         3.9789e-03,  6.0751e-03,  3.5156e-03, -2.0264e-03,  1.2738e-02,
         2.0103e-03,  9.4251e-03,  8.0599e-03,  1.2747e-03, -1.5586e-03,
        -1.2105e-02,  1.2967e-02, -6.8331e-03,  2.8779e-03, -7.1886e-03,
         2.5378e-03,  1.4118e-02,  2.9830e-03,  2.2566e-03, -8.6442e-03,
        -1.6012e-03, -8.8777e-03,  1.4638e-02, -9.0241e-03,  2.7185e-03,
        -1.2637e-02,  1.1978e-03,  1.5642e-03, -5.4317e-03, -5.8161e-03,
        -1.1671e-02, -4.6353e-03, -6.3262e-03, -1.5005e-03, -8.1478e-03,
         4.5472e-03,  1.0934e-02,  1.8330e-03, -1.1874e-02,  4.8969e-05,
         1.4118e-02, -1.4652e-02, -8.9279e-03, -2.9663e-03,  1.6517e-03,
         1.0366e-02, -7.0774e-03,  8.5822e-03, -8.1908e-03, -1.8724e-03,
        -7.9138e-03,  1.2561e-02, -6.9288e-03, -9.5829e-03, -1.2576e-03,
         1.0217e-02, -1.4606e-02, -1.1352e-02,  4.1367e-03,  9.5428e-03,
         3.9029e-03, -6.6395e-03, -9.8209e-03, -7.4270e-03, -3.5067e-03,
         1.4850e-04,  2.3050e-04,  1.1248e-02, -4.8599e-03,  7.3156e-03,
        -1.3181e-02, -1.0183e-02, -1.1092e-02, -3.1038e-03,  2.2835e-03,
        -1.2475e-02,  1.0012e-02,  3.1433e-03,  8.5843e-03,  1.2476e-02,
        -1.4424e-02,  1.3520e-02,  1.3488e-02, -1.3092e-02,  3.2126e-03,
        -1.0938e-02, -4.0416e-03,  5.9883e-03, -1.1070e-02,  1.0059e-03,
         4.3921e-03, -7.7739e-03, -2.1678e-05,  7.0301e-03, -1.8814e-03,
         1.3357e-02, -1.1957e-02, -4.4424e-03, -4.5878e-03,  1.1809e-02,
        -1.1018e-02,  9.6224e-03, -1.4667e-03,  1.2201e-02,  2.0042e-03,
         5.9561e-03, -3.0480e-03,  8.0742e-03,  9.7240e-03,  1.3716e-02,
         9.8678e-03,  6.8597e-03,  9.1999e-03, -2.8185e-03,  3.3136e-04,
         1.0519e-04, -7.1582e-03, -6.7300e-03,  8.3046e-03, -5.5879e-03,
        -3.7578e-03,  8.9307e-03, -1.4460e-02, -1.1435e-02,  1.1443e-02,
         1.0657e-02,  1.2652e-02,  1.2054e-02,  7.8360e-04,  2.9044e-03,
        -1.1851e-02,  8.6619e-03, -1.0737e-02, -5.0006e-03,  8.3285e-03,
         7.5523e-03,  1.3899e-02, -9.7126e-03,  9.1938e-03,  2.2493e-03,
         7.9298e-03,  1.8993e-03, -1.0091e-03, -8.5210e-03, -3.8128e-03,
        -1.4681e-02, -1.6077e-03, -1.9558e-03, -8.9578e-03,  2.7427e-03,
        -6.3787e-03, -9.8286e-03, -1.0485e-02, -3.0471e-04,  7.8552e-03,
         6.7677e-03, -1.1562e-03, -1.1325e-02, -1.3509e-02, -6.9368e-03,
         9.5108e-03,  3.4083e-03,  4.3394e-03,  2.6558e-04,  6.9441e-04,
        -1.4370e-02,  6.4427e-03, -5.4371e-03, -4.1740e-03,  1.0397e-02,
        -9.8583e-04, -1.3109e-02,  6.4933e-03,  7.6917e-03, -9.3798e-03,
         1.4606e-02,  1.9606e-03, -2.3850e-03,  6.8045e-03,  1.1062e-02,
        -8.1498e-03,  1.4051e-02,  1.1006e-02, -1.2774e-03,  9.5732e-03,
         7.1011e-03,  1.1032e-02,  1.3893e-02, -8.9716e-03, -1.0526e-02,
        -1.2902e-02, -4.6189e-05, -2.1222e-03, -1.4007e-02, -6.8983e-03,
        -6.6780e-03, -1.1933e-03, -8.2856e-03,  1.3288e-03,  1.9567e-03,
         1.0671e-02, -3.8717e-03, -4.8376e-03, -1.4427e-02, -1.1873e-02,
         1.0297e-02,  6.5809e-03,  3.1920e-03, -3.7616e-03, -1.3240e-02,
         1.4719e-02,  2.5178e-03,  2.4227e-03,  6.8826e-03, -8.9492e-03,
        -7.1636e-03,  8.7903e-03, -1.0307e-02, -1.4428e-02, -1.3198e-03,
         3.6286e-03, -3.7192e-03,  1.0071e-02,  9.2215e-03, -1.3549e-02,
        -7.4620e-03,  1.3228e-02,  1.2876e-02,  1.3167e-02,  1.3869e-03,
         6.7631e-03,  7.7256e-03,  1.4481e-02,  1.1342e-04, -6.8898e-03,
         1.4281e-02, -8.1286e-03, -6.6667e-03,  1.2402e-02,  1.2375e-02,
        -1.4300e-02, -1.2305e-02, -1.0919e-02, -5.8295e-03, -3.6533e-03,
         5.7322e-03, -1.2333e-02, -4.5613e-04,  1.2078e-02,  8.0005e-03,
         1.1303e-02, -1.1121e-02, -1.2267e-03, -3.7614e-03, -1.2455e-02,
        -1.2440e-02, -1.3683e-02, -2.9599e-03, -6.7937e-04, -1.3307e-02,
         5.0766e-03,  9.1842e-03], device='cuda:0', requires_grad=True)

conv_net.13.weight, torch.Size([512]), # params: 512, Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)

conv_net.13.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

conv_net.16.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[-1.4985e-03, -1.3799e-02, -1.6104e-03],
          [ 8.2217e-03, -2.3008e-03,  8.9672e-03],
          [ 4.4724e-03, -5.8106e-03, -1.0883e-02]],

         [[ 1.1440e-03, -2.1324e-03,  1.2080e-02],
          [ 7.9468e-03,  7.7901e-03, -4.1899e-03],
          [ 2.9776e-03,  1.9822e-03,  3.3303e-03]],

         [[-9.6027e-03, -1.3844e-02, -5.2556e-03],
          [-2.1704e-03,  1.0448e-02,  6.7430e-03],
          [ 1.3274e-02, -1.4244e-02,  7.7220e-03]],

         ...,

         [[ 3.9044e-03,  6.1788e-03,  6.7160e-03],
          [ 2.3260e-03,  1.0579e-02, -6.6697e-03],
          [ 1.7741e-03, -1.1669e-02, -9.2990e-03]],

         [[-1.1168e-02, -6.1186e-03, -1.4009e-02],
          [ 6.0929e-04, -1.0356e-02,  1.0450e-02],
          [ 7.2364e-03,  3.3311e-04,  2.8102e-03]],

         [[ 5.8744e-03,  1.2016e-02, -9.0008e-03],
          [ 1.1234e-02,  1.4721e-02,  9.6510e-03],
          [ 7.0245e-08,  7.6825e-03,  1.4491e-02]]],


        [[[ 1.1167e-02, -7.3094e-03, -3.0744e-03],
          [-7.1869e-03,  3.7345e-03, -1.3812e-02],
          [ 2.9355e-04,  9.7508e-04,  1.0503e-02]],

         [[ 9.3080e-03, -5.2076e-03, -1.2632e-02],
          [-1.2617e-02,  1.1706e-02, -7.9440e-04],
          [-8.8006e-04,  1.1551e-02, -7.6712e-03]],

         [[-7.9318e-03,  1.2709e-02,  1.0428e-02],
          [-1.1240e-02,  1.1941e-02,  1.1316e-02],
          [-1.4524e-02, -1.1251e-02, -8.6328e-03]],

         ...,

         [[-9.2231e-03,  6.4184e-03,  1.0308e-02],
          [-1.0163e-02,  1.6248e-04,  1.2923e-02],
          [ 8.1794e-03, -1.3806e-02, -2.6895e-03]],

         [[-3.4675e-03, -1.4169e-02, -1.4624e-02],
          [-5.1527e-03,  1.2432e-02,  5.9134e-05],
          [-9.4723e-03,  1.4448e-02, -3.7108e-03]],

         [[-7.8177e-03, -1.1821e-02,  6.8757e-05],
          [ 5.0047e-03, -1.4133e-02, -8.2261e-03],
          [ 1.3240e-02,  2.1837e-04,  1.2000e-03]]],


        [[[-1.5581e-03,  2.8015e-03, -6.5909e-03],
          [-8.3796e-03,  2.6328e-03,  1.1251e-02],
          [-8.1562e-03, -5.2341e-04, -5.4882e-05]],

         [[-1.1463e-02,  6.2033e-03,  1.4353e-02],
          [-1.6215e-03, -2.6822e-03,  3.5760e-03],
          [-1.3552e-02,  1.1491e-02,  1.1626e-02]],

         [[ 8.8637e-03, -4.7936e-03,  1.2683e-02],
          [-2.3010e-03, -5.1512e-04, -6.6296e-03],
          [ 6.6742e-03,  4.7537e-03, -8.8105e-03]],

         ...,

         [[-1.4359e-02, -1.1813e-02, -9.6583e-03],
          [ 1.3545e-02,  6.8521e-03,  1.1487e-02],
          [ 3.2134e-03, -7.8374e-03,  5.1937e-03]],

         [[ 2.0409e-03, -1.7375e-03, -1.3678e-02],
          [ 2.4236e-03, -1.3191e-03,  3.2827e-03],
          [-1.4228e-02, -4.3047e-03,  1.4493e-02]],

         [[ 9.0718e-03, -1.1545e-02,  4.7113e-04],
          [ 1.4556e-02, -3.6193e-03,  2.6970e-03],
          [ 6.3573e-03, -4.9349e-03, -1.9592e-03]]],


        ...,


        [[[ 6.2051e-03, -5.3732e-04,  1.4529e-02],
          [-8.2426e-03,  1.2113e-02, -7.2423e-03],
          [ 1.0808e-02,  3.7034e-03,  1.0132e-02]],

         [[-7.5839e-03,  6.9177e-03,  9.7699e-03],
          [-1.3590e-02,  3.0311e-05,  5.6720e-03],
          [ 1.0201e-03, -8.9681e-03,  1.0254e-02]],

         [[-6.4983e-03, -1.4260e-02,  4.2174e-03],
          [-4.2191e-03, -8.4291e-03, -1.3926e-02],
          [-4.5308e-03, -1.3941e-02,  7.7472e-03]],

         ...,

         [[ 4.1352e-03, -1.3875e-02, -1.1560e-02],
          [ 7.4978e-03,  1.3468e-03,  1.0482e-02],
          [-1.1429e-02,  1.2028e-02,  5.5825e-03]],

         [[ 9.3864e-03, -8.0287e-03,  1.1688e-02],
          [-8.9905e-03,  1.2184e-02,  8.1580e-03],
          [-7.2886e-03, -1.1024e-02, -1.3515e-02]],

         [[ 1.2844e-02, -8.4240e-03, -7.1535e-03],
          [ 5.9671e-03, -1.2993e-03, -6.5315e-03],
          [-2.9665e-03,  3.8391e-03,  4.3025e-04]]],


        [[[-1.3941e-02,  1.0744e-02, -9.0351e-03],
          [-8.7670e-03,  3.3543e-03, -8.7296e-03],
          [ 6.0831e-03, -5.2462e-03, -1.4446e-02]],

         [[ 9.6673e-03, -1.0132e-02,  1.1855e-02],
          [ 9.9024e-03,  4.7542e-04,  1.4064e-02],
          [-1.2744e-02, -1.8984e-03,  3.7872e-03]],

         [[-3.2650e-03,  5.3090e-03, -1.3676e-02],
          [-8.3242e-03, -6.0699e-03,  1.0249e-02],
          [ 1.4428e-02, -1.0533e-03, -3.2122e-03]],

         ...,

         [[ 8.4468e-03, -9.6699e-03, -3.3148e-03],
          [ 3.3511e-03, -4.3431e-03, -4.7605e-03],
          [ 1.1003e-02, -1.4829e-03,  1.4973e-03]],

         [[ 1.2530e-02,  1.2850e-02,  1.1357e-02],
          [-3.4831e-03, -6.2839e-03, -1.0183e-02],
          [-9.4758e-03,  1.1408e-02, -1.1873e-02]],

         [[-5.2882e-03, -1.4415e-02,  8.5797e-03],
          [-9.0409e-03, -1.0494e-02, -1.4347e-03],
          [-2.0104e-03, -3.0246e-03, -1.3636e-02]]],


        [[[ 1.2545e-02,  1.3239e-02, -9.7174e-03],
          [ 3.7866e-03,  1.2447e-02, -6.7750e-03],
          [ 1.2357e-02,  4.1158e-03, -1.2446e-02]],

         [[ 6.0955e-06,  1.3391e-02, -1.2931e-02],
          [-1.2823e-02, -5.2542e-03,  8.0406e-03],
          [-8.5116e-03, -2.0673e-04, -7.4592e-03]],

         [[ 5.1742e-03,  5.7876e-03,  9.8354e-03],
          [-7.7005e-03,  2.0708e-03,  1.1871e-02],
          [-7.9240e-03,  9.9752e-03, -1.4096e-02]],

         ...,

         [[ 1.0660e-02,  1.2977e-02, -6.1322e-03],
          [ 7.2397e-03,  7.6479e-05,  1.2682e-03],
          [ 1.1671e-02,  3.9523e-03, -3.6862e-03]],

         [[ 5.1555e-03, -7.8764e-03,  7.7857e-03],
          [ 4.5911e-03,  1.7990e-03,  4.3515e-03],
          [-8.8686e-03,  4.5474e-03, -5.3881e-03]],

         [[ 8.0862e-04,  1.3256e-02,  1.4141e-02],
          [ 9.1958e-03, -6.4674e-03, -7.4634e-03],
          [-6.0433e-04,  1.1959e-02, -9.7566e-03]]]], device='cuda:0',
       requires_grad=True)

conv_net.16.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([ 1.2632e-02, -8.0792e-03,  1.2194e-02,  1.0453e-03, -1.1466e-02,
        -9.6810e-03,  1.0235e-02,  1.4841e-03,  4.4270e-03,  4.8962e-03,
        -1.1209e-02,  7.3450e-03, -3.3676e-03, -3.9061e-03, -1.4395e-03,
         1.3198e-02, -9.9461e-03, -5.6432e-03,  2.3220e-03,  1.3332e-02,
         2.0546e-03, -1.1706e-02, -6.5864e-03, -2.2103e-03,  1.2294e-02,
         7.8898e-03, -1.3822e-02, -1.3653e-03, -1.3052e-02, -3.5141e-03,
        -6.5822e-04,  4.2402e-03,  4.4296e-03, -3.0910e-03, -4.2933e-03,
         1.4220e-02, -7.4991e-03,  3.5022e-04, -1.4482e-03, -1.1579e-02,
        -3.9235e-03, -8.3884e-03, -1.6486e-03, -2.8378e-03, -1.1176e-03,
        -6.2562e-03, -1.3640e-02, -2.1717e-03,  3.1831e-03, -1.7105e-03,
        -7.3641e-03, -1.6688e-03, -5.4527e-03, -1.2855e-02, -9.7550e-03,
         1.0742e-02,  2.3186e-03,  1.0039e-02, -6.4559e-03, -6.0039e-03,
         9.7602e-03,  6.5398e-03, -5.9203e-03, -2.1244e-03,  1.0818e-02,
        -4.5313e-03,  7.1131e-03, -4.3154e-03,  1.1137e-02, -8.5191e-03,
        -1.4125e-02,  9.3239e-03, -9.2917e-03, -1.0785e-02, -4.1985e-03,
         5.8606e-03,  7.9119e-03, -9.6727e-03, -1.0823e-02,  1.2855e-02,
         1.4519e-02, -7.6824e-03,  6.4376e-03, -3.4166e-03,  1.2827e-02,
         8.6090e-03, -1.1707e-02, -1.2531e-02,  1.4336e-03, -1.4409e-02,
         1.0028e-02,  1.3349e-02, -1.2224e-02,  5.1202e-03, -8.7947e-03,
         8.5784e-03, -2.0056e-03,  1.4319e-02,  7.9230e-03,  4.5176e-03,
         1.0545e-02, -1.3953e-02,  9.3137e-03,  4.3960e-03,  1.4132e-02,
        -1.2238e-03,  6.3342e-03,  5.7735e-03, -4.3184e-03, -1.4662e-03,
         1.0405e-02, -9.3626e-03,  1.3455e-02, -9.8212e-04, -4.7708e-03,
         5.5106e-03,  1.4649e-02, -1.1804e-02, -5.1667e-03,  5.9358e-03,
         7.4670e-03,  2.8261e-03,  3.0161e-03, -1.0154e-02,  2.4038e-05,
         1.2345e-02,  8.7269e-03, -1.0117e-02,  6.3117e-03, -8.5865e-03,
         8.4029e-04, -6.5096e-03, -1.0843e-02,  1.4362e-04, -1.5443e-04,
         5.9514e-03, -6.2944e-03, -4.2223e-03, -1.3747e-02, -9.8451e-04,
        -8.6308e-03, -8.4932e-03,  9.7523e-03,  6.2290e-03, -2.2025e-03,
         7.2587e-03,  7.2780e-04, -1.4109e-02, -1.4503e-02,  1.1233e-02,
         1.2692e-02, -8.7893e-03, -7.7067e-03,  1.0183e-02,  3.7994e-03,
         3.2678e-03, -1.0418e-02,  1.5471e-03,  1.4667e-02, -2.5246e-03,
        -1.4034e-04, -6.2136e-03, -8.1149e-03,  1.0315e-02,  8.1892e-03,
         3.9217e-03, -4.6688e-04,  1.3245e-03,  1.3435e-02,  7.1782e-03,
        -5.5730e-03, -5.3862e-03,  6.6104e-03,  4.5809e-03, -1.1205e-02,
         3.6218e-03, -5.8201e-03,  3.4404e-03,  1.3103e-02,  9.4560e-03,
        -1.2897e-04,  1.2832e-02, -1.8986e-03, -9.9345e-03,  7.8171e-03,
        -2.3386e-03,  2.9941e-03,  1.0661e-02,  1.4546e-02,  1.6351e-03,
        -1.1379e-02, -1.2015e-02, -1.1446e-02, -9.5555e-03, -4.4085e-03,
        -1.1548e-02,  1.3875e-02, -1.5560e-03, -3.0912e-03, -7.3408e-03,
         2.0913e-03, -1.3431e-02, -1.3707e-02, -8.3477e-03, -2.1428e-03,
         5.9880e-03,  5.0608e-03,  1.0758e-02, -1.3088e-02,  4.3797e-04,
         6.5981e-03,  7.4711e-03,  4.8421e-03, -6.5592e-03,  7.4355e-03,
        -5.1357e-03,  1.0691e-02,  2.4242e-03,  1.0363e-02, -9.2898e-03,
        -5.8432e-03, -1.9157e-03, -1.0671e-03, -4.8313e-03, -2.1376e-03,
        -1.3586e-02, -2.6770e-03, -1.3424e-02, -8.1374e-03,  1.2411e-02,
        -1.3264e-02, -1.5907e-03,  1.4325e-02, -2.0315e-03,  6.3163e-04,
         3.6647e-03,  7.0469e-03, -2.7497e-03, -8.2038e-03, -2.9031e-03,
        -1.1870e-02,  6.7241e-03, -4.4444e-03, -1.1782e-02, -1.4484e-03,
        -8.4725e-03,  6.3690e-04, -5.3815e-03, -8.0568e-03, -1.2464e-02,
         1.1268e-02, -9.2152e-03, -8.8560e-03, -9.6927e-03,  3.5304e-03,
         1.0146e-02, -1.2078e-02, -1.9041e-03,  4.5056e-03, -8.0641e-03,
        -1.1858e-02, -1.4511e-02, -8.9167e-03,  1.2349e-02,  1.0743e-02,
         4.6175e-03,  1.4458e-02,  3.2721e-03,  1.2103e-02,  6.7738e-03,
         9.5323e-03, -6.4750e-03,  1.2619e-02,  1.6401e-03,  1.0849e-03,
        -1.1672e-02,  1.0154e-03,  1.3799e-02, -1.0659e-02,  8.9283e-03,
         1.4037e-02, -2.3487e-03, -8.3333e-03, -1.4722e-02,  1.7535e-03,
        -1.0591e-02,  2.1705e-03, -7.0598e-03,  1.1535e-02,  6.8379e-03,
        -6.5073e-03, -4.2434e-03,  1.0934e-02,  7.9591e-03,  1.0548e-02,
         7.3767e-03,  5.0375e-03,  1.1010e-02,  7.6267e-03, -1.4328e-02,
        -1.1346e-02, -1.3544e-02,  2.2227e-03,  1.4463e-02,  6.6320e-03,
        -5.5254e-04,  2.8272e-05,  1.3888e-02,  7.5571e-03, -1.4446e-02,
         4.4762e-03, -1.3689e-02, -1.4019e-02,  1.3461e-02,  1.2797e-02,
        -9.9733e-03, -2.8625e-03, -1.1849e-02, -1.9029e-03, -4.4029e-03,
        -6.8564e-03, -6.5614e-03,  9.8732e-03,  1.2497e-02, -1.4351e-02,
         2.2529e-03,  8.7009e-03,  2.5946e-03,  1.3243e-02, -8.9565e-03,
        -1.1868e-02,  1.3237e-02,  3.4335e-03,  2.4591e-03,  4.2425e-03,
         2.2903e-03,  7.6217e-03, -1.1726e-02,  1.2313e-02, -2.1923e-03,
         1.1092e-02, -2.4196e-03,  3.3502e-03,  4.3979e-03, -5.5477e-03,
        -6.1703e-03,  2.7117e-03,  1.3575e-02, -1.7351e-03,  1.2381e-02,
         4.5947e-03, -1.1531e-02,  1.4040e-02, -1.1319e-02, -9.4884e-03,
         7.0007e-03,  1.3921e-02,  1.3005e-02, -8.8699e-03, -1.1124e-02,
        -1.9862e-03,  1.0622e-02, -1.0171e-02, -8.6199e-03, -3.4897e-03,
        -9.9468e-03,  2.8743e-03,  1.2739e-02, -9.3355e-03, -7.3601e-04,
         1.2938e-02, -9.5741e-03, -1.0652e-02, -5.7712e-03, -1.0333e-02,
        -2.7825e-03,  1.2108e-02,  3.7064e-03, -1.1446e-02,  1.1302e-02,
        -5.7040e-05, -7.9914e-03, -1.0108e-02, -1.1907e-02, -5.2277e-03,
         8.0594e-03, -5.5923e-03,  6.1066e-04,  1.2817e-02,  1.4306e-02,
        -1.3825e-02, -5.1737e-04, -1.3559e-02, -3.4720e-03,  4.1891e-03,
        -1.4694e-02, -4.7570e-03, -4.6092e-03,  4.6500e-03, -7.3880e-03,
        -8.1101e-03, -7.4368e-03, -7.1442e-03, -6.0385e-03,  9.9570e-03,
         9.0780e-03,  1.2795e-03, -1.1449e-02, -1.8372e-03,  2.6814e-03,
         5.0199e-03,  9.4903e-03, -1.3430e-02,  1.2550e-02,  1.6436e-04,
         4.6743e-03,  1.3733e-02, -7.0367e-03,  8.3167e-03,  3.2263e-04,
        -1.1751e-02,  1.1223e-02, -1.3300e-02,  5.3535e-04, -1.3049e-03,
         3.8055e-03,  7.9757e-03,  5.6873e-04, -8.7929e-03, -9.6618e-03,
        -1.1585e-02,  9.4719e-03,  1.1094e-02, -3.5774e-03,  9.2878e-03,
         8.7465e-03, -1.6331e-03, -5.8433e-03,  1.1813e-03,  1.8597e-04,
        -4.8859e-03, -3.0258e-03, -1.3364e-02, -1.8624e-03, -7.6382e-03,
        -9.3101e-04, -2.1491e-03, -7.6014e-03, -1.2848e-02, -4.4550e-03,
        -2.2609e-03,  1.0851e-02, -1.4279e-02,  5.4484e-03, -4.1218e-03,
         4.1302e-03,  9.7353e-03,  2.2819e-03,  3.2142e-03, -1.0511e-02,
         6.5930e-03, -2.0959e-03, -1.3764e-02, -3.6026e-03, -4.1756e-03,
         5.2977e-03,  1.2259e-05,  1.1471e-02,  3.5801e-03,  7.1789e-03,
         1.4480e-02, -8.7480e-03, -3.9580e-03, -1.2013e-03, -8.6691e-04,
        -8.0258e-03,  5.1877e-03, -8.7514e-04, -4.2050e-03, -1.4167e-02,
         7.2400e-04, -8.1105e-03,  1.4423e-03,  2.5617e-03, -1.4462e-02,
        -8.6261e-03,  7.2438e-03,  6.3746e-03,  1.2411e-02,  3.8966e-04,
         9.9222e-03, -1.2697e-02,  5.5214e-03, -5.2767e-04,  1.4242e-02,
         4.5686e-03, -7.6316e-03,  1.0211e-02, -1.2928e-02, -1.3009e-02,
        -1.1823e-02, -1.0599e-02, -1.1466e-02, -3.8155e-03,  8.9775e-03,
         7.4530e-03,  3.4209e-03, -9.4477e-03,  9.2269e-03,  4.8943e-03,
         8.7967e-03, -1.0930e-02], device='cuda:0', requires_grad=True)

conv_net.17.weight, torch.Size([512]), # params: 512, Parameter containing:
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0', requires_grad=True)

conv_net.17.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0', requires_grad=True)

conv_net.21.weight, torch.Size([10, 512]), # params: 5120, Parameter containing:
tensor([[ 3.2687e-04, -5.6776e-04, -9.8083e-04,  ...,  8.5091e-04,
          9.4690e-04, -9.4806e-05],
        [ 3.5432e-05, -1.7177e-03, -1.0172e-03,  ..., -1.1638e-03,
         -1.8630e-03, -1.1729e-03],
        [-1.2086e-03, -1.5894e-07, -5.1998e-04,  ...,  3.7303e-04,
         -6.1563e-04, -5.3969e-04],
        ...,
        [ 2.8451e-04, -1.2142e-03, -7.8847e-04,  ..., -8.6187e-04,
         -3.0310e-05, -3.7293e-04],
        [-1.0712e-03,  4.0197e-04,  9.6921e-04,  ...,  4.0892e-04,
          3.7416e-04, -1.4908e-04],
        [ 9.7245e-05, -1.3362e-03,  1.3261e-03,  ...,  9.7286e-04,
         -4.1477e-04, -2.1044e-04]], device='cuda:0', requires_grad=True)

conv_net.21.bias, torch.Size([10]), # params: 10, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       requires_grad=True)

Total # params: 7682826

conv_net[0].weight shape: torch.Size([128, 3, 3, 3])
Epoch [1/20], Step [100/245], Loss: 1.4359
Epoch [1/20], Step [200/245], Loss: 0.9737
Validataion accuracy is: 39.1 %
Epoch [2/20], Step [100/245], Loss: 1.0806
Epoch [2/20], Step [200/245], Loss: 0.8619
Validataion accuracy is: 58.0 %
Epoch [3/20], Step [100/245], Loss: 0.7626
Epoch [3/20], Step [200/245], Loss: 0.7198
Validataion accuracy is: 68.5 %
Epoch [4/20], Step [100/245], Loss: 0.6547
Epoch [4/20], Step [200/245], Loss: 0.7887
Validataion accuracy is: 74.3 %
Epoch [5/20], Step [100/245], Loss: 0.5364
Epoch [5/20], Step [200/245], Loss: 0.7132
Validataion accuracy is: 76.1 %
Epoch [6/20], Step [100/245], Loss: 0.5003
Epoch [6/20], Step [200/245], Loss: 0.6198
Validataion accuracy is: 78.5 %
Epoch [7/20], Step [100/245], Loss: 0.5122
Epoch [7/20], Step [200/245], Loss: 0.3626
Validataion accuracy is: 77.5 %
Epoch [8/20], Step [100/245], Loss: 0.4049
Epoch [8/20], Step [200/245], Loss: 0.3292
Validataion accuracy is: 79.2 %
Epoch [9/20], Step [100/245], Loss: 0.3404
Epoch [9/20], Step [200/245], Loss: 0.3391
Validataion accuracy is: 79.6 %
Epoch [10/20], Step [100/245], Loss: 0.2537
Epoch [10/20], Step [200/245], Loss: 0.3176
Validataion accuracy is: 79.1 %
Epoch [11/20], Step [100/245], Loss: 0.3469
Epoch [11/20], Step [200/245], Loss: 0.2006
Validataion accuracy is: 81.5 %
Epoch [12/20], Step [100/245], Loss: 0.1346
Epoch [12/20], Step [200/245], Loss: 0.2026
Validataion accuracy is: 77.4 %
Epoch [13/20], Step [100/245], Loss: 0.1332
Epoch [13/20], Step [200/245], Loss: 0.1673
Validataion accuracy is: 79.8 %
Epoch [14/20], Step [100/245], Loss: 0.1004
Epoch [14/20], Step [200/245], Loss: 0.2391
Validataion accuracy is: 78.5 %
Epoch [15/20], Step [100/245], Loss: 0.0940
Epoch [15/20], Step [200/245], Loss: 0.1528
Validataion accuracy is: 80.9 %
Epoch [16/20], Step [100/245], Loss: 0.1424
Epoch [16/20], Step [200/245], Loss: 0.0846
Validataion accuracy is: 80.7 %
Epoch [17/20], Step [100/245], Loss: 0.0629
Epoch [17/20], Step [200/245], Loss: 0.1435
Validataion accuracy is: 81.6 %
Epoch [18/20], Step [100/245], Loss: 0.0392
Epoch [18/20], Step [200/245], Loss: 0.1041
Validataion accuracy is: 81.5 %
Epoch [19/20], Step [100/245], Loss: 0.0572
Epoch [19/20], Step [200/245], Loss: 0.0491
Validataion accuracy is: 80.3 %
Epoch [20/20], Step [100/245], Loss: 0.0265
Epoch [20/20], Step [200/245], Loss: 0.0448
Validataion accuracy is: 82.5 %
Accuracy of the network on the 1000 test images: 81.6 %
conv_net[0].weight shape: torch.Size([128, 3, 3, 3])

