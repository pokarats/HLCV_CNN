Using device: cuda
CL-Arguments: Namespace(augment=0, comment='q1a_early_stop50', disp=False, dropout=None, e_stop=True, epoch=50, jitter=0.2, norm=False)
hidden sizes: [128, 512, 512, 512, 512, 512]

ConvNet(
  (conv_net): Sequential(
    (0): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (2): ReLU()
    (3): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): ReLU()
    (6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (8): ReLU()
    (9): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): ReLU()
    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (14): ReLU()
    (15): Flatten(start_dim=1, end_dim=-1)
    (16): Linear(in_features=512, out_features=10, bias=True)
  )
)
conv_net.0.weight, torch.Size([128, 3, 3, 3]), # params: 3456, Parameter containing:
tensor([[[[-0.1259, -0.1778,  0.0099],
          [-0.1605,  0.0046,  0.0401],
          [-0.0284,  0.0131, -0.1712]],

         [[-0.0015, -0.1863, -0.1487],
          [-0.0713, -0.1111,  0.0490],
          [-0.0070,  0.0095,  0.1388]],

         [[ 0.1018,  0.0037, -0.0804],
          [-0.1722, -0.1439,  0.1419],
          [-0.0835,  0.1889,  0.0657]]],


        [[[-0.0511,  0.0345,  0.0820],
          [ 0.1509,  0.0269,  0.0598],
          [ 0.0502, -0.0299, -0.1896]],

         [[ 0.0826,  0.0636,  0.0168],
          [ 0.1770, -0.0072, -0.0298],
          [ 0.0780,  0.0500, -0.0481]],

         [[ 0.0429,  0.0149,  0.0197],
          [ 0.1556,  0.1202, -0.1205],
          [-0.0600,  0.1655,  0.1178]]],


        [[[ 0.1861,  0.0410,  0.1702],
          [-0.0403, -0.0291,  0.1821],
          [-0.1641,  0.0185, -0.1906]],

         [[-0.0999, -0.0411,  0.1477],
          [-0.0276,  0.1023,  0.0568],
          [ 0.0600,  0.0938,  0.1329]],

         [[ 0.1875,  0.1568, -0.0072],
          [-0.0493, -0.1292,  0.1744],
          [ 0.0839,  0.0483,  0.1220]]],


        ...,


        [[[-0.1694,  0.0682,  0.1725],
          [ 0.0204,  0.1496,  0.0987],
          [ 0.1054,  0.0293,  0.0457]],

         [[-0.0054, -0.1413, -0.0417],
          [-0.1121, -0.1611,  0.1817],
          [-0.1498, -0.0938, -0.0749]],

         [[ 0.1676, -0.0861, -0.1467],
          [-0.0030,  0.1666,  0.0777],
          [-0.0531, -0.1197,  0.1144]]],


        [[[ 0.1566,  0.1665,  0.0941],
          [ 0.1629, -0.0209,  0.1381],
          [-0.0608,  0.1673,  0.0607]],

         [[-0.0829, -0.1204, -0.0486],
          [ 0.1824,  0.0966,  0.1566],
          [-0.1309, -0.1767,  0.1701]],

         [[ 0.0189,  0.1863,  0.1526],
          [ 0.1329,  0.1353,  0.1585],
          [-0.1763,  0.0027,  0.0912]]],


        [[[-0.0986, -0.1467,  0.1727],
          [ 0.0151,  0.1357,  0.1160],
          [-0.0425, -0.0830, -0.1463]],

         [[ 0.0272,  0.0594,  0.1103],
          [-0.1535,  0.1492, -0.0955],
          [-0.0832, -0.1793, -0.0869]],

         [[-0.0719, -0.0322,  0.0607],
          [ 0.0388, -0.1206, -0.1882],
          [-0.1100, -0.1393,  0.0228]]]], device='cuda:0', requires_grad=True)

conv_net.0.bias, torch.Size([128]), # params: 128, Parameter containing:
tensor([-0.1730, -0.1733,  0.0576, -0.1688, -0.1250, -0.0588, -0.0653,  0.1662,
         0.1434,  0.0489, -0.0514,  0.0042, -0.1154,  0.0872, -0.1472, -0.0177,
         0.0651,  0.0226,  0.0455,  0.0628,  0.0795, -0.1248, -0.0666,  0.1759,
         0.0194, -0.1168, -0.1593, -0.1359, -0.1827,  0.0399,  0.0302, -0.1893,
         0.0825, -0.0957, -0.1053, -0.0093,  0.1901,  0.1770, -0.0830,  0.1131,
        -0.1121, -0.0818, -0.0138, -0.0107, -0.1467,  0.0095,  0.1302,  0.1022,
        -0.1273, -0.1700,  0.0421, -0.1827,  0.0240,  0.0032, -0.1038,  0.0184,
         0.1472, -0.1607,  0.0597,  0.0778, -0.0303, -0.1424, -0.0496,  0.0853,
         0.0500,  0.1630, -0.0065,  0.1864,  0.0485,  0.1014, -0.0121, -0.0798,
         0.0757,  0.0453,  0.1265,  0.1015, -0.0444,  0.0738,  0.0453,  0.1087,
         0.0301, -0.0035, -0.1039, -0.0431, -0.1486,  0.0203, -0.1357, -0.1820,
         0.1398,  0.0191,  0.0169, -0.1492, -0.0615, -0.1524,  0.1311,  0.1126,
         0.1419, -0.1387, -0.0418,  0.0773,  0.0529, -0.0764, -0.0177,  0.1576,
         0.0069,  0.0320, -0.0968, -0.1562,  0.0367,  0.1477,  0.0999, -0.0032,
        -0.1191, -0.0626,  0.0433, -0.1228,  0.1058,  0.0735,  0.0108,  0.1109,
         0.0431, -0.1119,  0.1260,  0.0917, -0.1740,  0.1655, -0.1533, -0.1709],
       device='cuda:0', requires_grad=True)

conv_net.3.weight, torch.Size([512, 128, 3, 3]), # params: 589824, Parameter containing:
tensor([[[[-2.7690e-02, -6.3224e-03, -2.2479e-02],
          [-1.5501e-02,  1.2026e-02,  1.7480e-02],
          [-1.1738e-02,  2.3667e-02, -5.8086e-03]],

         [[ 1.7597e-02,  2.3846e-02,  1.0886e-02],
          [ 2.3647e-02,  2.0528e-03, -4.2884e-04],
          [ 2.0259e-02,  1.4747e-02, -2.9457e-02]],

         [[ 2.1015e-02, -2.3023e-02, -2.2288e-02],
          [-4.5739e-03, -5.6382e-03,  1.4560e-02],
          [-2.9745e-03, -1.7409e-02, -1.7407e-03]],

         ...,

         [[ 2.5184e-02,  1.1489e-02,  2.5272e-02],
          [-1.1596e-02, -2.6621e-02, -2.7121e-02],
          [-2.9082e-02,  9.0083e-03,  1.7524e-02]],

         [[-1.0436e-02, -1.1751e-02, -1.6704e-02],
          [ 9.6335e-03,  1.0414e-02, -2.7871e-02],
          [ 2.2855e-03,  2.6312e-02, -1.2461e-03]],

         [[ 1.4215e-04, -2.2289e-02,  3.5957e-03],
          [-5.3096e-03, -2.2421e-02,  1.6342e-02],
          [ 1.5953e-02, -2.3063e-02,  1.0896e-02]]],


        [[[-4.0662e-03, -2.5651e-02, -2.7759e-02],
          [ 1.7266e-02, -1.3060e-02,  9.1585e-03],
          [-1.2249e-02, -6.4266e-03, -7.8241e-03]],

         [[-2.8240e-02, -2.9153e-02,  2.3355e-02],
          [ 2.4868e-02,  5.1175e-03,  2.5575e-02],
          [-1.8883e-02,  5.3478e-04,  1.9564e-02]],

         [[-2.5533e-02, -2.5241e-02,  2.3230e-02],
          [ 2.7452e-02,  8.7805e-03, -1.0181e-02],
          [-5.5823e-04,  2.2459e-02, -6.5161e-03]],

         ...,

         [[-2.1078e-02,  1.5039e-02, -3.8832e-03],
          [ 1.8679e-02, -9.7534e-03,  2.7831e-02],
          [-7.1335e-03, -6.5201e-03,  4.3519e-04]],

         [[ 1.3514e-02,  1.5739e-02,  2.4838e-02],
          [ 9.0614e-03,  8.5435e-03, -1.0036e-03],
          [-8.1168e-03,  2.6580e-02,  6.3533e-03]],

         [[-1.3789e-02,  1.5030e-02,  1.5340e-03],
          [ 1.4642e-02, -5.0623e-03, -1.4435e-02],
          [-1.3426e-02,  5.2216e-03,  1.5138e-03]]],


        [[[ 2.1327e-02,  2.1527e-02, -5.4009e-04],
          [ 6.8930e-03,  2.9315e-03,  2.3624e-02],
          [ 2.5203e-02,  5.4145e-04,  2.3838e-02]],

         [[-2.3013e-02,  1.0833e-02,  1.9925e-02],
          [ 2.6548e-02, -1.7168e-02,  3.5384e-03],
          [-1.3933e-02, -2.0497e-02,  7.9887e-03]],

         [[-1.7753e-02,  2.1881e-02,  1.6475e-02],
          [-2.6854e-02, -2.4269e-02, -2.4327e-02],
          [-2.2102e-02, -2.8013e-02, -1.3870e-02]],

         ...,

         [[-1.0212e-02,  5.0420e-03, -1.1646e-02],
          [-1.9074e-02,  6.0018e-03,  2.7024e-02],
          [ 1.3464e-02, -1.7198e-02, -9.8144e-03]],

         [[ 1.9616e-02, -2.4208e-02,  1.4344e-02],
          [ 1.1125e-03,  2.1592e-02, -1.3405e-03],
          [-8.9759e-03,  1.9731e-02,  1.0961e-04]],

         [[-1.1839e-02,  2.2199e-03,  7.2765e-04],
          [-6.1320e-03,  2.3262e-02, -2.2567e-02],
          [ 2.3613e-04,  1.1366e-02, -1.6882e-02]]],


        ...,


        [[[ 1.1381e-02, -2.9242e-03,  6.1263e-04],
          [-9.5334e-04, -2.4864e-02,  1.2355e-02],
          [ 1.7382e-02,  6.9437e-03, -8.1070e-03]],

         [[ 2.6491e-02,  2.8745e-02, -2.6196e-03],
          [-9.1063e-03,  2.7199e-02, -2.9238e-02],
          [-1.4343e-02, -1.3434e-04, -1.3967e-02]],

         [[-1.6040e-02,  1.0092e-02, -4.8583e-03],
          [ 2.0908e-02, -1.6657e-02, -2.4632e-02],
          [ 2.7365e-02, -1.1115e-02,  1.7815e-02]],

         ...,

         [[-2.8887e-02, -1.5709e-02,  1.0755e-02],
          [ 1.4149e-03, -1.4646e-02,  2.8648e-02],
          [-9.9635e-03,  1.5698e-02, -2.1992e-02]],

         [[-2.5223e-03,  2.9000e-02, -1.6836e-02],
          [-1.8090e-02, -1.9733e-02, -2.0796e-02],
          [-2.1373e-02, -1.5072e-02,  2.6688e-02]],

         [[ 1.2075e-02,  3.8340e-03, -2.2678e-02],
          [ 1.6951e-03, -1.7845e-02,  1.3402e-02],
          [-2.0671e-02, -1.1585e-02, -1.8097e-02]]],


        [[[-2.8055e-02, -2.7125e-02, -2.0384e-02],
          [-1.0771e-03, -2.6894e-02,  8.8415e-03],
          [-1.9796e-02, -2.8014e-02, -1.7136e-02]],

         [[-2.6242e-02,  2.9198e-02,  4.3981e-03],
          [-2.0884e-02, -7.7472e-03, -1.3183e-02],
          [ 1.4491e-02, -2.7193e-02,  2.7735e-02]],

         [[-1.6420e-02, -4.0859e-03, -2.8439e-02],
          [ 9.6277e-03, -2.5911e-02,  1.0428e-02],
          [ 2.0448e-02, -1.3322e-02, -2.6486e-02]],

         ...,

         [[-2.2875e-02,  8.5249e-04, -9.4084e-03],
          [-4.6344e-03,  1.2887e-02, -1.4477e-02],
          [ 2.6564e-02, -2.8439e-02, -1.3573e-02]],

         [[ 1.4262e-02,  2.0775e-02,  6.3759e-03],
          [ 1.0029e-02,  1.1252e-02,  2.6110e-03],
          [ 1.8338e-02,  5.4373e-03,  1.2358e-02]],

         [[-2.7874e-02, -1.1477e-02, -1.5639e-02],
          [ 2.3099e-02,  2.8145e-02,  1.8938e-02],
          [ 1.5301e-02, -2.3671e-04,  2.8767e-02]]],


        [[[-2.1249e-02,  7.2776e-03,  1.9132e-02],
          [ 2.4864e-03,  7.1931e-03, -2.6534e-02],
          [ 4.4533e-03, -1.1645e-02,  1.2124e-02]],

         [[-4.6603e-03,  1.7851e-03, -5.4893e-05],
          [-1.1265e-02, -2.2398e-02,  2.5808e-02],
          [ 1.3837e-02, -2.1852e-02,  4.3202e-03]],

         [[ 8.6267e-04, -2.0101e-02, -6.5949e-03],
          [-1.5399e-02,  3.1122e-03, -4.9086e-03],
          [ 5.0363e-03,  1.2110e-02, -1.9145e-02]],

         ...,

         [[ 5.3090e-03, -8.0936e-05, -1.6694e-02],
          [ 2.1610e-02, -1.9138e-02,  1.5216e-02],
          [ 8.6850e-03, -1.5327e-02, -2.8088e-02]],

         [[-1.3423e-02, -5.8207e-03, -1.5268e-02],
          [-2.4426e-02, -8.0486e-03,  2.5709e-02],
          [ 1.9830e-02,  1.0626e-02,  2.6192e-02]],

         [[-2.7802e-02,  2.8578e-02, -8.8555e-03],
          [-2.0370e-02, -1.9525e-02,  5.2640e-03],
          [-2.5506e-02,  1.9482e-02, -9.9236e-04]]]], device='cuda:0',
       requires_grad=True)

conv_net.3.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([-2.0560e-02,  1.9317e-02,  9.6334e-03,  7.3909e-03, -1.5678e-02,
         1.9848e-02, -1.4950e-02, -8.7531e-03,  7.6960e-03,  2.2052e-02,
         8.0743e-03,  2.0689e-02, -7.1195e-03,  2.5379e-02, -2.2807e-02,
         2.2257e-02,  1.9718e-02, -2.2761e-02, -1.8828e-02,  2.2815e-02,
         6.8072e-03, -1.3361e-02,  2.9030e-02, -2.0606e-02,  1.5115e-02,
         2.7350e-02,  1.4774e-02, -1.1010e-02,  6.6665e-03,  1.9619e-02,
        -1.8222e-02,  6.0322e-03,  2.1104e-02, -6.6332e-03,  2.1322e-02,
        -2.9194e-02,  1.7578e-02,  5.2420e-03, -4.5949e-04,  1.9219e-02,
         2.0905e-02, -2.6735e-02, -1.8963e-02, -2.3810e-02,  1.6769e-03,
        -1.5472e-02, -1.7034e-02,  2.5786e-03,  4.9066e-03,  1.9127e-02,
         2.8463e-02,  2.6220e-02,  2.2704e-02,  2.8164e-02,  2.3249e-02,
        -2.5607e-02,  2.3123e-02,  9.9698e-05, -9.8068e-03, -1.4153e-02,
         2.3773e-02, -4.4232e-03,  2.6779e-02,  3.3173e-03,  1.6065e-02,
        -1.1510e-02, -8.7323e-03, -1.5316e-02,  2.5496e-02,  2.3374e-02,
        -1.4593e-02, -1.2316e-02, -2.5697e-03, -2.0263e-02, -3.4872e-04,
         2.7289e-04, -1.3732e-02, -8.8118e-04,  3.9246e-03,  2.5749e-02,
        -2.1576e-02, -1.9349e-02,  1.8285e-02, -1.8211e-02,  2.3716e-02,
         7.4982e-03,  1.2913e-02, -9.2334e-03, -7.8836e-03,  1.7637e-02,
        -3.6925e-03,  2.8956e-02,  6.0119e-03, -2.0506e-02,  1.0532e-02,
        -4.9262e-03,  2.3709e-02, -2.5993e-02,  2.7910e-02,  2.7693e-03,
        -4.4270e-03, -2.0409e-02,  2.4115e-02,  1.7685e-03,  2.0360e-02,
         2.7232e-02,  2.7330e-02,  1.6587e-02,  1.8183e-02, -2.3718e-02,
        -1.8821e-02, -1.0931e-02,  2.5306e-02,  2.7298e-02, -1.8746e-02,
         1.8797e-02, -1.9529e-02,  2.6609e-02, -2.6385e-03,  6.6576e-03,
        -5.1357e-03, -2.4056e-02,  7.8611e-04, -5.6734e-03,  1.2577e-02,
        -4.5611e-03, -1.4113e-02, -1.3155e-02,  2.1488e-02, -1.2165e-02,
         1.9320e-02, -2.1658e-02,  4.7048e-03, -2.7284e-02, -2.2189e-03,
         2.3320e-02, -3.7044e-03, -6.5660e-03,  1.3553e-02, -4.4861e-03,
        -1.2501e-02, -1.0762e-02, -1.5627e-02, -2.1302e-02, -1.1751e-02,
         1.3179e-02,  1.5898e-03,  1.8918e-02, -1.5732e-02,  1.1481e-03,
        -2.9049e-02, -2.7638e-02, -1.6178e-02, -1.6009e-02,  1.8427e-02,
         1.6188e-02,  7.1549e-03,  2.5720e-02,  2.3354e-02, -2.7149e-02,
        -2.1043e-02, -6.9092e-03,  1.4704e-03,  3.0797e-03,  2.8742e-02,
        -2.3599e-02, -1.4499e-03,  6.7893e-03,  5.9710e-03, -1.0636e-02,
        -1.4978e-02, -1.1431e-02, -1.6804e-02,  6.8434e-03, -2.4820e-02,
         8.9769e-03, -2.5654e-02,  2.7437e-02,  1.1155e-02, -1.0840e-02,
         9.8275e-03, -1.1121e-02,  7.2983e-03,  2.4260e-02,  2.3018e-02,
        -1.3215e-02,  8.7351e-03,  4.8571e-03, -1.5685e-02, -1.9306e-02,
         8.5290e-03, -2.7274e-02, -2.0993e-02,  1.5149e-02, -1.8025e-02,
        -8.0960e-03, -1.4403e-02,  2.4421e-02, -1.6445e-02, -2.6767e-02,
        -1.7619e-02, -2.3499e-02, -2.6709e-03, -8.9924e-03, -9.9496e-03,
        -8.7553e-03, -1.6949e-02, -2.5865e-02, -1.2891e-02,  1.1285e-02,
         7.2749e-03,  1.7945e-03, -1.0093e-02,  1.2081e-02, -9.5854e-03,
        -2.8669e-02,  3.6068e-03,  2.9267e-03,  1.0750e-02, -2.6347e-02,
         1.6322e-02,  4.2388e-03,  7.7804e-03, -1.9148e-03,  2.7592e-02,
         1.5984e-02, -1.0625e-02, -7.5881e-03, -1.2398e-04, -2.3858e-02,
        -2.8153e-02, -1.6639e-02,  2.3050e-02,  1.3236e-03, -8.0469e-03,
        -3.3292e-03,  1.3015e-02, -2.4151e-02,  5.3790e-03,  2.5726e-02,
        -2.2566e-02, -1.6038e-02,  1.4108e-02, -5.2696e-03,  5.2173e-03,
         2.1110e-02, -2.0153e-02, -6.4344e-03, -7.5444e-03, -2.5958e-02,
        -1.6146e-03,  2.5865e-02, -3.6779e-03, -1.4699e-02,  4.2817e-03,
         1.4936e-02, -1.6699e-02,  3.6480e-03,  5.7883e-03, -2.2343e-03,
        -2.1791e-02, -1.8099e-02, -2.3028e-02, -1.5506e-02,  1.3138e-02,
         2.6275e-02,  1.3770e-02, -2.8328e-02, -4.7105e-03, -2.8921e-02,
         1.7475e-02,  2.7445e-02, -3.9785e-03, -1.5252e-02,  2.1209e-02,
        -4.4599e-03,  5.4030e-03,  2.6455e-02,  2.4380e-02, -3.8473e-03,
         1.8512e-02, -1.0109e-02,  1.0566e-02,  2.5340e-02,  2.6857e-02,
         2.8442e-02,  6.5126e-03,  7.5952e-03, -2.6139e-02,  1.4565e-02,
        -6.4394e-04,  2.6104e-02,  1.2061e-03, -1.3737e-02, -3.1694e-03,
         1.7990e-02, -1.3810e-02,  2.7313e-03,  2.6736e-02, -1.0812e-02,
        -2.4483e-02,  2.8250e-02, -1.4811e-02,  2.5254e-02,  2.1595e-03,
         2.5853e-02, -1.5821e-02, -2.9112e-04,  4.4680e-03,  6.4047e-03,
         3.8882e-03, -2.7860e-03, -1.7709e-02, -5.2834e-03, -2.8410e-02,
         1.0317e-02, -1.8669e-02,  1.3254e-02, -2.2625e-02,  2.1800e-02,
         1.7265e-03,  1.6706e-02, -3.7454e-03,  2.2885e-03,  2.3054e-02,
         2.0582e-02,  3.5120e-03, -1.1035e-03, -2.5017e-02, -4.5780e-03,
        -4.7550e-03, -1.6621e-02, -8.2461e-04,  1.0927e-02,  4.9206e-03,
        -2.8860e-02, -1.5486e-02, -4.5922e-03, -2.4953e-02, -1.6653e-03,
        -5.2745e-03,  2.3997e-02, -1.3386e-03,  2.8571e-02,  2.8104e-02,
        -1.7842e-03, -5.9200e-03,  1.1164e-02,  1.6025e-02,  1.6431e-02,
        -1.5547e-02, -1.3380e-02, -2.0289e-02,  9.5927e-03,  1.2742e-03,
         1.4241e-02,  2.4226e-02, -1.9257e-02, -1.2207e-02,  1.3509e-02,
        -1.7194e-02, -2.9244e-02,  1.8919e-03,  8.3629e-03,  1.2203e-02,
        -2.0604e-02,  1.4059e-02,  5.2929e-03,  2.1521e-02, -9.7142e-03,
         4.1240e-03,  2.2186e-02,  2.3909e-02,  1.6134e-02, -1.7298e-02,
        -5.6105e-03,  2.8310e-02,  1.8396e-02,  3.9122e-03, -4.3304e-03,
        -2.4339e-02,  5.6272e-03, -2.6762e-02,  2.8577e-02, -1.4713e-03,
        -2.1910e-02,  2.7159e-02, -8.5228e-03, -2.7619e-02,  2.4332e-03,
        -1.0354e-02,  2.0427e-02,  1.6222e-02,  1.9165e-03,  1.5159e-02,
         2.0624e-02, -2.4438e-02,  6.3505e-03,  2.1976e-02,  2.8221e-02,
         5.4101e-03,  3.4377e-03,  2.1322e-02, -7.4067e-03,  1.7500e-02,
        -4.6212e-03, -1.9946e-02, -2.8781e-02,  2.4053e-02, -9.3274e-03,
        -2.5159e-02,  1.8619e-02,  9.4476e-03, -2.0829e-02, -2.4600e-02,
         2.4961e-02, -2.6250e-04, -1.7352e-02,  6.8239e-03,  2.1068e-02,
         1.4791e-02,  1.5278e-02,  1.0014e-02,  5.8945e-03, -2.1617e-02,
        -2.2253e-02, -1.4596e-02,  2.3990e-02, -1.8116e-02,  1.7983e-02,
         2.1074e-03, -9.6594e-03, -4.0194e-03, -1.9911e-02,  1.2554e-02,
         1.6170e-02,  2.8069e-02,  2.3191e-02,  4.1218e-03,  9.1512e-04,
         1.1871e-02,  2.0682e-02, -7.5366e-03, -1.8730e-02,  2.2980e-02,
        -1.9853e-02, -2.0179e-02,  6.5764e-03, -9.1537e-04, -1.4117e-02,
        -1.8637e-02, -2.8068e-04,  1.0532e-02,  3.8011e-03, -2.8143e-02,
        -2.8735e-02, -2.6420e-02, -2.5278e-02, -3.3288e-03, -2.3561e-02,
        -1.5277e-02,  8.0779e-03,  1.2116e-02,  2.7308e-02, -9.7581e-03,
         2.0688e-03,  1.3553e-02, -4.1689e-03,  1.6083e-02,  2.5215e-02,
         1.1195e-02, -1.5277e-03, -1.0266e-03,  2.0643e-02, -8.6492e-03,
        -8.1294e-03, -1.4442e-02, -2.4472e-02, -2.3628e-02,  1.5715e-02,
         8.1595e-03, -2.4764e-02, -1.3466e-02,  2.3219e-02,  1.9490e-02,
         1.3142e-02, -1.0731e-02,  4.5702e-04,  2.5420e-02, -1.9724e-02,
        -2.1962e-03, -2.9421e-02, -2.9331e-02, -1.1917e-02, -9.9958e-03,
        -1.8438e-02, -2.5960e-02, -1.1382e-02, -2.1384e-02, -4.7211e-03,
        -2.4718e-02,  1.5361e-02,  2.4926e-02, -2.2473e-02,  2.2807e-02,
        -2.8521e-02,  2.7424e-02, -1.3067e-02,  2.5376e-02, -1.6527e-02,
         2.2095e-02, -2.3073e-02], device='cuda:0', requires_grad=True)

conv_net.6.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[ 0.0102, -0.0145,  0.0145],
          [ 0.0124,  0.0005,  0.0127],
          [ 0.0013,  0.0127,  0.0004]],

         [[ 0.0048,  0.0115,  0.0117],
          [-0.0069, -0.0070,  0.0146],
          [ 0.0085, -0.0121, -0.0044]],

         [[ 0.0143,  0.0125,  0.0097],
          [-0.0003,  0.0046,  0.0065],
          [ 0.0136, -0.0043,  0.0067]],

         ...,

         [[ 0.0129, -0.0111, -0.0097],
          [-0.0126,  0.0033, -0.0109],
          [-0.0040,  0.0112, -0.0121]],

         [[-0.0027,  0.0141,  0.0108],
          [-0.0125, -0.0023,  0.0052],
          [-0.0064, -0.0051, -0.0134]],

         [[ 0.0126, -0.0037, -0.0120],
          [ 0.0135, -0.0143,  0.0073],
          [ 0.0005,  0.0074,  0.0028]]],


        [[[ 0.0045, -0.0052, -0.0043],
          [-0.0104, -0.0087,  0.0030],
          [-0.0024,  0.0073, -0.0045]],

         [[-0.0035,  0.0032, -0.0145],
          [ 0.0023,  0.0029,  0.0040],
          [ 0.0046, -0.0082, -0.0025]],

         [[-0.0136, -0.0094,  0.0018],
          [ 0.0014, -0.0129, -0.0062],
          [-0.0006, -0.0072, -0.0027]],

         ...,

         [[ 0.0020,  0.0014,  0.0078],
          [-0.0046, -0.0082, -0.0076],
          [ 0.0104,  0.0043, -0.0041]],

         [[ 0.0083,  0.0106,  0.0023],
          [ 0.0071,  0.0035,  0.0131],
          [-0.0031, -0.0039, -0.0044]],

         [[ 0.0035,  0.0071, -0.0033],
          [-0.0118, -0.0078, -0.0011],
          [-0.0076,  0.0081, -0.0030]]],


        [[[ 0.0088, -0.0138,  0.0064],
          [-0.0076, -0.0096, -0.0025],
          [ 0.0042, -0.0116,  0.0051]],

         [[-0.0131,  0.0045, -0.0041],
          [ 0.0065, -0.0066,  0.0030],
          [-0.0091,  0.0089,  0.0050]],

         [[ 0.0146,  0.0132, -0.0039],
          [ 0.0067, -0.0099, -0.0125],
          [-0.0088,  0.0016, -0.0068]],

         ...,

         [[ 0.0009,  0.0039,  0.0146],
          [-0.0128,  0.0108,  0.0046],
          [ 0.0103,  0.0009, -0.0052]],

         [[ 0.0036, -0.0007, -0.0014],
          [-0.0102, -0.0103,  0.0112],
          [-0.0022,  0.0109,  0.0145]],

         [[-0.0094, -0.0067,  0.0015],
          [-0.0076,  0.0076,  0.0072],
          [ 0.0142, -0.0096, -0.0133]]],


        ...,


        [[[-0.0082,  0.0038, -0.0036],
          [ 0.0069, -0.0114,  0.0109],
          [ 0.0087,  0.0073, -0.0107]],

         [[-0.0089,  0.0115, -0.0085],
          [ 0.0073, -0.0038,  0.0089],
          [-0.0003, -0.0049, -0.0063]],

         [[ 0.0007, -0.0098,  0.0064],
          [ 0.0059,  0.0010,  0.0030],
          [ 0.0125,  0.0102, -0.0131]],

         ...,

         [[-0.0136, -0.0108, -0.0020],
          [ 0.0067,  0.0101,  0.0128],
          [ 0.0038,  0.0030, -0.0055]],

         [[ 0.0056,  0.0013,  0.0072],
          [-0.0039, -0.0084, -0.0061],
          [-0.0007, -0.0081,  0.0110]],

         [[-0.0110, -0.0127, -0.0105],
          [ 0.0032,  0.0088,  0.0090],
          [-0.0013, -0.0092, -0.0046]]],


        [[[ 0.0082, -0.0109, -0.0101],
          [ 0.0028, -0.0139, -0.0063],
          [-0.0113, -0.0056,  0.0092]],

         [[ 0.0093, -0.0132,  0.0119],
          [ 0.0106,  0.0064, -0.0041],
          [ 0.0002, -0.0089,  0.0031]],

         [[-0.0067, -0.0037, -0.0030],
          [-0.0068, -0.0132, -0.0015],
          [ 0.0063, -0.0022,  0.0106]],

         ...,

         [[ 0.0115,  0.0099,  0.0075],
          [ 0.0068, -0.0068, -0.0124],
          [ 0.0010,  0.0043,  0.0079]],

         [[ 0.0069, -0.0109, -0.0013],
          [-0.0089, -0.0138,  0.0138],
          [ 0.0097, -0.0144,  0.0106]],

         [[ 0.0091, -0.0022,  0.0130],
          [-0.0060,  0.0142, -0.0125],
          [ 0.0024, -0.0119, -0.0068]]],


        [[[ 0.0023,  0.0086, -0.0134],
          [-0.0014,  0.0088,  0.0063],
          [-0.0131, -0.0006, -0.0096]],

         [[ 0.0057, -0.0128,  0.0108],
          [ 0.0088, -0.0122, -0.0040],
          [-0.0019,  0.0086, -0.0049]],

         [[-0.0095,  0.0133,  0.0018],
          [ 0.0056, -0.0044,  0.0057],
          [ 0.0093,  0.0049,  0.0135]],

         ...,

         [[-0.0099, -0.0145, -0.0046],
          [ 0.0125, -0.0084, -0.0058],
          [ 0.0131, -0.0137, -0.0025]],

         [[-0.0049,  0.0059, -0.0043],
          [ 0.0138, -0.0139, -0.0087],
          [-0.0066,  0.0106,  0.0108]],

         [[-0.0099,  0.0113, -0.0009],
          [ 0.0062, -0.0111, -0.0018],
          [ 0.0074, -0.0040, -0.0004]]]], device='cuda:0', requires_grad=True)

conv_net.6.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([ 1.3820e-02, -7.2014e-03, -9.9600e-03,  1.3777e-02,  1.4426e-02,
        -1.0235e-02, -1.3739e-02,  9.8310e-03, -1.0930e-02,  1.0138e-02,
         4.6827e-03,  6.4125e-03, -8.3047e-03,  1.3640e-02,  1.2346e-02,
        -8.4717e-03, -1.3201e-02,  9.2125e-03,  4.6822e-05,  4.8179e-03,
         5.8823e-03, -1.2088e-02,  1.0685e-02,  4.4295e-04, -6.1842e-03,
         1.8791e-03,  7.0828e-03, -8.5367e-03,  9.9043e-03, -8.4067e-03,
         7.1310e-03, -1.2272e-02,  4.3126e-03, -9.1972e-03, -1.2151e-02,
         4.9373e-03,  1.4761e-03,  6.0897e-03, -1.6076e-03,  7.3966e-03,
        -6.6062e-03, -2.9936e-03,  5.0494e-03,  1.4380e-02,  6.5134e-03,
        -5.0593e-03,  1.1948e-02,  1.1848e-02, -1.0765e-02,  9.6709e-03,
         3.0556e-03, -2.2932e-03, -7.6026e-03,  4.5573e-03,  6.2591e-03,
         1.4319e-02, -1.1966e-02,  5.9194e-03,  1.0023e-02, -5.8370e-03,
        -1.0943e-02,  1.4874e-03, -9.8470e-03,  5.2227e-03,  4.4076e-03,
         9.0914e-03, -8.7356e-03,  1.4234e-02, -1.2905e-03, -9.0683e-04,
         3.2764e-03,  4.6114e-03,  6.8482e-03,  1.7984e-04,  4.9140e-04,
         1.2888e-02,  3.2610e-03,  1.3425e-02,  8.4542e-03, -5.8272e-03,
         5.1952e-03, -1.0239e-02,  1.0628e-02,  1.4052e-02, -7.0736e-03,
         4.9253e-03,  5.9041e-03,  1.0794e-02,  3.6420e-03,  1.2523e-02,
        -8.7693e-03,  7.1838e-03, -8.5572e-03,  2.9472e-03, -8.0919e-03,
         1.8628e-04,  2.8149e-03,  1.0615e-02,  1.0144e-02, -8.8165e-03,
        -2.4073e-03, -1.4058e-03, -4.7383e-03,  1.1390e-02,  5.4173e-03,
        -1.1102e-02, -7.5077e-03,  1.4317e-02,  1.9068e-03, -1.1611e-02,
         9.1579e-04, -4.0043e-03, -9.0876e-03,  1.2732e-02, -1.1892e-02,
         1.3013e-02,  1.2702e-02, -9.5502e-03, -1.2329e-02, -1.2065e-02,
        -4.9216e-03,  3.3921e-03,  3.1788e-03, -4.6661e-04,  8.3386e-03,
        -8.2540e-03,  1.1656e-02, -7.3597e-03,  2.7974e-03, -1.2439e-02,
        -1.0464e-02, -4.1313e-04, -1.3115e-02, -5.1888e-03, -1.3189e-02,
        -6.5537e-03,  4.2240e-03,  9.5641e-03,  1.2370e-02, -5.6648e-03,
        -2.3927e-03,  1.1589e-02,  1.0617e-02, -8.4537e-03, -1.3178e-02,
        -1.2573e-02,  8.0282e-03, -6.9868e-03,  6.7738e-03,  4.6724e-03,
        -7.0685e-03,  1.3294e-02, -4.0645e-04,  1.3886e-02, -3.3106e-03,
         4.6818e-03,  2.1346e-03, -2.6533e-03,  4.7278e-03,  2.3758e-03,
        -5.3690e-03,  6.3626e-03, -2.4221e-03, -4.1896e-03, -4.7158e-03,
         2.5072e-03, -1.2033e-02, -1.4184e-03,  4.5350e-03,  1.2372e-02,
         3.4200e-04, -5.1586e-03, -6.5137e-03,  3.3090e-04,  1.2800e-02,
         7.1545e-03,  1.4117e-02,  9.2405e-03,  2.6497e-03, -1.4367e-02,
        -1.1794e-02, -6.6577e-03, -9.0012e-03, -1.6997e-03, -1.3946e-02,
        -1.3222e-02,  1.0331e-02, -9.4147e-03, -2.5147e-03, -1.0801e-02,
        -1.8042e-03, -6.8536e-03, -6.9375e-04, -7.9778e-03, -9.2390e-03,
         3.9667e-03,  1.3315e-02,  7.9993e-03,  6.0119e-03, -6.3394e-03,
        -4.5505e-03,  1.1878e-02, -1.4294e-02, -1.4565e-02,  7.9680e-03,
        -2.5467e-04, -1.3062e-02,  1.0933e-02, -5.2402e-03,  2.2656e-03,
        -5.3592e-03,  1.4306e-03, -8.2064e-03, -2.7218e-03, -1.1772e-02,
         1.1290e-02,  1.3645e-02,  1.1649e-02,  5.7885e-03,  1.1816e-03,
         8.7663e-03, -2.0907e-03,  7.0617e-03,  1.2273e-02, -4.8293e-03,
         2.6251e-03,  1.1663e-02, -1.2691e-02,  5.0653e-03, -9.9308e-03,
         7.0161e-03, -7.7125e-03, -7.9958e-03, -4.4308e-03, -9.1598e-03,
         9.0282e-04,  1.1359e-02, -6.0541e-03,  6.0089e-03,  2.3317e-03,
        -3.1376e-03,  4.0491e-03,  2.7720e-03, -1.1091e-02, -8.8669e-03,
         7.7990e-04,  8.5072e-03,  1.0001e-02, -3.4657e-03, -1.1096e-02,
        -6.9776e-03, -1.2546e-02, -1.2380e-03, -1.5617e-03,  6.5824e-03,
         5.7805e-03,  1.3269e-02, -4.7106e-03,  1.2477e-02, -1.3594e-02,
         1.0983e-02, -7.1149e-03, -4.6870e-03, -1.4149e-02, -1.3423e-02,
         6.4166e-03,  5.3138e-03,  1.0305e-02, -1.1082e-02,  5.4113e-03,
        -1.4577e-02,  1.2759e-02,  9.9248e-03, -4.2282e-04, -1.2863e-02,
        -1.1227e-03, -4.6773e-03,  6.0114e-03, -1.2443e-02,  1.0500e-02,
         7.6700e-03,  9.3950e-03, -9.8132e-03, -8.0983e-05, -8.8521e-03,
         1.1182e-02, -8.1756e-03, -1.9539e-03,  2.0754e-03, -1.3926e-02,
         1.3803e-02,  9.7971e-03, -9.3245e-03,  1.0778e-02,  5.0807e-03,
        -6.9257e-03,  5.2629e-03,  1.2824e-02, -1.4379e-02, -6.5704e-03,
        -6.2776e-03,  3.1526e-03,  4.0984e-03,  5.6333e-03, -1.0704e-02,
        -6.7977e-04, -9.4624e-03, -1.1246e-02,  1.4193e-02,  1.8826e-03,
         2.9459e-04,  4.4233e-03, -9.0996e-03,  4.5779e-03,  5.1504e-03,
        -6.6881e-03, -9.6056e-03, -4.8509e-03, -4.8007e-03,  1.0474e-03,
         1.0134e-03, -2.0022e-03, -3.4308e-03, -5.7763e-03, -8.9096e-03,
        -4.5941e-03,  3.0695e-03, -1.1180e-03,  1.4062e-02,  2.6020e-03,
        -1.0843e-03, -5.2377e-03,  2.4911e-03, -1.4087e-02, -1.2159e-02,
         1.2381e-02, -1.3357e-02, -1.5542e-03, -9.0959e-03,  8.6931e-03,
         6.4433e-03,  3.7272e-03, -1.7376e-03,  9.6150e-03,  1.3510e-02,
         1.1586e-04, -1.0579e-02, -1.1240e-02, -5.4003e-03,  6.4979e-03,
         1.2248e-03,  1.1923e-02, -9.7518e-04, -4.3545e-03,  4.8462e-03,
        -1.7041e-03, -5.3791e-03,  6.4574e-03,  1.4408e-02,  1.4675e-02,
        -2.1266e-03,  1.1980e-02, -7.1509e-03,  5.4166e-04, -7.7539e-03,
         9.2580e-03,  3.7762e-03, -4.2957e-03, -8.9542e-03, -1.2097e-02,
         4.3201e-03, -1.4397e-02,  1.9818e-03, -8.1338e-03, -1.2906e-02,
         2.5450e-03, -7.4361e-03, -1.4189e-02, -9.4375e-03, -5.1938e-03,
        -1.2511e-02,  5.7442e-03,  3.0306e-03, -3.0634e-03, -5.5212e-03,
         4.5222e-03, -1.7607e-03,  8.0199e-03, -4.0341e-03,  1.2402e-02,
         1.5709e-03, -1.2172e-03, -1.1630e-02,  1.2379e-02, -6.8890e-03,
         1.4077e-02,  6.3463e-03, -4.9695e-03, -7.7876e-03, -9.0536e-03,
        -1.8289e-03, -1.3060e-03,  1.4791e-03, -1.0184e-02,  1.3980e-03,
         9.8866e-03,  1.2482e-02,  8.9411e-04,  8.9191e-03, -4.0816e-03,
         1.4565e-02,  1.2149e-02, -1.1135e-02,  8.9337e-03, -6.7283e-03,
        -1.1710e-02, -6.4151e-03, -1.0779e-02, -8.2853e-03, -8.9521e-03,
         7.3875e-03,  1.8354e-03,  8.8116e-03,  9.7478e-03,  1.4368e-02,
        -7.0391e-03, -9.1324e-03,  1.7744e-05,  1.1442e-02,  1.4220e-03,
        -3.7796e-03,  7.6068e-03, -1.2147e-02, -1.4563e-02, -1.4701e-02,
        -8.8109e-03,  2.8420e-03, -3.5633e-04,  8.8544e-03, -3.0362e-03,
        -8.1270e-03,  4.0737e-03,  1.1642e-02, -9.9188e-03, -2.1112e-03,
        -1.3994e-02,  9.8599e-03, -9.7630e-03, -4.7481e-03, -4.5420e-03,
         2.7994e-03,  3.5558e-03,  7.4443e-03, -5.3514e-04,  6.1840e-03,
        -2.6917e-03,  1.2087e-03, -3.9593e-03, -1.4363e-02,  1.2368e-03,
         1.3699e-02, -2.8809e-03,  5.6981e-03, -1.2927e-02, -1.2468e-02,
        -8.9011e-03, -5.5518e-03, -1.4638e-02,  9.3815e-03,  8.9885e-03,
         1.3026e-02,  3.4816e-03, -1.0705e-02, -1.7671e-03,  2.6453e-03,
         1.4126e-02, -1.3725e-02, -1.3631e-02, -3.0642e-03, -5.2852e-03,
        -6.9819e-03,  7.6969e-04,  1.1666e-02,  9.2171e-03,  5.2185e-03,
        -6.0744e-04, -1.3044e-02,  1.0881e-02,  7.1379e-03, -8.5204e-03,
         9.5986e-03, -1.0774e-02,  1.0888e-02,  6.5612e-03,  6.0621e-03,
         1.3475e-02,  1.1321e-02,  8.6237e-03, -2.7943e-03, -1.3433e-03,
        -9.4491e-03, -1.0694e-02,  1.1348e-02, -1.0742e-02,  3.4068e-03,
         3.6734e-03, -1.3163e-02, -7.9909e-03, -2.2793e-03,  1.4336e-02,
        -7.5034e-03, -9.6090e-03], device='cuda:0', requires_grad=True)

conv_net.9.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[ 6.0207e-03,  1.2574e-02, -2.0335e-03],
          [-1.1916e-02,  3.0457e-03, -2.4906e-03],
          [-2.1940e-03, -4.8583e-03,  1.7441e-03]],

         [[-6.8287e-03, -5.6068e-03,  6.0114e-03],
          [ 6.7234e-03, -1.1297e-02, -1.0784e-02],
          [ 9.9929e-04, -8.1564e-03, -2.0859e-03]],

         [[ 1.3184e-03, -8.4011e-03,  1.4176e-02],
          [ 4.4505e-04, -1.3782e-02, -1.4472e-02],
          [-7.6861e-03,  4.5528e-03,  8.1046e-03]],

         ...,

         [[-9.3631e-03, -1.0343e-02,  1.4124e-02],
          [-3.7922e-03,  4.6909e-03,  1.3178e-02],
          [-6.5259e-03,  1.2004e-02,  1.2415e-02]],

         [[-1.1595e-02,  1.1238e-03,  1.4263e-03],
          [ 4.1090e-03, -9.7558e-03,  5.7286e-03],
          [ 1.9859e-03,  1.3712e-03, -7.2061e-04]],

         [[ 2.4862e-03, -1.1459e-02, -2.2858e-03],
          [-2.3177e-03, -3.3084e-03,  1.2215e-02],
          [ 1.0181e-02,  4.5712e-03, -3.0777e-03]]],


        [[[ 7.5193e-03, -7.9795e-04,  1.3299e-02],
          [ 1.4522e-02,  1.4518e-02, -1.3129e-02],
          [ 3.5983e-03,  6.4734e-05,  2.1759e-03]],

         [[ 6.3859e-03, -1.2925e-02, -1.7773e-03],
          [-8.7237e-03,  1.1556e-02, -6.2291e-03],
          [-9.0487e-03, -6.4002e-04, -4.1158e-03]],

         [[-4.8356e-03,  4.0627e-03,  2.0648e-03],
          [ 6.1958e-04, -6.9843e-03, -9.1592e-03],
          [-1.1329e-02, -1.2460e-02,  1.4413e-02]],

         ...,

         [[ 1.9149e-03, -1.2092e-02, -2.7576e-03],
          [-3.2466e-04, -7.3353e-03, -9.0504e-03],
          [ 1.4421e-02, -3.0060e-04, -8.9937e-03]],

         [[ 7.4389e-03,  1.3099e-02,  4.9667e-03],
          [-1.4041e-02,  1.3902e-02, -9.6909e-03],
          [-1.2794e-02,  6.6625e-03, -7.3161e-03]],

         [[-5.3811e-03, -9.8170e-03,  5.5296e-03],
          [-1.1509e-02,  4.5460e-03, -2.1970e-03],
          [ 2.2430e-03, -1.1757e-02,  1.2748e-02]]],


        [[[ 1.3653e-02, -1.2571e-02, -1.3439e-02],
          [ 6.5999e-03, -7.0002e-03, -1.3666e-02],
          [ 9.0555e-03,  8.5385e-03,  2.3192e-03]],

         [[-1.2523e-02,  4.8057e-03, -2.3566e-03],
          [-8.9734e-03, -1.1201e-02,  3.8974e-04],
          [ 2.5287e-03, -1.2581e-02,  1.0742e-02]],

         [[ 7.2376e-03, -5.3179e-03,  6.6917e-03],
          [ 4.7139e-03, -6.2288e-03,  1.6990e-03],
          [ 4.5962e-03,  1.1692e-02, -1.2054e-02]],

         ...,

         [[-1.0314e-02,  2.9864e-03, -1.0377e-02],
          [ 1.1101e-02,  1.0709e-02, -1.1153e-02],
          [ 1.2230e-03,  1.2921e-02,  1.0860e-04]],

         [[-8.4974e-03,  6.3186e-04,  6.0964e-03],
          [-3.6274e-03,  1.0766e-02, -1.2314e-02],
          [-1.1578e-02, -7.7452e-03, -1.1866e-02]],

         [[-3.9125e-03, -5.6635e-03, -1.5492e-03],
          [ 9.4130e-03,  7.1697e-03, -2.9141e-03],
          [ 7.8009e-04,  6.7407e-03,  8.4776e-03]]],


        ...,


        [[[-1.4116e-02, -7.3928e-03,  7.8224e-03],
          [-8.4225e-03,  6.7108e-03,  7.0644e-03],
          [ 1.4063e-02,  1.3692e-02, -5.7251e-03]],

         [[-4.5823e-03, -1.3246e-02, -2.0535e-03],
          [ 4.0088e-03,  1.1787e-02,  4.7775e-03],
          [-3.9087e-03,  1.1359e-02,  1.1141e-03]],

         [[ 5.4945e-03, -2.7029e-03,  1.0550e-02],
          [ 8.3077e-03,  1.0786e-02, -4.7864e-03],
          [ 1.2933e-02,  8.9600e-03, -5.8924e-03]],

         ...,

         [[-8.6232e-03, -1.1901e-02, -8.4958e-03],
          [-8.6337e-03, -6.2101e-03,  3.6157e-03],
          [-8.9478e-04,  1.2327e-02, -1.4227e-02]],

         [[-1.1205e-02, -2.3800e-03,  5.8711e-03],
          [ 8.3614e-03, -6.9615e-03,  6.2041e-03],
          [-3.8647e-03, -5.9055e-03,  1.3960e-02]],

         [[-2.3739e-03, -7.9703e-03, -1.4069e-02],
          [ 2.9022e-03,  6.1576e-04, -1.3710e-02],
          [-1.3386e-02,  1.1835e-02,  1.2474e-02]]],


        [[[-2.8192e-03, -1.0211e-02,  5.7519e-03],
          [-1.0021e-02, -6.5917e-03, -7.7221e-03],
          [-2.1522e-03, -1.3947e-02,  1.2796e-03]],

         [[ 9.2868e-03, -1.4300e-02,  1.0407e-02],
          [ 6.8207e-03, -1.3635e-02,  1.0950e-02],
          [-4.8676e-03,  1.1909e-02, -1.2433e-03]],

         [[ 1.3171e-02, -3.0027e-03, -6.8117e-03],
          [-1.3738e-02, -1.3414e-02, -3.3775e-03],
          [ 1.2288e-02, -2.3766e-04,  9.5104e-03]],

         ...,

         [[-5.7037e-03, -4.6871e-03, -1.2793e-02],
          [ 1.0568e-04, -3.7327e-03, -9.7112e-03],
          [ 1.4542e-02, -7.2187e-03,  5.7258e-04]],

         [[ 1.3556e-02,  6.3493e-03,  4.8005e-03],
          [-2.4958e-03, -1.4567e-02,  1.2855e-02],
          [-1.1720e-03, -8.1885e-03,  1.3422e-02]],

         [[ 1.6250e-03,  1.4145e-02,  3.8055e-04],
          [ 5.0376e-03,  7.4414e-03,  1.3161e-02],
          [-6.4726e-03,  1.2329e-02,  2.1142e-03]]],


        [[[ 1.3336e-02, -4.5905e-03, -7.3861e-03],
          [ 4.0759e-03, -5.3316e-03, -6.3734e-03],
          [-1.2869e-02, -1.3248e-02,  1.0361e-02]],

         [[-6.8362e-03, -7.4794e-03, -9.9503e-03],
          [ 7.7024e-03, -6.7041e-03,  1.0510e-02],
          [-8.5574e-03,  4.8134e-03,  9.9204e-04]],

         [[ 8.9614e-03,  8.2595e-03,  5.8107e-03],
          [ 5.4913e-03, -2.5330e-03,  6.8002e-03],
          [ 1.4167e-02,  1.9411e-03, -1.0802e-02]],

         ...,

         [[ 6.0346e-03,  8.5689e-03,  1.1812e-02],
          [ 1.4818e-03,  3.9060e-03,  7.7908e-03],
          [-8.6819e-03,  8.7987e-03,  7.2421e-03]],

         [[-1.3868e-02, -9.2014e-03,  1.0067e-02],
          [-1.4883e-04, -1.1487e-02,  5.1362e-03],
          [ 1.1805e-03, -7.5377e-03, -4.0748e-03]],

         [[-7.6228e-03, -1.1804e-03, -9.9108e-03],
          [ 7.5655e-03,  4.5128e-03,  1.0718e-02],
          [-1.2733e-02,  1.0456e-02,  2.3465e-03]]]], device='cuda:0',
       requires_grad=True)

conv_net.9.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([ 7.3426e-03,  5.0608e-03, -3.5635e-03, -4.3965e-03,  4.5611e-03,
         6.1631e-04,  7.3287e-03,  1.2401e-02,  1.1388e-02,  3.1341e-03,
         1.3527e-02,  9.6208e-04,  1.0104e-02,  1.1183e-02, -7.7759e-03,
         5.5293e-04, -3.0234e-03, -2.1476e-03,  7.8714e-03, -1.1454e-02,
         9.4994e-03,  9.5051e-03,  4.5450e-03, -1.1422e-02,  4.6099e-03,
         8.2912e-03,  5.8323e-03,  4.5351e-03,  6.2096e-04,  8.3616e-03,
         2.5053e-04,  1.1497e-02, -4.9359e-03, -4.8241e-03, -9.6306e-03,
        -3.6574e-03,  1.5909e-03, -9.2211e-03, -1.0129e-03, -6.9243e-03,
         2.6496e-03, -6.0826e-03, -6.9373e-03,  8.2371e-03,  1.4484e-02,
        -9.6793e-03,  5.0021e-03, -8.0626e-03, -1.0010e-02,  6.1854e-03,
         8.9034e-03, -8.2821e-03,  9.3860e-03, -7.8971e-04,  2.4638e-03,
        -1.7534e-03, -1.2097e-02, -7.6188e-03, -4.8364e-03,  2.1578e-03,
        -1.2796e-02,  8.8981e-03, -8.8441e-03, -4.1972e-03, -5.8721e-03,
        -9.5171e-03, -7.7651e-03,  1.4574e-02, -4.6527e-03, -3.7665e-04,
        -1.2870e-02, -3.8843e-04,  4.9352e-03,  1.3120e-02, -3.7347e-03,
        -3.4467e-03, -4.6583e-03,  3.9395e-03, -6.9494e-03, -1.4212e-02,
         1.3041e-02, -1.2137e-02, -1.1280e-02,  1.0393e-02, -8.3155e-03,
         9.5019e-03,  1.0031e-02, -1.0422e-02,  1.2760e-02,  5.9002e-03,
         1.4434e-02,  2.5171e-04,  6.9934e-03,  7.3258e-03,  1.4557e-02,
        -1.3230e-02, -3.9689e-03,  2.9207e-03,  6.0763e-03, -5.6615e-03,
        -1.0507e-02,  1.0314e-04,  8.3119e-03, -1.3430e-02,  8.9729e-03,
         2.2425e-03,  9.0773e-03, -1.2791e-04,  1.4722e-02, -4.9388e-03,
         6.3060e-03, -7.6335e-03, -7.2096e-03,  1.1083e-02, -1.1789e-02,
        -3.9636e-03, -9.6863e-03,  2.9727e-03, -5.7035e-03,  1.1874e-02,
         3.2704e-03, -1.3523e-02,  8.4016e-03, -8.5430e-03, -1.0210e-02,
         7.0393e-03, -7.7254e-04,  1.1100e-02, -6.6372e-03,  1.3106e-02,
         1.4435e-02, -9.1553e-03, -6.3082e-03,  3.6647e-03,  6.7591e-03,
        -7.0109e-03,  8.1525e-03,  1.3010e-02,  6.1929e-03, -1.4183e-02,
        -3.4236e-03,  1.3734e-02, -8.8977e-04, -1.3015e-02, -1.3813e-02,
        -8.7497e-03, -6.8124e-03, -3.5815e-03,  6.9086e-03, -7.1384e-03,
         4.5214e-03, -1.1656e-02, -3.4034e-03, -2.7661e-03,  2.0306e-03,
         1.4095e-02, -5.4575e-03,  1.3212e-02,  3.1635e-03,  3.4393e-03,
         1.2537e-02, -6.2600e-04, -7.3544e-03,  1.3087e-02, -2.5001e-03,
        -1.0939e-03, -8.7307e-03,  5.3069e-03, -1.2060e-02, -4.5204e-04,
         5.5732e-03,  2.0541e-03, -3.4693e-03,  3.7760e-03,  2.2378e-04,
        -6.0047e-03, -1.2084e-02,  1.0474e-03, -2.7543e-03, -1.0674e-02,
         1.2271e-02,  4.7066e-03,  1.0855e-02, -1.1460e-02,  4.0952e-03,
         1.3287e-02, -1.8085e-03, -1.3954e-02, -1.0250e-02, -8.5711e-03,
        -3.1428e-03, -6.7660e-03, -8.8257e-03, -1.3684e-02, -6.6541e-03,
        -9.6627e-03, -6.8642e-03,  4.1840e-03, -2.1514e-03,  3.0231e-03,
         1.6997e-03,  1.2421e-02, -5.9352e-03, -9.5146e-04, -7.1673e-03,
        -3.9630e-03,  2.1256e-03,  2.3443e-03, -8.4278e-03, -3.8847e-03,
         6.8288e-03,  3.1336e-03, -3.6253e-03, -8.8511e-03, -1.2616e-02,
        -9.6931e-04, -5.3207e-03, -1.2241e-02, -2.7882e-03,  1.1036e-02,
         1.6783e-03, -5.0639e-03,  6.7761e-03, -3.2860e-03, -1.9412e-03,
        -5.8850e-03, -2.9544e-03,  1.2786e-02, -8.0840e-03, -4.3126e-03,
        -3.9175e-03, -1.4885e-03, -7.4550e-03,  1.2612e-02,  9.6053e-03,
        -6.3902e-03,  1.3285e-02,  2.0334e-03,  1.4164e-02, -4.6313e-03,
        -9.3494e-03, -1.4528e-02, -1.1850e-02, -1.1136e-02, -2.1459e-04,
         6.2083e-03, -1.1903e-02, -2.8732e-03, -7.8691e-03,  1.1850e-02,
        -1.0733e-02,  1.4649e-03, -1.0460e-02,  2.2335e-03, -2.5202e-03,
         1.0530e-02, -9.5659e-03, -1.0994e-02, -3.1455e-03,  1.2897e-02,
        -3.0766e-03, -3.9742e-03, -4.5410e-03, -1.0755e-02,  6.3898e-03,
         8.6729e-03, -1.3561e-02,  8.4439e-03, -1.0828e-02,  3.9178e-03,
        -8.6319e-04, -1.9085e-03, -1.3366e-02, -1.0543e-02,  1.4079e-02,
        -2.3105e-03, -1.4381e-02, -1.0247e-02, -1.8859e-03, -2.5577e-04,
        -5.9766e-03,  1.3342e-02, -2.6492e-04,  5.0702e-03, -4.2828e-03,
         1.0206e-02, -2.9799e-03,  1.1204e-02,  5.0537e-03,  1.7372e-03,
         1.0631e-02,  4.8845e-03,  9.6262e-03,  6.8603e-03, -1.3345e-02,
        -3.3075e-03, -5.7076e-04, -1.0162e-02, -2.6128e-03,  5.8423e-03,
         3.1190e-03, -4.8615e-03, -9.9791e-03,  8.3884e-03,  1.4519e-02,
        -2.6352e-03,  1.0830e-02, -5.5453e-03, -1.2576e-02, -9.1628e-03,
        -3.8779e-03,  9.0347e-03,  1.4452e-02, -1.1000e-02,  1.2793e-02,
        -1.2568e-02,  3.3435e-03, -3.4510e-03,  1.4724e-02, -1.2529e-02,
         8.6011e-03,  1.7761e-03, -6.5853e-03, -2.3069e-03, -1.3524e-02,
         3.3178e-04, -1.3492e-02,  1.3594e-02,  7.5822e-03, -1.0506e-02,
         7.1927e-03, -5.7072e-03,  3.5129e-03,  2.5324e-03, -7.7265e-03,
        -1.1053e-02, -1.0633e-02, -3.3505e-03,  1.1195e-02,  4.7766e-03,
         1.1904e-02, -4.8519e-03, -6.7710e-03, -9.0121e-03, -1.0420e-02,
         5.9820e-03, -1.2407e-02, -3.4454e-03,  9.2510e-03, -8.1007e-03,
         7.2566e-03,  1.3374e-02, -1.1896e-02,  1.4406e-02, -5.2224e-03,
        -1.3833e-02, -1.4000e-02,  6.1460e-04,  3.0833e-03, -1.1069e-03,
        -8.3436e-03,  4.3296e-03,  1.1308e-02,  1.7288e-03,  1.2433e-02,
         7.4786e-03, -1.0617e-02, -8.2403e-03,  2.0477e-03, -5.0817e-03,
        -5.5197e-03,  1.1667e-02, -6.5242e-03,  6.7610e-03, -2.7314e-03,
         5.9694e-03, -1.2256e-02,  9.9321e-03, -3.7320e-03,  9.9621e-03,
        -1.4274e-02,  1.2148e-02, -8.8147e-03,  9.4665e-03,  1.0432e-02,
         5.9494e-03,  9.5159e-04,  1.4590e-02,  1.3298e-03,  6.5780e-03,
         1.8969e-03, -3.4256e-03,  5.7726e-03, -6.3720e-03,  2.9486e-03,
        -1.4568e-02, -4.9694e-04, -7.4477e-03,  1.3032e-02,  1.3115e-02,
         3.9872e-03, -9.4655e-03, -2.0854e-03, -1.4085e-02,  3.1067e-04,
        -1.0911e-02,  1.6438e-03, -7.7452e-03,  2.5582e-03,  8.5273e-03,
        -9.3215e-04, -1.1286e-02,  1.4531e-03,  1.3827e-02, -8.3320e-03,
         2.2157e-03,  1.2253e-03,  7.6586e-03, -5.0491e-03,  1.2518e-02,
        -1.5520e-03,  2.7338e-03, -2.3173e-03,  1.3434e-02,  4.8751e-03,
         1.7807e-03,  4.6856e-04,  1.1488e-02, -1.4341e-02, -9.1642e-03,
        -2.8910e-03,  4.4890e-03,  5.3817e-03,  3.0160e-03,  7.1422e-03,
        -9.9092e-03,  5.7622e-04, -1.0601e-02,  1.5925e-03,  5.6226e-04,
        -1.0020e-02, -4.3455e-03, -2.5999e-03, -1.3105e-02, -7.4864e-03,
         8.9594e-03, -1.0183e-02, -3.0741e-03, -5.8704e-03,  1.1730e-02,
        -1.6344e-03,  1.3773e-02,  9.5536e-05,  1.1743e-02, -8.9788e-03,
         1.3954e-02, -1.0363e-02,  1.0683e-02, -8.5087e-04, -1.2518e-02,
         1.3316e-02, -4.1735e-03,  3.4521e-03,  8.5353e-03,  1.1478e-02,
         1.3375e-02, -1.3108e-02,  4.1165e-03, -4.2831e-03,  1.3062e-02,
        -1.4702e-02, -1.3645e-03,  2.0758e-03,  1.4054e-03,  3.3528e-03,
        -1.2420e-02, -1.8111e-03,  1.2753e-02, -4.3525e-03, -1.2879e-02,
        -6.3231e-03, -4.5171e-04, -6.1754e-03, -5.4367e-03, -1.0575e-02,
         3.7815e-04, -5.0571e-03, -1.1441e-02,  1.0185e-02, -8.9795e-03,
        -1.0785e-02, -4.3041e-04, -3.5391e-03,  7.0827e-03, -3.0324e-03,
        -7.0202e-03, -1.3183e-02, -2.3109e-03,  6.6246e-03, -5.8425e-03,
         6.5276e-03, -1.2458e-02,  1.3485e-02, -1.3764e-02, -5.1852e-03,
        -9.6815e-03, -1.3162e-02,  9.5596e-03, -1.1552e-03, -8.0671e-03,
        -7.8928e-03, -1.4087e-02], device='cuda:0', requires_grad=True)

conv_net.12.weight, torch.Size([512, 512, 3, 3]), # params: 2359296, Parameter containing:
tensor([[[[-7.6791e-04, -7.5946e-04, -2.6459e-03],
          [-1.0035e-02, -1.2555e-02, -9.2460e-03],
          [-2.0794e-03, -1.1734e-02, -3.9817e-03]],

         [[ 8.6834e-03,  5.9596e-03,  5.1615e-03],
          [-1.4138e-02,  9.5422e-03,  1.3506e-03],
          [ 1.4245e-02,  6.0462e-03,  7.1677e-03]],

         [[-7.8323e-04, -1.1032e-02, -1.5149e-03],
          [-2.6397e-03,  5.5576e-03,  1.0170e-02],
          [-1.2315e-02,  5.6252e-03,  3.7022e-03]],

         ...,

         [[ 3.4653e-04, -1.1121e-02, -8.9887e-03],
          [ 9.5876e-03,  3.1027e-04,  9.3245e-03],
          [ 4.3524e-03, -1.4223e-02, -2.4632e-03]],

         [[ 8.7780e-03, -1.2790e-02,  1.3182e-02],
          [ 1.2425e-02,  1.4272e-02, -9.4746e-03],
          [-5.1896e-03,  5.5027e-03, -1.3926e-02]],

         [[ 1.0913e-02,  1.3284e-02,  1.4140e-02],
          [-3.1009e-04,  5.7847e-03, -1.1546e-02],
          [-4.9024e-03,  1.3127e-02,  3.0961e-03]]],


        [[[-2.1913e-04, -3.4781e-04, -6.9086e-03],
          [ 1.1397e-03,  7.8278e-04, -1.4222e-02],
          [ 1.2199e-02,  1.4251e-02, -7.2407e-03]],

         [[ 9.1624e-03,  5.0935e-03, -5.0229e-03],
          [-1.2643e-03, -1.5373e-03,  1.4639e-03],
          [-1.5716e-03,  1.0174e-02,  1.3071e-02]],

         [[-1.1153e-02,  8.7370e-03, -1.2930e-02],
          [ 4.0360e-03,  7.6721e-03,  6.1995e-03],
          [-9.6755e-03,  2.8845e-04,  6.3349e-03]],

         ...,

         [[ 2.8408e-03,  7.3148e-03, -1.0573e-02],
          [-8.2868e-03, -9.5104e-03, -1.2922e-02],
          [ 4.7759e-04, -1.1883e-02, -9.0088e-03]],

         [[ 8.0060e-03,  4.9328e-04, -1.3217e-02],
          [ 1.3659e-02,  3.0218e-05, -2.7019e-03],
          [ 8.4650e-04,  6.6578e-03,  6.6979e-03]],

         [[-5.7404e-04,  1.1703e-02,  1.3984e-02],
          [-2.7662e-03, -8.1998e-03, -6.2116e-03],
          [-2.2069e-03,  2.7698e-03,  8.7062e-03]]],


        [[[-1.3067e-02,  9.4402e-05,  1.0915e-02],
          [-4.0918e-03,  7.4674e-03,  9.1153e-03],
          [-1.5496e-03,  6.3544e-04, -9.2414e-03]],

         [[ 3.7457e-03,  7.0961e-03,  4.4362e-03],
          [-1.2987e-02, -1.2560e-02, -1.1771e-02],
          [-7.4820e-03,  4.7500e-03,  1.0854e-02]],

         [[-7.5002e-03,  1.0347e-02,  1.0629e-02],
          [ 1.0364e-02,  5.8776e-03,  1.2172e-02],
          [ 2.4756e-03,  9.3717e-03, -2.8268e-03]],

         ...,

         [[-1.0071e-02, -5.4146e-03,  4.2558e-03],
          [-1.2761e-03,  7.3637e-03, -3.6691e-03],
          [-3.3652e-03, -1.3799e-02,  4.6234e-03]],

         [[-5.8239e-03,  2.2391e-03, -3.2394e-03],
          [-1.1165e-02, -8.4229e-03,  2.2534e-03],
          [ 1.0170e-02, -6.4886e-04, -3.4181e-03]],

         [[ 4.2328e-03,  1.0353e-02, -1.1676e-02],
          [ 1.3324e-02,  5.7931e-03,  1.0938e-02],
          [-3.3763e-03, -1.0966e-02,  4.4402e-03]]],


        ...,


        [[[-7.0147e-03, -7.1280e-03,  1.4928e-03],
          [-1.4728e-02, -1.3514e-02, -1.0726e-02],
          [ 1.8184e-03,  1.3988e-02,  1.3159e-02]],

         [[ 8.7075e-03,  2.3157e-03, -6.5369e-03],
          [ 1.0326e-02,  6.2605e-03,  2.9020e-03],
          [ 9.9381e-04, -6.4657e-03, -1.3634e-02]],

         [[ 1.4263e-02, -7.4572e-03,  9.6306e-03],
          [-1.1602e-02, -6.3034e-03, -8.6642e-03],
          [-1.4724e-02,  1.1180e-02,  5.8231e-04]],

         ...,

         [[-9.6460e-03, -5.4337e-03, -1.1824e-02],
          [ 1.1733e-02, -1.5214e-03, -6.1574e-03],
          [-5.6754e-03, -2.3811e-03,  7.3293e-03]],

         [[-1.1200e-02,  1.1909e-02,  9.2076e-03],
          [-9.9148e-03,  3.0309e-03,  1.7746e-03],
          [-5.2418e-03,  1.3355e-02, -1.2909e-03]],

         [[ 5.0009e-04,  1.2910e-02,  1.0501e-02],
          [ 1.1909e-02, -2.1496e-03, -7.9105e-03],
          [-1.2114e-02, -3.2517e-03,  1.3864e-02]]],


        [[[ 4.5192e-04, -1.2498e-02,  2.3854e-03],
          [-1.1136e-03,  1.7405e-03,  1.0333e-03],
          [-1.5135e-03,  5.3736e-03, -7.8730e-03]],

         [[-1.4683e-02, -3.7282e-03,  8.2577e-04],
          [-1.2696e-02, -2.1883e-03,  1.8006e-03],
          [ 5.0431e-03, -1.0374e-02,  6.1255e-03]],

         [[-5.7528e-03, -1.3696e-02,  8.7255e-03],
          [ 2.3787e-03,  5.9962e-03,  5.7637e-03],
          [-1.0655e-02,  4.2078e-03,  6.8042e-03]],

         ...,

         [[-6.1157e-03, -1.0264e-02, -1.1451e-02],
          [-1.0027e-02, -9.1821e-03, -4.4991e-03],
          [-4.1696e-03, -1.1708e-02, -1.1512e-02]],

         [[ 2.1755e-03,  1.5069e-03,  1.2171e-02],
          [ 2.7423e-03, -4.4019e-03, -1.0571e-02],
          [-4.0641e-03,  2.7150e-03,  1.1319e-02]],

         [[ 9.2235e-03,  8.1440e-03,  7.5935e-03],
          [ 1.0060e-02,  7.9310e-03, -8.2045e-03],
          [ 1.0301e-02, -1.2964e-02,  2.6811e-03]]],


        [[[ 1.1091e-02, -7.0719e-03, -7.9799e-03],
          [ 1.1661e-02, -1.2801e-03,  1.4224e-02],
          [ 4.7644e-03,  1.1325e-02,  1.2690e-03]],

         [[ 7.2338e-05,  1.3200e-03,  1.3915e-02],
          [-1.2769e-02,  1.3719e-02,  5.8216e-03],
          [-2.8314e-05, -4.7918e-03, -2.4903e-03]],

         [[-1.3298e-02, -4.8074e-03, -1.0023e-02],
          [ 8.7887e-03, -3.3645e-03,  1.0754e-02],
          [ 9.3377e-03,  9.0634e-03, -1.9410e-03]],

         ...,

         [[ 1.0372e-02,  2.4266e-03, -6.1244e-03],
          [-4.7886e-03,  6.2042e-03,  6.3526e-03],
          [ 4.3563e-03,  1.4494e-02,  6.0661e-03]],

         [[-3.1611e-03,  7.2717e-03, -9.1293e-03],
          [-1.2871e-02,  9.6860e-04,  1.8389e-03],
          [ 1.1620e-02,  9.5430e-03,  1.4062e-02]],

         [[-6.7829e-03,  1.2834e-03,  9.2188e-03],
          [-8.4565e-03,  4.5837e-03,  1.3522e-02],
          [-5.3839e-04, -9.8804e-03, -2.7461e-03]]]], device='cuda:0',
       requires_grad=True)

conv_net.12.bias, torch.Size([512]), # params: 512, Parameter containing:
tensor([-1.3396e-02,  6.5194e-03, -7.8576e-03,  8.6128e-03, -7.0688e-03,
        -1.6031e-03, -1.1601e-02,  6.8137e-03,  1.3511e-02,  5.8600e-03,
        -5.4260e-03,  3.5375e-03,  4.2223e-04, -1.4045e-02,  6.4503e-03,
        -1.4064e-02, -5.1046e-04,  1.2336e-02, -4.7452e-03, -5.0329e-03,
         3.4594e-03,  9.3648e-04,  3.8624e-03,  1.2689e-02,  5.6638e-03,
         1.0437e-02, -6.9492e-03,  8.1330e-03,  2.6069e-03,  7.7060e-03,
        -1.1845e-02,  3.0889e-03,  6.0583e-03, -1.8341e-03,  4.3730e-04,
        -1.0181e-03,  1.3113e-02, -2.3668e-03, -1.0860e-02, -2.0667e-03,
        -1.0479e-02,  1.2185e-02, -6.3215e-03, -6.9851e-05, -1.3515e-02,
         1.3908e-02, -9.8538e-03,  7.9598e-03,  1.3282e-05,  1.8234e-03,
        -1.3962e-02,  1.0119e-02,  4.4526e-04, -6.6143e-03, -2.5439e-03,
         5.0225e-03,  1.0314e-02,  5.0130e-03,  1.1688e-02,  2.0703e-03,
         3.9079e-03, -2.0648e-04,  1.2841e-02,  3.2619e-03,  1.0375e-02,
         1.0980e-02, -1.2675e-02,  1.2284e-02,  1.2392e-02,  9.1964e-03,
        -4.5686e-03,  1.4067e-02, -8.1466e-03, -1.4623e-02,  9.5384e-03,
        -1.0348e-02, -1.8784e-03,  2.5870e-03, -7.9218e-03,  1.3717e-02,
        -3.4942e-03,  1.0705e-02, -1.3326e-02, -1.0089e-02,  1.2516e-02,
        -1.2348e-02, -1.4013e-02, -1.3792e-02,  1.2642e-02, -8.1713e-03,
        -1.4386e-02, -1.3874e-02,  6.2767e-03,  1.1286e-03, -6.3853e-03,
         2.8460e-03, -7.3233e-03, -1.2886e-02,  1.4147e-02, -1.2593e-02,
         4.3409e-03,  1.4772e-03,  7.8665e-04, -1.0062e-02,  5.2410e-03,
        -9.0671e-04, -1.1456e-02,  5.3191e-03, -9.3684e-03,  3.4144e-03,
         1.2609e-03, -1.3818e-02,  4.6982e-03,  4.4130e-03, -1.0842e-02,
        -8.1359e-03,  3.1373e-03,  3.8729e-03, -1.0410e-02, -6.3861e-03,
        -1.6611e-03, -1.4572e-02, -1.4390e-02,  1.4237e-02,  9.2250e-03,
         4.9442e-03,  4.1334e-03, -1.0664e-02, -9.5189e-03, -1.5776e-03,
        -5.5892e-04,  1.2952e-02, -1.2759e-02, -4.0212e-03,  6.3747e-06,
        -1.3192e-02,  7.3667e-03, -1.3776e-02, -1.0033e-02,  8.4292e-03,
        -7.7628e-03, -3.0071e-03,  5.5041e-03, -8.3819e-03, -2.3824e-03,
         1.1914e-02, -9.1998e-03, -1.3396e-03, -5.6392e-03,  6.9410e-03,
        -3.9928e-04, -4.1731e-03, -3.5349e-03, -9.5307e-03,  2.6379e-04,
        -7.5528e-03, -6.5706e-04, -5.1067e-03,  1.3151e-02, -3.9417e-03,
         1.2496e-02,  7.4165e-03, -9.4690e-03, -3.5541e-03,  8.3020e-04,
        -7.1137e-03, -5.3008e-03,  1.0745e-02, -4.0694e-03,  5.5074e-03,
        -6.9296e-03,  2.0021e-03, -5.4303e-03, -5.9638e-03, -9.8432e-03,
         1.8505e-03,  8.8083e-03, -7.9396e-04, -6.5192e-03,  5.6321e-03,
        -1.1064e-02, -5.3975e-03, -7.4808e-03,  1.0120e-02, -1.1923e-02,
         2.8939e-03,  5.9309e-03, -4.2352e-03, -8.6358e-03,  5.0030e-03,
         4.6156e-03,  9.9321e-03,  5.5161e-03, -2.2633e-03, -3.7905e-03,
        -7.1524e-03, -9.1708e-03, -1.4404e-02,  2.8155e-03,  3.9334e-03,
        -2.5476e-03, -5.8649e-03,  8.2489e-03, -9.0549e-03, -1.8381e-03,
         1.0918e-02, -9.6780e-03,  5.7965e-03, -3.2871e-03,  1.4309e-02,
        -3.4790e-04, -3.3916e-03, -2.9727e-03, -4.1949e-03,  1.2181e-02,
        -1.4385e-02, -8.9789e-03, -9.6745e-03, -1.2549e-02, -6.5184e-03,
        -1.2680e-02, -5.0598e-03, -5.7481e-03,  5.9075e-03,  7.5819e-03,
        -1.3143e-02,  1.5180e-03,  8.1555e-03, -1.2370e-02, -2.2580e-03,
        -9.3820e-03, -1.8001e-03, -1.9623e-03, -1.2299e-02, -1.2522e-02,
        -1.3599e-02,  5.8295e-03, -4.5976e-03,  1.4021e-02, -2.9356e-03,
         8.1463e-04,  3.5649e-03, -6.8284e-03,  1.3806e-02, -2.1598e-03,
        -1.0229e-02, -3.7838e-03, -1.0973e-02, -9.7615e-03,  1.1369e-02,
        -1.9871e-03,  2.4199e-03,  3.3426e-03, -1.3379e-02,  6.0266e-03,
        -7.7813e-03, -1.1115e-02, -8.4324e-03, -1.0434e-02, -5.5455e-03,
        -6.9081e-03,  8.8161e-03, -9.2326e-03, -9.5630e-03,  1.2286e-03,
        -1.0259e-02,  8.9501e-03, -3.7551e-03,  1.0719e-02, -1.2441e-02,
         6.7129e-03, -6.7492e-03,  1.1911e-02, -1.5737e-03, -2.5400e-03,
         4.6254e-04, -3.9260e-03,  1.2674e-02, -2.0052e-03, -1.1623e-02,
        -5.9209e-03, -3.3643e-03,  3.1716e-03,  1.3850e-02,  7.6735e-03,
         2.9166e-03, -1.2825e-02, -1.2878e-02, -7.7548e-03, -8.1865e-03,
        -1.3288e-02,  6.7659e-03,  2.6325e-03,  1.9449e-03,  8.0271e-03,
         4.2563e-03,  8.0201e-03,  8.8302e-03, -1.0837e-02,  1.4614e-02,
         5.8174e-03,  5.8172e-03,  1.0123e-02,  1.0733e-02,  9.2253e-03,
         7.3217e-03,  6.0192e-03, -1.5667e-03, -8.7801e-03, -6.3116e-03,
        -2.3129e-03, -5.2987e-03, -8.8907e-03,  3.4788e-03, -5.6884e-03,
         1.3525e-02,  5.3827e-03,  5.6321e-03, -4.4648e-03, -3.5052e-03,
        -1.9157e-04,  4.6689e-03,  9.6143e-03, -6.5920e-04, -8.4376e-03,
        -5.2230e-03,  7.7175e-03,  7.9016e-04, -8.1766e-03,  1.4211e-02,
         6.6297e-03, -1.2216e-02,  2.3378e-03, -9.9200e-03,  1.3763e-02,
        -1.0008e-02, -1.2564e-02, -1.3502e-02,  2.0737e-03,  6.7312e-03,
        -1.3254e-02,  2.2014e-03, -4.6814e-03,  3.9414e-03, -9.5430e-03,
        -1.3406e-02, -9.1605e-03, -1.0144e-02,  6.5414e-03,  1.0628e-02,
         1.1055e-03,  4.2070e-03, -2.0102e-04,  3.7664e-03,  4.5320e-03,
        -8.7536e-03, -8.5332e-03, -1.1368e-02,  5.4573e-03, -2.0657e-03,
         5.6598e-04, -6.9105e-03, -1.2586e-03,  1.0083e-02,  8.6153e-03,
         6.6642e-03, -3.8805e-05, -1.0377e-02, -1.2368e-02,  1.2578e-02,
         4.5213e-03,  1.0391e-02,  3.4889e-03, -5.0234e-03, -6.5515e-03,
        -1.3496e-02, -4.2750e-04, -5.5189e-03, -2.1206e-03, -2.7854e-03,
         3.7464e-03, -1.9065e-03, -7.5911e-03,  1.1713e-02,  1.6086e-03,
         1.2437e-02,  1.2294e-03, -1.2357e-02, -3.0890e-03, -1.2786e-02,
         1.0752e-02,  1.4169e-02,  1.1784e-02,  5.2216e-03, -1.1086e-02,
         8.8995e-03,  6.9849e-03, -1.0904e-02,  6.7283e-03, -1.0540e-02,
         1.1126e-03, -6.8277e-03, -7.0703e-03, -8.2621e-03, -1.1948e-02,
        -1.1257e-02, -8.1783e-04,  2.8155e-03,  1.3529e-02,  8.4562e-03,
         1.0115e-02,  8.0973e-03,  8.7828e-03,  1.3642e-02,  1.2801e-02,
         1.0559e-02,  1.2331e-02,  1.3495e-02,  1.1490e-02,  1.3695e-02,
         9.6379e-03, -6.2802e-03,  7.3128e-03,  1.0545e-02, -9.0537e-03,
        -4.9384e-03, -3.3674e-03, -1.1999e-03,  6.1797e-03, -7.6482e-03,
        -3.5310e-03,  1.1931e-02, -1.0666e-02,  1.0204e-02,  1.0087e-02,
        -1.1836e-02,  1.7039e-03,  1.0861e-04,  1.2880e-02,  5.3127e-03,
        -2.0191e-03,  4.7786e-03, -1.0708e-03,  1.3639e-02,  1.2699e-02,
        -1.0321e-02, -1.1561e-03, -8.2429e-03, -6.5098e-03, -1.0962e-02,
        -6.3791e-03,  1.2729e-02, -3.7229e-03, -4.9669e-03,  5.4865e-05,
        -9.2468e-04,  2.0089e-03, -2.6073e-03, -2.3093e-03,  9.8840e-03,
         1.0632e-02, -4.5253e-04, -8.9169e-03, -8.4551e-03, -1.0190e-03,
         1.0742e-02, -8.5581e-03, -4.9411e-03,  1.1622e-02, -4.0772e-03,
        -6.4275e-04,  6.5100e-03, -1.0463e-02,  1.3268e-03,  5.3923e-03,
         9.2409e-03,  4.7766e-04, -1.0131e-02,  1.4042e-02, -7.7593e-03,
         2.3406e-03, -5.7328e-03, -6.3101e-03,  1.0550e-02, -2.3091e-03,
         4.1111e-03, -9.3874e-03, -9.0414e-03, -1.0786e-02,  1.2145e-02,
         3.5846e-05, -2.2454e-03, -2.8096e-03, -3.7694e-03, -1.4512e-02,
        -1.3875e-02,  5.6938e-03, -1.1480e-02,  3.8519e-03,  3.1260e-04,
         6.2892e-03, -1.3450e-02, -7.4172e-03,  1.2905e-02,  1.1140e-02,
         1.3612e-03,  4.1899e-03, -1.1067e-02, -9.9949e-03,  8.6787e-03,
         1.2992e-02,  3.5117e-03], device='cuda:0', requires_grad=True)

conv_net.16.weight, torch.Size([10, 512]), # params: 5120, Parameter containing:
tensor([[ 1.8567e-03,  1.0186e-04,  6.0793e-04,  ...,  9.2356e-04,
          1.1038e-03,  2.0925e-03],
        [ 8.0798e-05, -1.4505e-04,  3.3515e-04,  ...,  3.5733e-04,
         -3.7920e-04,  7.3041e-04],
        [ 1.4381e-03,  4.7777e-04, -2.6404e-03,  ...,  1.6088e-04,
          7.2652e-04, -1.3060e-03],
        ...,
        [ 6.9347e-04,  2.2148e-04, -9.5821e-04,  ...,  1.4235e-03,
          5.6630e-04,  1.8727e-03],
        [-1.2380e-03, -8.9626e-04,  5.3784e-04,  ..., -1.2041e-03,
          1.1965e-03, -4.8963e-04],
        [-8.8442e-04,  6.5482e-04, -9.6397e-04,  ...,  1.2021e-03,
         -8.3118e-05,  1.5674e-03]], device='cuda:0', requires_grad=True)

conv_net.16.bias, torch.Size([10]), # params: 10, Parameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',
       requires_grad=True)

Total # params: 7678474

conv_net[0].weight shape: torch.Size([128, 3, 3, 3])
Epoch [1/50], Step [100/245], Loss: 1.8457
Epoch [1/50], Step [200/245], Loss: 1.5261
Validataion accuracy is: 47.9 %
Saving model with best validation accuracy so-far...

Epoch [2/50], Step [100/245], Loss: 1.3714
Epoch [2/50], Step [200/245], Loss: 1.1633
Validataion accuracy is: 61.7 %
Saving model with best validation accuracy so-far...

Epoch [3/50], Step [100/245], Loss: 1.0958
Epoch [3/50], Step [200/245], Loss: 0.9392
Validataion accuracy is: 67.9 %
Saving model with best validation accuracy so-far...

Epoch [4/50], Step [100/245], Loss: 0.7948
Epoch [4/50], Step [200/245], Loss: 0.8413
Validataion accuracy is: 71.3 %
Saving model with best validation accuracy so-far...

Epoch [5/50], Step [100/245], Loss: 0.7469
Epoch [5/50], Step [200/245], Loss: 0.7576
Validataion accuracy is: 72.1 %
Saving model with best validation accuracy so-far...

Epoch [6/50], Step [100/245], Loss: 0.4961
Epoch [6/50], Step [200/245], Loss: 0.6025
Validataion accuracy is: 74.2 %
Saving model with best validation accuracy so-far...

Epoch [7/50], Step [100/245], Loss: 0.4686
Epoch [7/50], Step [200/245], Loss: 0.4832
Validataion accuracy is: 76.7 %
Saving model with best validation accuracy so-far...

Epoch [8/50], Step [100/245], Loss: 0.6654
Epoch [8/50], Step [200/245], Loss: 0.4751
Validataion accuracy is: 75.0 %
Epoch [9/50], Step [100/245], Loss: 0.5223
Epoch [9/50], Step [200/245], Loss: 0.5672
Validataion accuracy is: 77.0 %
Saving model with best validation accuracy so-far...

Epoch [10/50], Step [100/245], Loss: 0.4099
Epoch [10/50], Step [200/245], Loss: 0.5229
Validataion accuracy is: 77.7 %
Saving model with best validation accuracy so-far...

Epoch [11/50], Step [100/245], Loss: 0.4468
Epoch [11/50], Step [200/245], Loss: 0.3588
Validataion accuracy is: 78.6 %
Saving model with best validation accuracy so-far...

Epoch [12/50], Step [100/245], Loss: 0.4759
Epoch [12/50], Step [200/245], Loss: 0.3296
Validataion accuracy is: 77.9 %
Epoch [13/50], Step [100/245], Loss: 0.3721
Epoch [13/50], Step [200/245], Loss: 0.3813
Validataion accuracy is: 78.7 %
Saving model with best validation accuracy so-far...

Epoch [14/50], Step [100/245], Loss: 0.2590
Epoch [14/50], Step [200/245], Loss: 0.3264
Validataion accuracy is: 79.7 %
Saving model with best validation accuracy so-far...

Epoch [15/50], Step [100/245], Loss: 0.2869
Epoch [15/50], Step [200/245], Loss: 0.2371
Validataion accuracy is: 78.5 %
Epoch [16/50], Step [100/245], Loss: 0.1617
Epoch [16/50], Step [200/245], Loss: 0.2722
Validataion accuracy is: 78.1 %
Epoch [17/50], Step [100/245], Loss: 0.1987
Epoch [17/50], Step [200/245], Loss: 0.2321
Validataion accuracy is: 78.2 %
Epoch [18/50], Step [100/245], Loss: 0.1695
Epoch [18/50], Step [200/245], Loss: 0.2148
Validataion accuracy is: 77.9 %
Epoch [19/50], Step [100/245], Loss: 0.1561
Epoch [19/50], Step [200/245], Loss: 0.1240
Validataion accuracy is: 80.5 %
Saving model with best validation accuracy so-far...

Epoch [20/50], Step [100/245], Loss: 0.0905
Epoch [20/50], Step [200/245], Loss: 0.1271
Validataion accuracy is: 80.4 %
Epoch [21/50], Step [100/245], Loss: 0.1121
Epoch [21/50], Step [200/245], Loss: 0.1016
Validataion accuracy is: 80.8 %
Saving model with best validation accuracy so-far...

Epoch [22/50], Step [100/245], Loss: 0.1663
Epoch [22/50], Step [200/245], Loss: 0.0824
Validataion accuracy is: 79.6 %
Epoch [23/50], Step [100/245], Loss: 0.0860
Epoch [23/50], Step [200/245], Loss: 0.1092
Validataion accuracy is: 78.6 %
Epoch [24/50], Step [100/245], Loss: 0.0618
Epoch [24/50], Step [200/245], Loss: 0.0865
Validataion accuracy is: 80.2 %
Epoch [25/50], Step [100/245], Loss: 0.0648
Epoch [25/50], Step [200/245], Loss: 0.0853
Validataion accuracy is: 78.2 %
Epoch [26/50], Step [100/245], Loss: 0.0351
Epoch [26/50], Step [200/245], Loss: 0.0658
Validataion accuracy is: 79.1 %
Epoch [27/50], Step [100/245], Loss: 0.0417
Epoch [27/50], Step [200/245], Loss: 0.0623
Validataion accuracy is: 79.3 %
Epoch [28/50], Step [100/245], Loss: 0.0520
Epoch [28/50], Step [200/245], Loss: 0.0535
Validataion accuracy is: 79.6 %
Epoch [29/50], Step [100/245], Loss: 0.0348
Epoch [29/50], Step [200/245], Loss: 0.0344
Validataion accuracy is: 80.2 %
Epoch [30/50], Step [100/245], Loss: 0.0273
Epoch [30/50], Step [200/245], Loss: 0.0421
Validataion accuracy is: 79.9 %
Epoch [31/50], Step [100/245], Loss: 0.0334
Epoch [31/50], Step [200/245], Loss: 0.0549
Validataion accuracy is: 80.6 %
Epoch [32/50], Step [100/245], Loss: 0.0396
Epoch [32/50], Step [200/245], Loss: 0.0277
Validataion accuracy is: 80.2 %
Epoch [33/50], Step [100/245], Loss: 0.0192
Epoch [33/50], Step [200/245], Loss: 0.0228
Validataion accuracy is: 79.9 %
Epoch [34/50], Step [100/245], Loss: 0.0207
Epoch [34/50], Step [200/245], Loss: 0.0391
Validataion accuracy is: 79.2 %
Epoch [35/50], Step [100/245], Loss: 0.0177
Epoch [35/50], Step [200/245], Loss: 0.0298
Validataion accuracy is: 79.7 %
Epoch [36/50], Step [100/245], Loss: 0.0209
Epoch [36/50], Step [200/245], Loss: 0.0380
Validataion accuracy is: 80.3 %
Epoch [37/50], Step [100/245], Loss: 0.0376
Epoch [37/50], Step [200/245], Loss: 0.0348
Validataion accuracy is: 79.5 %
Epoch [38/50], Step [100/245], Loss: 0.0181
Epoch [38/50], Step [200/245], Loss: 0.0231
Validataion accuracy is: 80.0 %
Epoch [39/50], Step [100/245], Loss: 0.0175
Epoch [39/50], Step [200/245], Loss: 0.0300
Validataion accuracy is: 80.3 %
Epoch [40/50], Step [100/245], Loss: 0.0169
Epoch [40/50], Step [200/245], Loss: 0.0324
Validataion accuracy is: 79.4 %
Epoch [41/50], Step [100/245], Loss: 0.0200
Epoch [41/50], Step [200/245], Loss: 0.0209
Validataion accuracy is: 79.5 %
Epoch [42/50], Step [100/245], Loss: 0.0198
Epoch [42/50], Step [200/245], Loss: 0.0202
Validataion accuracy is: 79.1 %
Epoch [43/50], Step [100/245], Loss: 0.0223
Epoch [43/50], Step [200/245], Loss: 0.0316
Validataion accuracy is: 79.7 %
Epoch [44/50], Step [100/245], Loss: 0.0145
Epoch [44/50], Step [200/245], Loss: 0.0161
Validataion accuracy is: 80.3 %
Epoch [45/50], Step [100/245], Loss: 0.0211
Epoch [45/50], Step [200/245], Loss: 0.0243
Validataion accuracy is: 78.9 %
Epoch [46/50], Step [100/245], Loss: 0.0166
Epoch [46/50], Step [200/245], Loss: 0.0180
Validataion accuracy is: 79.7 %
Epoch [47/50], Step [100/245], Loss: 0.0194
Epoch [47/50], Step [200/245], Loss: 0.0189
Validataion accuracy is: 79.5 %
Epoch [48/50], Step [100/245], Loss: 0.0191
Epoch [48/50], Step [200/245], Loss: 0.0186
Validataion accuracy is: 80.3 %
Epoch [49/50], Step [100/245], Loss: 0.0125
Epoch [49/50], Step [200/245], Loss: 0.0184
Validataion accuracy is: 80.2 %
Epoch [50/50], Step [100/245], Loss: 0.0138
Epoch [50/50], Step [200/245], Loss: 0.0158
Validataion accuracy is: 79.3 %
Best Validataion accuracy is: 80.80000000000001
Accuracy of the network on the 1000 test images: 78.7 %
conv_net[0].weight shape: torch.Size([128, 3, 3, 3])

